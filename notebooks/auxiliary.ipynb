{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add id to original label guided dataset\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "file_a_path = \"../VariErr-Label-Guided-longest.json\"\n",
    "file_b_path = \"../varierr.json\"\n",
    "output_path = \"../VariErr-Label-Guided-longest-with-ID.json\"\n",
    "\n",
    "with open(file_b_path, \"r\") as f:\n",
    "    full_dataset = [json.loads(line) for line in f]\n",
    "    pair_to_id = {\n",
    "        (sample[\"context\"].strip(), sample[\"statement\"].strip()): sample[\"id\"]\n",
    "        for sample in full_dataset\n",
    "    }\n",
    "\n",
    "print(f\"We have {len(pair_to_id)} pairs.\")\n",
    "\n",
    "with open(file_a_path, \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "with open(output_path, \"w\") as f_out:\n",
    "    for sample in tqdm(data):\n",
    "        premise = sample[\"premise\"].strip()\n",
    "        hypothesis = sample[\"hypothesis\"].strip()\n",
    "        key = (premise, hypothesis)\n",
    "\n",
    "        if key in pair_to_id:\n",
    "            sample[\"id\"] = pair_to_id[key]\n",
    "        else:\n",
    "            print(f\"Not found: premise='{premise}...', hypothesis='{hypothesis}...'\")\n",
    "            sample[\"id\"] = None\n",
    "\n",
    "        f_out.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存：/Users/phoebeeeee/ongoing/LLM_AED/generation/qwen_72b_generation_raw/manual_check.csv（共 3920 行）\n"
     ]
    }
   ],
   "source": [
    "# for manual checking\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"/Users/phoebeeeee/ongoing/LLM_AED/generation/qwen_72b_generation_raw\")\n",
    "OUTPUT_CSV = BASE_DIR / \"manual_check.csv\"\n",
    "FILE_TYPES = [\"E\", \"N\", \"C\"]\n",
    "VALIDATION = True \n",
    "STRIP_NUMBERING = True \n",
    "\n",
    "_CLEAN_PREFIX_RE = re.compile(r\"^\\s*(?:[\\d]+[\\.\\)]|[-•*]|[a-zA-Z][\\.\\)]|\\(\\w+\\))\\s*\")\n",
    "\n",
    "def clean_explanation(text: str) -> str:\n",
    "    return _CLEAN_PREFIX_RE.sub(\"\", text).strip()\n",
    "\n",
    "def read_file_lines(file_path: Path, strip_numbering: bool = True):\n",
    "    lines = []\n",
    "    if not file_path.is_file():\n",
    "        return lines\n",
    "    with file_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for raw in f:\n",
    "            s = raw.strip()\n",
    "            if not s:\n",
    "                continue  # 跳过空行\n",
    "            if strip_numbering:\n",
    "                s = clean_explanation(s)\n",
    "                if not s:     # 清理后为空则跳过（避免写入 \"\"）\n",
    "                    continue\n",
    "            lines.append(s)\n",
    "    return lines\n",
    "\n",
    "def aggregate_to_csv(base_dir: Path, output_csv: Path):\n",
    "    records = []\n",
    "    for sub in sorted([p for p in base_dir.iterdir() if p.is_dir()]):\n",
    "        subfolder_name = sub.name\n",
    "        for ft in FILE_TYPES:\n",
    "            fpath = sub / ft  # 期望文件名就是 'E' / 'N' / 'C'\n",
    "            if not fpath.exists():\n",
    "                continue\n",
    "            lines = read_file_lines(fpath, strip_numbering=STRIP_NUMBERING)\n",
    "            for idx, content in enumerate(lines, start=1):\n",
    "                records.append({\n",
    "                    \"validation\": VALIDATION,\n",
    "                    \"subfolder\": subfolder_name,\n",
    "                    \"file_type\": ft,\n",
    "                    \"line_no\": idx,\n",
    "                    \"content\": content\n",
    "                })\n",
    "\n",
    "    if not records:\n",
    "        print(\"未收集到任何记录，请检查目录与文件命名是否正确。\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame.from_records(\n",
    "        records,\n",
    "        columns=[\"validation\", \"subfolder\", \"file_type\", \"line_no\", \"content\"]\n",
    "    )\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"已保存：{output_csv}（共 {len(df)} 行）\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    aggregate_to_csv(BASE_DIR, OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inject explanations:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inject explanations: 100%|██████████| 500/500 [00:00<00:00, 1383.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# integrate explanations generated by LLMs to a singel file\n",
    "\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "explanation_root = Path(\"/Users/phoebeeeee/ongoing/LLM_AED/generation/llama_70b_generation_raw\")\n",
    "input_jsonl = Path(\"/Users/phoebeeeee/ongoing/LLM_AED/dataset/varierr/varierr.json\")\n",
    "output_jsonl = Path(\"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/llama_70b_generation_raw.jsonl\")\n",
    "\n",
    "# suffix = \".txt\"\n",
    "\n",
    "def clean_explanation(text: str) -> str:\n",
    "    return re.sub(r\"^\\s*(?:[\\d]+[\\.\\)]|[-•*]|[a-zA-Z][\\.\\)]|\\(\\w+\\))\\s*\", \"\", text).strip()\n",
    "\n",
    "label_map = {\"E\": \"e\", \"N\": \"n\", \"C\": \"c\"}\n",
    "\n",
    "with open(input_jsonl, \"r\", encoding=\"utf-8\") as f:\n",
    "    instances = [json.loads(line) for line in f]\n",
    "\n",
    "with open(output_jsonl, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for instance in tqdm(instances, desc=\"Inject explanations\"):\n",
    "        sample_id = str(instance[\"id\"])\n",
    "        subfolder = explanation_root / sample_id\n",
    "        new_comments = []\n",
    "\n",
    "        if not subfolder.exists():\n",
    "            print(f\"missing folder: {subfolder}\")\n",
    "        else:\n",
    "            for label in [\"E\", \"N\", \"C\"]:\n",
    "                tried_files = [\n",
    "                    # f\"{label}_third.txt\"\n",
    "                    # f\"{label}_second.txt\",\n",
    "                    # f\"{label}_first.txt\",\n",
    "                    label\n",
    "                ]\n",
    "        \n",
    "                file_found = False\n",
    "                for fname in tried_files:\n",
    "                    file_path = subfolder / f\"{fname}\"\n",
    "                    if file_path.exists():\n",
    "                        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                            for raw in f:\n",
    "                                if not raw.strip():\n",
    "                                    continue  \n",
    "                                exp = clean_explanation(raw)\n",
    "                                if exp: \n",
    "                                    new_comments.append([exp, label_map[label]])\n",
    "                        file_found = True\n",
    "\n",
    "                if not file_found:\n",
    "                    print(f\"No file found for {label} in {subfolder}\")\n",
    "        new_instance = {\n",
    "            \"id\": instance[\"id\"],\n",
    "            \"premise\": instance[\"context\"],\n",
    "            \"hypothesis\": instance[\"statement\"],\n",
    "            \"generated_explanations\": new_comments\n",
    "        }\n",
    "        if new_comments:\n",
    "            fout.write(json.dumps(new_instance, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total generated_explanations: 3920\n",
      "label=n: 1382 (35.26%)\n",
      "label=e: 1337 (34.11%)\n",
      "label=c: 1201 (30.64%)\n",
      "Unique labels: ['c', 'e', 'n']\n"
     ]
    }
   ],
   "source": [
    "## double check explanation number in _raw.jsonl\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "in_path = \"/Users/phoebeeeee/ongoing/LLM_AED/no_preprocessing/qwen_72b_generation_raw.jsonl\"  # 改成你的文件路径\n",
    "df = pd.read_json(in_path, lines=True)\n",
    "\n",
    "labels_series = df[\"generated_explanations\"].apply(\n",
    "    lambda lst: [x[1] for x in (lst or []) if isinstance(x, (list, tuple)) and len(x) >= 2]\n",
    ")\n",
    "\n",
    "labels_exploded = labels_series.explode().dropna().astype(str)\n",
    "total = labels_exploded.shape[0]\n",
    "label_counts = labels_exploded.value_counts()\n",
    "\n",
    "print(f\"Total generated_explanations: {total}\")\n",
    "for lbl, cnt in label_counts.items():\n",
    "    print(f\"label={lbl}: {cnt} ({cnt/total:.2%})\")\n",
    "\n",
    "print(\"Unique labels:\", sorted(label_counts.index.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E=1198，N=1407，C=1415，total: 4020\n"
     ]
    }
   ],
   "source": [
    "# count number\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_FOLDER = \"/Users/phoebeeeee/ongoing/Beyond-noise-MA-Zuo/EACL/qwen_7b_generation_raw\"\n",
    "\n",
    "def count_generations(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return sum(1 for line in f if line.strip())\n",
    "\n",
    "def count_all_generations():\n",
    "    records = []\n",
    "    total = {\"E\": 0, \"N\": 0, \"C\": 0}\n",
    "\n",
    "    for subfolder in os.listdir(ROOT_FOLDER):\n",
    "        sub_path = os.path.join(ROOT_FOLDER, subfolder)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "\n",
    "        row = {\"folder\": subfolder}\n",
    "        for label in [\"E\", \"N\", \"C\"]:\n",
    "            file_path = os.path.join(sub_path, f\"{label}_third.txt\")\n",
    "            if os.path.isfile(file_path):\n",
    "                count = count_generations(file_path)\n",
    "            else:\n",
    "                count = 0\n",
    "            row[label] = count\n",
    "            total[label] += count\n",
    "\n",
    "        records.append(row)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df.loc[\"TOTAL\"] = [\"TOTAL\"] + [total[\"E\"], total[\"N\"], total[\"C\"]]\n",
    "    # print(df)\n",
    "\n",
    "    print(f\"E={total['E']}，N={total['N']}，C={total['C']}，total: {total['E'] + total['N'] + total['C']}\")\n",
    "\n",
    "count_all_generations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get avg score for instance\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('../scores.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "groups = defaultdict(list)\n",
    "for key, value in data.items():\n",
    "    try:\n",
    "        id_label, _ = key.rsplit('-', 1)\n",
    "        groups[id_label].append(value)\n",
    "    except ValueError:\n",
    "        print(f\"'{key}' does not match.\")\n",
    "        continue\n",
    "\n",
    "averaged_data = {k: sum(v) / len(v) for k, v in groups.items()}\n",
    "with open('../avg_llama3.1_scores.jsonn', 'w') as f:\n",
    "    json.dump(averaged_data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thresholding for ChaosNLI\n",
    "import json\n",
    "\n",
    "def process_label_distribution(label_probs, threshold=0.2):\n",
    "    valid_indices = [i for i, p in enumerate(label_probs) if p >= threshold]\n",
    "    count = len(valid_indices)\n",
    "    if count == 0:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    return [1.0 / count if i in valid_indices else 0.0 for i in range(3)]\n",
    "\n",
    "input_file = '../dev_cleaned.json'\n",
    "output_file = '../dev_cleaned_20.json'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as fin, open(output_file, 'w', encoding='utf-8') as fout:\n",
    "    for line in fin:\n",
    "        item = json.loads(line)\n",
    "        raw_label = item['label']\n",
    "        new_label = process_label_distribution(raw_label)\n",
    "        item['label'] = new_label\n",
    "        fout.write(json.dumps(item, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已写出 /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original_peer/qwen_72b_original_peer/llama8b.json\n",
      "已写出 /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original_peer/qwen_72b_original_peer/llama70b.json\n",
      "已写出 /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original_peer/qwen_72b_original_peer/qwen7b.json\n",
      "已写出 /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original_peer/qwen_72b_original_peer/qwen72b.json\n"
     ]
    }
   ],
   "source": [
    "# processing peer results\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# 输入输出路径\n",
    "input_file = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original_peer/qwen_72b_original_peer/scores.json\"\n",
    "output_dir = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original_peer/qwen_72b_original_peer\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# {model_id: {instance_id: [(label_code, old_idx, value), ...]}}\n",
    "grouped = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for key, value in data.items():\n",
    "    try:\n",
    "        model_id, instance_id, rest = key.split(\"_\", 2)\n",
    "        label_code, old_idx = rest.split(\"-\")\n",
    "        old_idx = int(old_idx)\n",
    "    except ValueError:\n",
    "        print(f\"跳过非法 key: {key}\")\n",
    "        continue\n",
    "\n",
    "    grouped[model_id][instance_id].append((label_code, old_idx, value))\n",
    "\n",
    "# 重新编号并写文件\n",
    "for model_id, instances in grouped.items():\n",
    "    new_dict = {}\n",
    "    for instance_id, items in instances.items():\n",
    "        # 保持原始顺序：先按 old_idx 排好\n",
    "        items.sort(key=lambda x: x[1])\n",
    "        for new_idx, (label_code, _, value) in enumerate(items):\n",
    "            new_key = f\"{instance_id}_{label_code}-{new_idx}\"\n",
    "            new_dict[new_key] = value\n",
    "\n",
    "    output_file = os.path.join(output_dir, f\"{model_id}.json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(new_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"已写出 {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两个文件的 key 完全相同 ✅\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file1 = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/chase_peer/qwen_72b_chase_peer/qwen72b.json\"\n",
    "file2 = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/all/qwen_72b_all/scores.json\"\n",
    "\n",
    "with open(file1, \"r\", encoding=\"utf-8\") as f:\n",
    "    data1 = json.load(f)\n",
    "with open(file2, \"r\", encoding=\"utf-8\") as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "keys1 = set(data1.keys())\n",
    "keys2 = set(data2.keys())\n",
    "\n",
    "if keys1 == keys2:\n",
    "    print(\"两个文件的 key 完全相同 ✅\")\n",
    "else:\n",
    "    print(\"两个文件的 key 不完全相同 ❌\")\n",
    "    print(\"只在 file1 中存在的 key:\", keys1 - keys2)\n",
    "    print(\"只在 file2 中存在的 key:\", keys2 - keys1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第二列 llm_not_calidated_error：\n",
      "  e: 32  n: 195  c: 90\n",
      "第三列 varierr_error：\n",
      "  e: 53  n: 23  c: 53\n",
      "两列相同的 error（逐行交集计数）：\n",
      "  e: 1  n: 10  c: 7\n"
     ]
    }
   ],
   "source": [
    "# count error number + overlap per label\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "path = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/llama_8b_original/kld_jsd/llama_8b_original_after_0.9_merged_errors.csv\"  # 改成你的文件路径\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# 把单元格里的 '[\"c\"]'、'[]' 等转为 Python 列表；兼容引号异常\n",
    "def parse_list_cell(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        # 某些 CSV 里会出现双引号翻倍的情况\n",
    "        try:\n",
    "            return ast.literal_eval(s.replace('\"\"', '\"'))\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "# 映射为 e/n/c\n",
    "map_long = {\"entailment\": \"e\", \"neutral\": \"n\", \"contradiction\": \"c\",\n",
    "            \"e\": \"e\", \"n\": \"n\", \"c\": \"c\"}\n",
    "\n",
    "cnt2 = Counter()       # llm_error 计数（按标签逐项）\n",
    "cnt3 = Counter()       # varierr_error 计数（按标签逐项）\n",
    "overlap_cnt = Counter()  # 两列里相同的标签计数（逐行一次）\n",
    "\n",
    "# 统计第二列（通常是 'e'/'n'/'c'）\n",
    "for items in df[\"llm_error\"].apply(parse_list_cell):\n",
    "    for it in items:\n",
    "        k = map_long.get(it, None)\n",
    "        if k in (\"e\", \"n\", \"c\"):\n",
    "            cnt2[k] += 1\n",
    "\n",
    "# 统计第三列（可能是完整单词）\n",
    "for items in df[\"varierr_error\"].apply(parse_list_cell):\n",
    "    for it in items:\n",
    "        k = map_long.get(it, None)\n",
    "        if k in (\"e\", \"n\", \"c\"):\n",
    "            cnt3[k] += 1\n",
    "\n",
    "# 逐行统计两列相同的标签（同一行里只计一次该标签）\n",
    "for llm_items, var_items in zip(\n",
    "    df[\"llm_error\"].apply(parse_list_cell),\n",
    "    df[\"varierr_error\"].apply(parse_list_cell)\n",
    "):\n",
    "    llm_set = {map_long.get(it) for it in llm_items if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "    var_set = {map_long.get(it) for it in var_items if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "    inter = llm_set & var_set\n",
    "    for lab in inter:\n",
    "        overlap_cnt[lab] += 1\n",
    "\n",
    "print(\"第二列 llm_not_calidated_error：\")\n",
    "print(f\"  e: {cnt2.get('e',0)}  n: {cnt2.get('n',0)}  c: {cnt2.get('c',0)}\")\n",
    "\n",
    "print(\"第三列 varierr_error：\")\n",
    "print(f\"  e: {cnt3.get('e',0)}  n: {cnt3.get('n',0)}  c: {cnt3.get('c',0)}\")\n",
    "\n",
    "print(\"两列相同的 error（逐行交集计数）：\")\n",
    "print(f\"  e: {overlap_cnt.get('e',0)}  n: {overlap_cnt.get('n',0)}  c: {overlap_cnt.get('c',0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_validated：\n",
      "  e: 466  n: 418  c: 353\n",
      "varierr_validated：\n",
      "  e: 210  n: 380  c: 159\n",
      "两列相同的\n",
      "  e: 200  n: 318  c: 112\n"
     ]
    }
   ],
   "source": [
    "# count error number + overlap per label\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "path = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/all/llama_8b_all/validated_overlap/with_validation_0.1_merged_validation.csv\"  # 改成你的文件路径\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# 把单元格里的 '[\"c\"]'、'[]' 等转为 Python 列表；兼容引号异常\n",
    "def parse_list_cell(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    return ast.literal_eval(s)\n",
    "    # except Exception:\n",
    "        # 某些 CSV 里会出现双引号翻倍的情况\n",
    "        # try:\n",
    "        #     return ast.literal_eval(s.replace('\"\"', '\"'))\n",
    "        # except Exception:\n",
    "        #     return []\n",
    "\n",
    "# 映射为 e/n/c\n",
    "map_long = {\"entailment\": \"e\", \"neutral\": \"n\", \"contradiction\": \"c\", \"e\": \"e\", \"n\": \"n\", \"c\": \"c\"}\n",
    "\n",
    "cnt2 = Counter()       # llm 计数（按标签逐项）\n",
    "cnt3 = Counter()       # varierr计数（按标签逐项）\n",
    "overlap_cnt = Counter()  # 两列里相同的标签计数（逐行一次）\n",
    "\n",
    "# 统计第二列（通常是 'e'/'n'/'c'）\n",
    "for items in df[\"llm_validated\"].apply(parse_list_cell):\n",
    "    for it in items:\n",
    "        k = map_long.get(it, None)\n",
    "        if k in (\"e\", \"n\", \"c\"):\n",
    "            cnt2[k] += 1\n",
    "\n",
    "# 统计第三列（可能是完整单词）\n",
    "for items in df[\"varierr_validated\"].apply(parse_list_cell):\n",
    "    for it in items:\n",
    "        k = map_long.get(it, None)\n",
    "        if k in (\"e\", \"n\", \"c\"):\n",
    "            cnt3[k] += 1\n",
    "\n",
    "# 逐行统计两列相同的标签（同一行里只计一次该标签）\n",
    "for llm_items, var_items in zip(\n",
    "    df[\"llm_validated\"].apply(parse_list_cell),\n",
    "    df[\"varierr_validated\"].apply(parse_list_cell)\n",
    "):\n",
    "    llm_set = {map_long.get(it) for it in llm_items if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "    var_set = {map_long.get(it) for it in var_items if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "    inter = llm_set & var_set\n",
    "    for lab in inter:\n",
    "        overlap_cnt[lab] += 1\n",
    "\n",
    "print(\"llm_validated：\")\n",
    "print(f\"  e: {cnt2.get('e',0)}  n: {cnt2.get('n',0)}  c: {cnt2.get('c',0)}\")\n",
    "\n",
    "print(\"varierr_validated：\")\n",
    "print(f\"  e: {cnt3.get('e',0)}  n: {cnt3.get('n',0)}  c: {cnt3.get('c',0)}\")\n",
    "\n",
    "print(\"两列相同的\")\n",
    "print(f\"  e: {overlap_cnt.get('e',0)}  n: {overlap_cnt.get('n',0)}  c: {overlap_cnt.get('c',0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explanations from E/N/C: 4022\n",
      "Average length (characters): 22.35\n",
      "4022\n"
     ]
    }
   ],
   "source": [
    "# average number of space-separated words per explanation\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# 根目录（按你的路径）\n",
    "BASE_DIR = Path(\"/Users/phoebeeeee/ongoing/LLM_AED/generation/llama_70b_generation_raw\")\n",
    "\n",
    "# 行首序号清理正则：匹配 \"1.\"、\"2)\"、\"3、\"、\"4-\"、\"5:\"、\"6：\" 等\n",
    "LEADING_NUM_RE = re.compile(r\"^\\s*\\d+\\s*[\\.\\)\\-、:：]?\\s*\")\n",
    "\n",
    "def clean_line(line: str) -> str:\n",
    "    \"\"\"去首尾空白、去掉行首序号，返回清理后的行。\"\"\"\n",
    "    s = line.strip()\n",
    "    s = LEADING_NUM_RE.sub(\"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def read_file_lines(p: Path):\n",
    "    \"\"\"读取文件并逐行清洗，返回非空解释列表。\"\"\"\n",
    "    if not p.is_file():\n",
    "        return []\n",
    "    cleaned = []\n",
    "    with p.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            s = clean_line(line)\n",
    "            if s:  # 过滤清洗后为空的行\n",
    "                cleaned.append(s)\n",
    "    return cleaned\n",
    "\n",
    "def collect_explanations(base: Path):\n",
    "    \"\"\"\n",
    "    遍历 base 下所有子文件夹，读取 E/N/C 三个文件，\n",
    "    返回所有 explanation 的列表（来自 E/N/C 的总和）。\n",
    "    \"\"\"\n",
    "    all_exps = []\n",
    "    for sub in sorted(base.iterdir()):\n",
    "        if not sub.is_dir():\n",
    "            continue\n",
    "        # 每个子目录下的 E/N/C（无扩展名）\n",
    "        for name in [\"E\", \"N\", \"C\"]:\n",
    "            fp = sub / name\n",
    "            exps = read_file_lines(fp)\n",
    "            all_exps.extend(exps)\n",
    "    return all_exps\n",
    "\n",
    "def main():\n",
    "    all_exps = collect_explanations(BASE_DIR)\n",
    "    total_count = len(all_exps)\n",
    "    avg_len = (sum(len(x.split()) for x in all_exps) / total_count)\n",
    "\n",
    "    print(f\"Total explanations from E/N/C: {total_count}\")\n",
    "    print(f\"Average length (characters): {avg_len:.2f}\")\n",
    "    print(total_count)\n",
    "\n",
    "    # 如需查看一个样例：\n",
    "    # for i, e in enumerate(all_exps[:10], 1):\n",
    "    #     print(f\"{i}. {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall ===\n",
      "total_reasons: 1933\n",
      "labels_with_reason: 1933\n",
      "num_label_items: 1933\n",
      "Avg. Expl./Label: 1.0000\n",
      "Avg. tokens/expl (cleaned, split): 13.89\n",
      "\n",
      "=== By Category ===\n",
      "[entailment]\n",
      "  total_reasons: 554\n",
      "  labels_with_reason: 554\n",
      "  num_label_items: 554\n",
      "  Avg. Expl./Label: 1.0000\n",
      "  Avg. tokens/expl: 13.92\n",
      "[neutral]\n",
      "  total_reasons: 977\n",
      "  labels_with_reason: 977\n",
      "  num_label_items: 977\n",
      "  Avg. Expl./Label: 1.0000\n",
      "  Avg. tokens/expl: 13.97\n",
      "[contradiction]\n",
      "  total_reasons: 402\n",
      "  labels_with_reason: 402\n",
      "  num_label_items: 402\n",
      "  Avg. Expl./Label: 1.0000\n",
      "  Avg. tokens/expl: 13.65\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "LEADING_NUM_RE = re.compile(r\"^\\s*\\d+\\s*[\\.\\)\\-、:：]?\\s*\")\n",
    "\n",
    "def clean_line(line: str) -> str:\n",
    "    \"\"\"去首尾空白、去掉行首序号，返回清理后的行。\"\"\"\n",
    "    s = line.strip()\n",
    "    s = LEADING_NUM_RE.sub(\"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def read_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
    "    items = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                items.append(obj)\n",
    "            except json.JSONDecodeError as e:\n",
    "                # 不中断，报行号方便你去捶数据\n",
    "                print(f\"[WARN] JSON 解析失败 {path}:{i}: {e}\")\n",
    "    return items\n",
    "\n",
    "def collect_reasons(sample: Dict[str, Any], key: str):\n",
    "    \"\"\"返回 (该类的标注项总数, 清洗后非空 reason 列表)\"\"\"\n",
    "    arr = sample.get(key, [])\n",
    "    if not isinstance(arr, list):\n",
    "        return 0, []\n",
    "    reasons = []\n",
    "    for ann in arr:\n",
    "        if not isinstance(ann, dict):\n",
    "            continue\n",
    "        r = clean_line(str(ann.get(\"reason\", \"\")))\n",
    "        if r:\n",
    "            reasons.append(r)\n",
    "    return len(reasons), reasons\n",
    "\n",
    "def main(paths: List[Path]):\n",
    "    overall_label_items = 0\n",
    "    overall_reasons: List[str] = []\n",
    "\n",
    "    # 按类别的细分统计\n",
    "    per_cat = {\n",
    "        \"entailment\": {\"label_items\": 0, \"reasons\": []},\n",
    "        \"neutral\": {\"label_items\": 0, \"reasons\": []},\n",
    "        \"contradiction\": {\"label_items\": 0, \"reasons\": []},\n",
    "    }\n",
    "\n",
    "    for p in paths:\n",
    "        for obj in read_jsonl(p):\n",
    "            for cat in [\"entailment\", \"neutral\", \"contradiction\"]:\n",
    "                n_items, reasons = collect_reasons(obj, cat)\n",
    "                per_cat[cat][\"label_items\"] += n_items\n",
    "                per_cat[cat][\"reasons\"].extend(reasons)\n",
    "                overall_label_items += n_items\n",
    "                overall_reasons.extend(reasons)\n",
    "\n",
    "    labels_with_reason = len(overall_reasons)  # 带非空 reason 的标注项个数\n",
    "    total_reasons = len(overall_reasons)\n",
    "    num_label_items = overall_label_items\n",
    "    avg_expl_per_label = (total_reasons / num_label_items) if num_label_items else 0.0\n",
    "\n",
    "    # 计算 explanation 平均长度（按 split 后 token 数）\n",
    "    def avg_len(strs: List[str]) -> float:\n",
    "        if not strs:\n",
    "            return 0.0\n",
    "        lengths = [len(s.split()) for s in strs]\n",
    "        return sum(lengths) / len(lengths)\n",
    "\n",
    "    avg_tokens_per_expl = avg_len(overall_reasons)\n",
    "\n",
    "    # 输出\n",
    "    print(\"=== Overall ===\")\n",
    "    print(f\"total_reasons: {total_reasons}\")\n",
    "    print(f\"labels_with_reason: {labels_with_reason}\")\n",
    "    print(f\"num_label_items: {num_label_items}\")\n",
    "    print(f\"Avg. Expl./Label: {avg_expl_per_label:.4f}\")\n",
    "    print(f\"Avg. tokens/expl (cleaned, split): {avg_tokens_per_expl:.2f}\")\n",
    "\n",
    "    print(\"\\n=== By Category ===\")\n",
    "    for cat in [\"entailment\", \"neutral\", \"contradiction\"]:\n",
    "        tr = len(per_cat[cat][\"reasons\"])\n",
    "        ti = per_cat[cat][\"label_items\"]\n",
    "        avg_cat = (tr / ti) if ti else 0.0\n",
    "        avg_tok = avg_len(per_cat[cat][\"reasons\"])\n",
    "        print(f\"[{cat}]\")\n",
    "        print(f\"  total_reasons: {tr}\")\n",
    "        print(f\"  labels_with_reason: {tr}\")\n",
    "        print(f\"  num_label_items: {ti}\")\n",
    "        print(f\"  Avg. Expl./Label: {avg_cat:.4f}\")\n",
    "        print(f\"  Avg. tokens/expl: {avg_tok:.2f}\")\n",
    "\n",
    "\n",
    "path = [Path(\"/Users/phoebeeeee/ongoing/LLM_AED/dataset/varierr/varierr.json\")]\n",
    "main(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选结果已保存到 /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/all/qwen_72b_all/error_overlap.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "input_file = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/all/qwen_72b_all/varierr_without_qwen_72b.json\"   # 你的jsonl文件路径\n",
    "output_file = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/all/qwen_72b_all/error_overlap.csv\" # 输出csv文件路径\n",
    "\n",
    "abb_dict = {\"entailment\":\"e\", \"neutral\":\"n\", \"contradiction\":\"c\"}\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as fin, open(output_file, \"w\", encoding=\"utf-8\", newline=\"\") as fout:\n",
    "    writer = csv.writer(fout)\n",
    "    # 表头\n",
    "    writer.writerow([\"id\", \"error_labels\", \"error_llm\", \"chaosnli_low_labels\"])\n",
    "\n",
    "    for line in fin:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        error_labels = data.get(\"error_labels\", [])\n",
    "        error_labels = [abb_dict[error] for error in error_labels]\n",
    "        error_llm = data.get(\"error_llm\", [])\n",
    "        error_llm = [abb_dict[error] for error in error_llm]\n",
    "        chaosnli_labels = data.get(\"chaosnli_labels\", {})\n",
    "\n",
    "        # 找出 chaosnli_labels 里 < 20 的 label 名称\n",
    "        low_labels = [k for k, v in chaosnli_labels.items() if v is not None and v < 20]\n",
    "\n",
    "        writer.writerow([\n",
    "            data.get(\"id\"),\n",
    "            \";\".join(error_labels) if error_labels else \"\",\n",
    "            \";\".join(error_llm) if error_llm else \"\",\n",
    "            \";\".join(low_labels) if low_labels else \"\"\n",
    "        ])\n",
    "\n",
    "print(f\"筛选结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== with_validation_0.1_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 500  n: 500  c: 500\n",
      "llm和varierr：\n",
      "  e: 210  n: 380  c: 159\n",
      "llm和chaos：\n",
      "  e: 327  n: 389  c: 190\n",
      "\n",
      "=== with_validation_0.2_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 500  n: 500  c: 500\n",
      "llm和varierr：\n",
      "  e: 210  n: 380  c: 159\n",
      "llm和chaos：\n",
      "  e: 327  n: 389  c: 190\n",
      "\n",
      "=== with_validation_0.3_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 495  n: 500  c: 496\n",
      "llm和varierr：\n",
      "  e: 210  n: 380  c: 159\n",
      "llm和chaos：\n",
      "  e: 327  n: 389  c: 190\n",
      "\n",
      "=== with_validation_0.4_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 491  n: 500  c: 492\n",
      "llm和varierr：\n",
      "  e: 210  n: 380  c: 157\n",
      "llm和chaos：\n",
      "  e: 326  n: 389  c: 189\n",
      "\n",
      "=== with_validation_0.5_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 491  n: 500  c: 492\n",
      "llm和varierr：\n",
      "  e: 210  n: 380  c: 157\n",
      "llm和chaos：\n",
      "  e: 326  n: 389  c: 189\n",
      "\n",
      "=== with_validation_0.6_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 491  n: 500  c: 492\n",
      "llm和varierr：\n",
      "  e: 210  n: 380  c: 157\n",
      "llm和chaos：\n",
      "  e: 326  n: 389  c: 189\n",
      "\n",
      "=== with_validation_0.7_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 489  n: 500  c: 492\n",
      "llm和varierr：\n",
      "  e: 210  n: 380  c: 157\n",
      "llm和chaos：\n",
      "  e: 326  n: 389  c: 189\n",
      "\n",
      "=== with_validation_0.8_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 462  n: 493  c: 462\n",
      "llm和varierr：\n",
      "  e: 204  n: 377  c: 152\n",
      "llm和chaos：\n",
      "  e: 315  n: 385  c: 186\n",
      "\n",
      "=== with_validation_0.9_merged_validation.csv ===\n",
      "LLM\n",
      "  e: 196  n: 97  c: 130\n",
      "llm和varierr：\n",
      "  e: 105  n: 72  c: 72\n",
      "llm和chaos：\n",
      "  e: 136  n: 72  c: 103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_list_cell(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    # CSV 里存的是 JSON 风格列表，如 [\"e\",\"n\"]，用 literal_eval 解析\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "# 将各种写法映射为 e/n/c\n",
    "map_long = {\n",
    "    \"entailment\": \"e\", \"neutral\": \"n\", \"contradiction\": \"c\",\n",
    "    \"e\": \"e\", \"n\": \"n\", \"c\": \"c\"\n",
    "}\n",
    "\n",
    "def process_csv(path: Path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    overlap_23 = Counter()  # LLM ∩ VariErr\n",
    "    overlap_24 = Counter()  # LLM ∩ Chaos\n",
    "    total_col2 = Counter()  # LLM\n",
    "    total_col3 = Counter()  # VariErr\n",
    "    total_col4 = Counter()  # Chaos\n",
    "\n",
    "    for items2, items3, items4 in zip(\n",
    "        df[\"llm_validated\"].apply(parse_list_cell),\n",
    "        df[\"varierr_validated\"].apply(parse_list_cell),\n",
    "        df[\"chaos_validated\"].apply(parse_list_cell)\n",
    "    ):\n",
    "        set2 = {map_long.get(it) for it in items2 if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "        set3 = {map_long.get(it) for it in items3 if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "        set4 = {map_long.get(it) for it in items4 if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "\n",
    "        for lab in (set2 & set3):\n",
    "            overlap_23[lab] += 1\n",
    "        for lab in (set2 & set4):\n",
    "            overlap_24[lab] += 1\n",
    "\n",
    "        for lab in set2:\n",
    "            total_col2[lab] += 1\n",
    "        for lab in set3:\n",
    "            total_col3[lab] += 1\n",
    "        for lab in set4:\n",
    "            total_col4[lab] += 1\n",
    "\n",
    "    # 打印该文件结果\n",
    "    print(f\"\\n=== {path.name} ===\")\n",
    "    print(\"LLM\")\n",
    "    print(f\"  e: {total_col2.get('e',0)}  n: {total_col2.get('n',0)}  c: {total_col2.get('c',0)}\")\n",
    "\n",
    "    print(\"llm和varierr：\")\n",
    "    print(f\"  e: {overlap_23.get('e',0)}  n: {overlap_23.get('n',0)}  c: {overlap_23.get('c',0)}\")\n",
    "\n",
    "    print(\"llm和chaos：\")\n",
    "    print(f\"  e: {overlap_24.get('e',0)}  n: {overlap_24.get('n',0)}  c: {overlap_24.get('c',0)}\")\n",
    "\n",
    "    # print(\"VariErr：\")\n",
    "    # print(f\"  e: {total_col3.get('e',0)}  n: {total_col3.get('n',0)}  c: {total_col3.get('c',0)}\")\n",
    "\n",
    "    # print(\"Chaos\")\n",
    "    # print(f\"  e: {total_col4.get('e',0)}  n: {total_col4.get('n',0)}  c: {total_col4.get('c',0)}\")\n",
    "\n",
    "    # 返回计数，便于全局汇总\n",
    "    return {\n",
    "        \"overlap_23\": overlap_23,\n",
    "        \"overlap_24\": overlap_24,\n",
    "        \"total_col2\": total_col2,\n",
    "        \"total_col3\": total_col3,\n",
    "        \"total_col4\": total_col4,\n",
    "    }\n",
    "\n",
    "def process_folder(folder: str, pattern: str = \"*.csv\"):\n",
    "    folder_path = Path(folder)\n",
    "    files = sorted(folder_path.glob(pattern))\n",
    "    if not files:\n",
    "        print(f\"No CSV matched in: {folder}\")\n",
    "        return\n",
    "    \n",
    "    for csv_path in files:\n",
    "        try:\n",
    "            res = process_csv(csv_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {csv_path.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 替换为你的目录路径；可选 pattern 调整筛选\n",
    "    process_folder(\n",
    "        folder=\"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap\",\n",
    "        pattern=\"*.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM\n",
      "  e: 466  n: 418  c: 353\n",
      "llm和varierr：\n",
      "  e: 200  n: 318  c: 112\n",
      "llm和chaos：\n",
      "  e: 312  n: 332  c: 135\n",
      "VariErr：\n",
      "  e: 210  n: 380  c: 159\n",
      "Chaos\n",
      "  e: 327  n: 389  c: 190\n"
     ]
    }
   ],
   "source": [
    "# count overlap between col2 with col3 & col4 (row-wise, label-wise)\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "path = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/all/llama_8b_all/validated_overlap/with_validation_0.1_merged_validation.csv\"  # 改成你的新CSV路径\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# def parse_list_cell(x):\n",
    "#     if pd.isna(x):\n",
    "#         return []\n",
    "#     s = str(x).strip()\n",
    "#     if not s:\n",
    "#         return []\n",
    "#     # 分号分隔\n",
    "#     if \";\" in s:\n",
    "#         return [t.strip() for t in s.split(\";\") if t.strip()]\n",
    "#     # 单个标签\n",
    "#     return [s]\n",
    "def parse_list_cell(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    return ast.literal_eval(s)\n",
    "    \n",
    "def to_enc_set(items):\n",
    "    out = set()\n",
    "    for it in items:\n",
    "        # key = map_long.get(str(it).strip().lower())\n",
    "        key = str(it).strip().lower()\n",
    "        if key in (\"e\", \"n\", \"c\"):\n",
    "            out.add(key)\n",
    "    return out\n",
    "\n",
    "# 将各种写法映射为 e/n/c\n",
    "map_long = {\n",
    "    \"entailment\": \"e\", \"neutral\": \"n\", \"contradiction\": \"c\",\n",
    "    \"e\": \"e\", \"n\": \"n\", \"c\": \"c\"\n",
    "}\n",
    "\n",
    "\n",
    "# cnt2 = Counter()     \n",
    "# cnt3 = Counter()     \n",
    "# cnt4 = Counter()\n",
    "overlap_23 = Counter()  # 两列里相同的标签计数（逐行一次）\n",
    "overlap_24= Counter() \n",
    "\n",
    "total_col2 = Counter()\n",
    "total_col3 = Counter()\n",
    "total_col4 = Counter()\n",
    "\n",
    "for items2, items3, items4 in zip(\n",
    "    df[\"llm_validated\"].apply(parse_list_cell),\n",
    "    df[\"varierr_validated\"].apply(parse_list_cell),\n",
    "    df[\"chaos_validated\"].apply(parse_list_cell)\n",
    "):\n",
    "    # set2 = to_enc_set(items2)\n",
    "    # set3 = to_enc_set(items3)\n",
    "    # set4 = to_enc_set(items4)\n",
    "    # print(items2)\n",
    "    set2 = {map_long.get(it) for it in items2 if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "    set3 = {map_long.get(it) for it in items3 if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "    set4 = {map_long.get(it) for it in items4 if map_long.get(it) in (\"e\", \"n\", \"c\")}\n",
    "\n",
    "    for lab in (set2 & set3):\n",
    "        overlap_23[lab] += 1\n",
    "\n",
    "    for lab in (set2 & set4):\n",
    "        overlap_24[lab] += 1\n",
    "\n",
    "    for lab in set2:\n",
    "        total_col2[lab] += 1\n",
    "    for lab in set3:\n",
    "        total_col3[lab] += 1\n",
    "    for lab in set4:\n",
    "        total_col4[lab] += 1\n",
    "\n",
    "print(\"LLM\")\n",
    "print(f\"  e: {total_col2.get('e',0)}  n: {total_col2.get('n',0)}  c: {total_col2.get('c',0)}\")\n",
    "\n",
    "print(\"llm和varierr：\")\n",
    "print(f\"  e: {overlap_23.get('e',0)}  n: {overlap_23.get('n',0)}  c: {overlap_23.get('c',0)}\")\n",
    "\n",
    "print(\"llm和chaos：\")\n",
    "print(f\"  e: {overlap_24.get('e',0)}  n: {overlap_24.get('n',0)}  c: {overlap_24.get('c',0)}\")\n",
    "\n",
    "\n",
    "print(\"VariErr：\")\n",
    "print(f\"  e: {total_col3.get('e',0)}  n: {total_col3.get('n',0)}  c: {total_col3.get('c',0)}\")\n",
    "\n",
    "print(\"Chaos\")\n",
    "print(f\"  e: {total_col4.get('e',0)}  n: {total_col4.get('n',0)}  c: {total_col4.get('c',0)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum is 1500\n"
     ]
    }
   ],
   "source": [
    "## how many of the E/N/C labels have explanation\n",
    "\n",
    "import json\n",
    "\n",
    "def check_jsonl(file_path):\n",
    "    sum = 0\n",
    "    required_labels = {\"e\", \"n\", \"c\"}\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            explanations = data.get(\"generated_explanations\", [])\n",
    "            # 取出每个解释的 label（在列表最后一个元素）\n",
    "            labels = {item[-1] for item in explanations if isinstance(item, list) and item}\n",
    "            missing = required_labels - labels\n",
    "            if missing:\n",
    "                print(f\"ID: {data.get('id')} 缺少: {', '.join(missing)}\")\n",
    "            sum += len(labels)\n",
    "        print(\"sum is\", sum)\n",
    "\n",
    "check_jsonl(\"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/qwen_72b_generation_raw.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Summary (validated only, sample-level) =====\n",
      "总样本数: 2.834\n",
      "完整样本数 (含 e/n/c 且均为 validated): 419\n",
      "多少个样本包含各label: {'c': 462, 'n': 493, 'e': 462}\n"
     ]
    }
   ],
   "source": [
    "## how many are validated\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def check_jsonl_validated(file_path, required_labels=(\"e\", \"n\", \"c\")):\n",
    "    required_labels = set(required_labels)\n",
    "    sample_label_counter = Counter()   # 按样本统计多少个instance包含某label\n",
    "    complete_count = 0\n",
    "    total_samples = 0\n",
    "    missing_list = []                  # [(id, [missing labels])]\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            # total_samples += 1\n",
    "            data = json.loads(line)\n",
    "            exps = data.get(\"generated_explanations\", [])\n",
    "\n",
    "            # 每个 instance 的 validated label set\n",
    "            validated_labels = set()\n",
    "            for item in exps:\n",
    "                if isinstance(item, list) and len(item) >= 3:\n",
    "                    label = item[1]\n",
    "                    status = str(item[2]).strip().lower()\n",
    "                    if status == \"validated\":\n",
    "                        validated_labels.add(label)\n",
    "\n",
    "            # 按样本统计覆盖情况\n",
    "            for lbl in validated_labels:\n",
    "                sample_label_counter[lbl] += 1\n",
    "            total_samples += len(validated_labels)\n",
    "\n",
    "            # 判断是否完整\n",
    "            missing = sorted(required_labels - validated_labels)\n",
    "            if missing:\n",
    "                missing_list.append((data.get(\"id\"), missing))\n",
    "            else:\n",
    "                complete_count += 1\n",
    "\n",
    "    # 打印汇总\n",
    "    print(\"\\n===== Summary (validated only, sample-level) =====\")\n",
    "    print(\"总样本数:\", total_samples/500)\n",
    "    print(\"完整样本数 (含 e/n/c 且均为 validated):\", complete_count)\n",
    "    print(\"多少个样本包含各label:\", dict(sample_label_counter))\n",
    "\n",
    "    return missing_list\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/with_validation_0.8.jsonl\"\n",
    "    missing = check_jsonl_validated(path)\n",
    "    # print(missing)  # 如果需要看缺失详情"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"id\": \"73260n\", \"context\": \"The disputes among nobles were not the first concern of ordinary French citizens.\", \"statement\": \"Ordinary French citizens were not concerned with the disputes among nobles.\", \"entailment\": [{\"annotator\": 1, \"id\": \"1456-entailment-1\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": false}, {\"annotator\": 2, \"makes_sense\": false}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"In the context, \\\"The first concern\\\" can be read as a pars pro toto which would mean that it was really no concern at all.\", \"self_corrected\": true}], \"neutral\": [{\"annotator\": 0, \"id\": \"1456-neutral-1\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"\\\"not the first concern\\\" doesn't mean not the concern. The statement can be true or false.\", \"self_corrected\": false}, {\"annotator\": 1, \"id\": \"1456-neutral-2\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"It might not be the most important concern to the French citizens, but maybe an important concern after all.\", \"self_corrected\": false}, {\"annotator\": 2, \"id\": \"1456-neutral-3\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"The disputes among nobles could be second concern of ordinary French citizens.\", \"self_corrected\": false}], \"contradiction\": [{\"annotator\": 3, \"id\": \"1456-contradiction-1\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": false}, {\"annotator\": 1, \"makes_sense\": false}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"They could be concerned. But it is not their first concern\", \"self_corrected\": false}], \"idk\": [], \"label_count_round_1\": {\"contradiction\": 1.0, \"entailment\": 1.0, \"neutral\": 3.0}, \"label_count_round_2\": {\"contradiction\": 1.0, \"entailment\": null, \"neutral\": 3.0}, \"label_set_round_1\": [\"contradiction\", \"neutral\", \"entailment\"], \"label_set_round_2\": [\"neutral\", \"contradiction\"], \"error_labels\": [\"entailment\"], \"has_ambiguity\": true, \"chaosnli_labels\": {\"n\": 18, \"e\": 72, \"c\": 10}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Summary =====\n",
      "总样本数: 500\n",
      "Round 1 label 分布: 878\n",
      "Round 2 label 分布: 749\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def count_label_sets(file_path):\n",
    "    round1_counter = 0\n",
    "    round2_counter = 0\n",
    "    total = 0\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            total += 1\n",
    "            data = json.loads(line)\n",
    "\n",
    "            # 统计 round_1\n",
    "            for lbl in data.get(\"label_set_round_1\", []):\n",
    "                round1_counter += 1\n",
    "\n",
    "            # 统计 round_2\n",
    "            for lbl in data.get(\"label_set_round_2\", []):\n",
    "                round2_counter += 1\n",
    "\n",
    "    print(\"\\n===== Summary =====\")\n",
    "    print(\"总样本数:\", total)\n",
    "    print(\"Round 1 label 分布:\", round1_counter)\n",
    "    print(\"Round 2 label 分布:\", round2_counter)\n",
    "\n",
    "    return round1_counter, round2_counter\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"/Users/phoebeeeee/ongoing/LLM_AED/dataset/varierr/varierr.json\"\n",
    "    r1, r2 = count_label_sets(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_merged_errors(model_jsonl, varierr_json, out_csv):\n",
    "    data_a = {}\n",
    "    with open(model_jsonl, \"r\", encoding=\"utf-8\") as f:\n",
    "        data_a = {json.loads(line)[\"id\"]: json.loads(line) for line in f}\n",
    "\n",
    "    data_b = {}\n",
    "    with open(varierr_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        data_b = {json.loads(line)[\"id\"]: json.loads(line) for line in f}\n",
    "\n",
    "    all_ids = list(data_a.keys())\n",
    "\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"id\", \"llm_validated\", \"varierr_validated\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for id_ in all_ids:\n",
    "            if id_ not in data_b:\n",
    "                print(f\"ID {id_} not found in VariErr dataset.\")\n",
    "\n",
    "            row = {\n",
    "                \"id\": id_,\n",
    "                \"llm_validated\": json.dumps(data_a.get(id_, {}).get(\"label_set_round_2\", []), ensure_ascii=False),\n",
    "                \"varierr_validated\": json.dumps(data_b.get(id_, {}).get(\"label_set_round_2\", []), ensure_ascii=False),\n",
    "            }\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def write_merged_errors_batch(model_dir, varierr_json, out_dir=None, suffix=\"_merged_validation.csv\"):\n",
    "    model_dir = Path(model_dir)\n",
    "    varierr_json = Path(varierr_json)\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    abb_dict = {\"entailment\": \"e\", \"contradiction\": \"c\", \"neutral\": \"n\"}\n",
    "\n",
    "    # 读取 VariErr\n",
    "    with varierr_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data_b = {json.loads(line)[\"id\"]: json.loads(line) for line in f}\n",
    "\n",
    "    # 遍历 model_dir 下所有 .jsonl\n",
    "    for model_jsonl in sorted(model_dir.glob(\"*.jsonl\")):\n",
    "        out_csv = out_dir / f\"{model_jsonl.stem}{suffix}\"\n",
    "\n",
    "        # 读取 model_jsonl\n",
    "        with model_jsonl.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            data_a = {json.loads(line)[\"id\"]: json.loads(line) for line in f}\n",
    "\n",
    "        all_ids = list(data_a.keys())\n",
    "\n",
    "        with out_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(\n",
    "                f, fieldnames=[\"id\", \"llm_validated\", \"varierr_validated\", \"chaos_validated\"]\n",
    "            )\n",
    "            writer.writeheader()\n",
    "\n",
    "            for id_ in all_ids:\n",
    "                if id_ not in data_b:\n",
    "                    print(f\"[{model_jsonl.name}] ID {id_} not found in VariErr dataset.\")\n",
    "\n",
    "                # VariErr 的 Round 2 labels（映射为 e/n/c）\n",
    "                raw_labels = data_b.get(id_, {}).get(\"label_set_round_2\", [])\n",
    "                mapped_labels = [abb_dict.get(lbl, lbl) for lbl in raw_labels]\n",
    "\n",
    "                # ChaosNLI validated （阈值 >=20）\n",
    "                chaos_dict = data_b.get(id_, {}).get(\"chaosnli_labels\", {})\n",
    "                chaos_validated = [lbl for lbl, val in chaos_dict.items() if val >= 20]\n",
    "\n",
    "                row = {\n",
    "                    \"id\": id_,\n",
    "                    \"llm_validated\": json.dumps(\n",
    "                        data_a.get(id_, {}).get(\"label_set_round_2\", []), ensure_ascii=False\n",
    "                    ),\n",
    "                    \"varierr_validated\": json.dumps(mapped_labels, ensure_ascii=False),\n",
    "                    \"chaos_validated\": json.dumps(chaos_validated, ensure_ascii=False),\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "\n",
    "        print(f\"Written: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.1_merged_validation.csv\n",
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.2_merged_validation.csv\n",
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.3_merged_validation.csv\n",
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.4_merged_validation.csv\n",
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.5_merged_validation.csv\n",
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.6_merged_validation.csv\n",
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.7_merged_validation.csv\n",
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.8_merged_validation.csv\n",
      "Written: /Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap/with_validation_0.9_merged_validation.csv\n"
     ]
    }
   ],
   "source": [
    "write_merged_errors_batch(\n",
    "    model_dir=\"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/threshold\",\n",
    "    varierr_json=\"/Users/phoebeeeee/ongoing/LLM_AED/dataset/varierr/varierr.json\",\n",
    "    out_dir=\"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/validated_overlap\"  # 或者指定输出目录；None 则写到 model_dir/merged_csv/\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"id\": \"61429c\", \"context\": \"In this enclosed but airy building, you'll find ladies with large machetes expertly chopping off hunks of kingfish, tuna, or shark for eager buyers.\", \"statement\": \"You'll find small lepers chopping of chunks of tuna, its the only place they can work.\", \"entailment\": [], \"neutral\": [{\"annotator\": 0, \"id\": \"1265-neutral-1\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"The context doesn't mention whether the ladies are small lepers and whether its the only place they can work.\", \"self_corrected\": false}, {\"annotator\": 1, \"id\": \"1265-neutral-2\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"The context does not say anything about lepers or where they could work.\", \"self_corrected\": false}, {\"annotator\": 2, \"id\": \"1265-neutral-3\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"\\\"Small lepers\\\" don't have to be \\\"ladies\\\"; we don't know whether \\\"small lepers\\\" can find other jobs.\", \"self_corrected\": false}, {\"annotator\": 3, \"id\": \"1265-neutral-4\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"Lepers and the only place to work at are not mentioned\", \"self_corrected\": false}], \"contradiction\": [], \"idk\": [], \"label_count_round_1\": {\"contradiction\": null, \"entailment\": null, \"neutral\": 4.0}, \"label_count_round_2\": {\"contradiction\": null, \"entailment\": null, \"neutral\": 4.0}, \"label_set_round_1\": [\"neutral\"], \"label_set_round_2\": [\"neutral\"], \"error_labels\": [], \"has_ambiguity\": false, \"chaosnli_labels\": {\"n\": 41, \"c\": 57, \"e\": 2}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/chase/llama_8b_chase/with_validation_0.7.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[476]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mwrite_merged_errors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_jsonl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/chase/llama_8b_chase/with_validation_0.7.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvarierr_json\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/phoebeeeee/ongoing/LLM_AED/dataset/varierr/varierr.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/all/qwen_72b_all/validated_overlap/with_validation_0.7_merged_validation.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[456]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mwrite_merged_errors\u001b[39m\u001b[34m(model_jsonl, varierr_json, out_csv)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite_merged_errors\u001b[39m(model_jsonl, varierr_json, out_csv):\n\u001b[32m      2\u001b[39m     data_a = {}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_jsonl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      4\u001b[39m         data_a = {json.loads(line)[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m]: json.loads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f}\n\u001b[32m      6\u001b[39m     data_b = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/ma/lib/python3.12/site-packages/IPython/core/interactiveshell.py:327\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/chase/llama_8b_chase/with_validation_0.7.jsonl'"
     ]
    }
   ],
   "source": [
    "write_merged_errors(\n",
    "    model_jsonl=\"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/chase/llama_8b_chase/with_validation_0.7.jsonl\",\n",
    "    varierr_json=\"/Users/phoebeeeee/ongoing/LLM_AED/dataset/varierr/varierr.json\",\n",
    "    out_csv=\"/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/all/qwen_72b_all/validated_overlap/with_validation_0.7_merged_validation.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove LLM-detected errors from original VariErr\n",
    "\n",
    "import json\n",
    "\n",
    "varierr_file = '/Users/phoebeeeee/ongoing/LLM_AED/dataset/varierr/varierr.json'\n",
    "model_file = '/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/with_validation_0.8.jsonl'\n",
    "output_file = '/Users/phoebeeeee/ongoing/LLM_AED/new_processing/validation_result/original/qwen_72b_original/varierr_without_qwen_72b.json'\n",
    "\n",
    "with open(varierr_file, 'r', encoding='utf-8') as f:\n",
    "    varierr_data = {json.loads(line)['id']: json.loads(line) for line in f}\n",
    "\n",
    "with open(model_file, 'r', encoding='utf-8') as f:\n",
    "    model_data = {json.loads(line)['id']: json.loads(line) for line in f}\n",
    "label_map = {'e': 'entailment', 'n': 'neutral', 'c': 'contradiction'}\n",
    "\n",
    "merged = []\n",
    "\n",
    "for uid, var_entry in varierr_data.items():\n",
    "    model_entry = model_data.get(uid, {})\n",
    "\n",
    "    var_entry.pop('entailment', None)\n",
    "    var_entry.pop('contradiction', None)\n",
    "    var_entry.pop('neutral', None)\n",
    "    var_entry.pop('idk', None)\n",
    "\n",
    "    if 'error' in model_entry:\n",
    "        error_raw = model_entry['error']\n",
    "        error_mapped = [label_map.get(lbl, lbl) for lbl in error_raw]\n",
    "        var_entry['error_llm'] = error_mapped\n",
    "    if 'not_validated_exp' in model_entry:\n",
    "        var_entry['not_validated_exp_llm'] = model_entry['not_validated_exp']\n",
    "\n",
    "    original_labels = set(var_entry.get('label_set_round_1', []))\n",
    "    error_labels = set(var_entry.get('error_llm', []))\n",
    "    label_set_llm = sorted(original_labels - error_labels)\n",
    "\n",
    "    var_entry['label_set_llm'] = label_set_llm\n",
    "    merged.append(var_entry)\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as out:\n",
    "    for item in merged:\n",
    "        json.dump(item, out, ensure_ascii=False)\n",
    "        out.write('\\n')\n",
    "\n",
    "print(f\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"id\": \"49807n\", \"context\": \"The next year, he built himself a palace, Iolani, which can still be toured in Honolulu.\", \"statement\": \"Lolani was built in only 1 year.\", \"entailment\": [{\"annotator\": 1, \"id\": \"362-entailment-1\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"\\\"The next year\\\" can be interpreted as indicating that the building of Lolani was concluded in the same year.\", \"self_corrected\": false}, {\"annotator\": 3, \"id\": \"362-entailment-2\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"It was built \\\"the next year\\\".\", \"self_corrected\": false}], \"neutral\": [{\"annotator\": 0, \"id\": \"362-neutral-1\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"The context makes no mention of how long it took to build lolani.\", \"self_corrected\": false}, {\"annotator\": 1, \"id\": \"362-neutral-2\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": true}], \"label_correction\": false, \"reason\": \"\\\"The next year\\\" can be interpreted as indicating that the building of Lolani was started in the next year.\", \"self_corrected\": false}, {\"annotator\": 2, \"id\": \"362-neutral-3\", \"judgments\": [{\"annotator\": 0, \"makes_sense\": true}, {\"annotator\": 1, \"makes_sense\": true}, {\"annotator\": 2, \"makes_sense\": true}, {\"annotator\": 3, \"makes_sense\": false}], \"label_correction\": false, \"reason\": \"We don't know when did Lolani start to be built.\", \"self_corrected\": false}], \"contradiction\": [], \"idk\": [], \"label_count_round_1\": {\"contradiction\": null, \"entailment\": 2.0, \"neutral\": 3.0}, \"label_count_round_2\": {\"contradiction\": null, \"entailment\": 2.0, \"neutral\": 3.0}, \"label_set_round_1\": [\"neutral\", \"entailment\"], \"label_set_round_2\": [\"neutral\", \"entailment\"], \"error_labels\": [], \"has_ambiguity\": true, \"chaosnli_labels\": {\"n\": 67, \"e\": 28, \"c\": 5}}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
