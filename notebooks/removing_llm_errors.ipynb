{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove LLM-detected errors from original VariErr\n",
    "\n",
    "import json\n",
    "\n",
    "varierr_file = '../varierr.json'\n",
    "model_file = '../llama33_70b_explanation_with_validation_count.jsonl'\n",
    "output_file = '../varierr_without_70b.json'\n",
    "\n",
    "with open(varierr_file, 'r', encoding='utf-8') as f:\n",
    "    varierr_data = {json.loads(line)['id']: json.loads(line) for line in f}\n",
    "\n",
    "with open(model_file, 'r', encoding='utf-8') as f:\n",
    "    model_data = {json.loads(line)['id']: json.loads(line) for line in f}\n",
    "label_map = {'e': 'entailment', 'n': 'neutral', 'c': 'contradiction'}\n",
    "\n",
    "merged = []\n",
    "\n",
    "for uid, var_entry in varierr_data.items():\n",
    "    model_entry = model_data.get(uid, {})\n",
    "\n",
    "    var_entry.pop('entailment', None)\n",
    "    var_entry.pop('contradiction', None)\n",
    "    var_entry.pop('neutral', None)\n",
    "    var_entry.pop('idk', None)\n",
    "\n",
    "    if 'error' in model_entry:\n",
    "        error_raw = model_entry['error']\n",
    "        error_mapped = [label_map.get(lbl, lbl) for lbl in error_raw]\n",
    "        var_entry['error_llm'] = error_mapped\n",
    "    if 'not_validated_exp' in model_entry:\n",
    "        var_entry['not_validated_exp_llm'] = model_entry['not_validated_exp']\n",
    "\n",
    "    original_labels = set(var_entry.get('label_set_round_1', []))\n",
    "    error_labels = set(var_entry.get('error_llm', []))\n",
    "    label_set_llm = sorted(original_labels - error_labels)\n",
    "\n",
    "    var_entry['label_set_llm'] = label_set_llm\n",
    "    merged.append(var_entry)\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as out:\n",
    "    for item in merged:\n",
    "        json.dump(item, out, ensure_ascii=False)\n",
    "        out.write('\\n')\n",
    "\n",
    "print(f\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "input_path = \"../varierr_without_70b.json\"\n",
    "output_path = \"../varierr_without_70b_dist.json\"\n",
    "\n",
    "def convert_label_list_to_dist(label_list):\n",
    "    counter = Counter(label_list or [])\n",
    "    e = counter.get(\"entailment\", 0)\n",
    "    n = counter.get(\"neutral\", 0)\n",
    "    c = counter.get(\"contradiction\", 0)\n",
    "\n",
    "    total = e + n + c\n",
    "    if total == 0:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    return [e / total, n / total, c / total] \n",
    "\n",
    "with open(input_path, \"r\") as infile, \\\n",
    "     open(output_path, \"w\") as outfile:\n",
    "\n",
    "    for line in infile:\n",
    "        item = json.loads(line)\n",
    "\n",
    "        label_list = item.get(\"label_set_llm\")\n",
    "        if label_list:\n",
    "            item[\"label\"] = convert_label_list_to_dist(label_list)\n",
    "        else:\n",
    "            item[\"label\"] = [0.0, 0.0, 0.0]\n",
    "\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_label_dist(chaos_dict):\n",
    "   \n",
    "    label_order = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    values = [(chaos_dict.get(k) or 0.0) for k in label_order] \n",
    "    total = sum(values)\n",
    "    if total == 0:\n",
    "        return [0.0] * 3\n",
    "    return [v / total for v in values]\n",
    "\n",
    "\n",
    "def process_file(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in tqdm(fin, desc=f\"Processing {input_path}\"):\n",
    "            raw = json.loads(line)\n",
    "            out = {\n",
    "                \"uid\": raw.get(\"id\", raw.get(\"uid\")),\n",
    "                \"premise\": raw.get(\"context\"),\n",
    "                \"hypothesis\": raw.get(\"statement\"),\n",
    "                \"label\": raw.get(\"label\")\n",
    "            }\n",
    "            fout.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = \"../varierr_without_70b_dist.json\"\n",
    "    output_path = \"../varierr_without_70b_cleaned.json\"\n",
    "    process_file(input_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
