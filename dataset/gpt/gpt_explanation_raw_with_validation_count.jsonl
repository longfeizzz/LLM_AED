{"id": "23751e", "premise": "Part of the reason for the difference in pieces per possible delivery may be due to the fact that five percent of possible residential deliveries are businesses, and it is thought, but not known, that a lesser percentage of possible deliveries on rural routes are businesses.", "hypothesis": "It is thought, but not known, that a lesser percentage of possible deliveries on rural routes are businesses, and part of the reason for the difference in pieces per possible delivery, may be due to the fact that five percent of possible residential deliveries are businesses.", "generated_explanations": [["The statement is a direct restatement of information given in the context, with no factual difference between the two.", "e", "validated"], ["Both the context and the statement describe the same hypothesis: a lower proportion of businesses among rural deliveries and a five percent business share among possible residential deliveries may explain differences in pieces per delivery.", "e", "validated"], ["The statement repeats information from the context without introducing any new claim to evaluate, making the inference relationship undetermined.", "n", "validated"], ["The context states that it is thought, but not known, about the lesser percentage of rural businesses, and the statement reproduces this uncertainty, so there is no definitive factual basis to establish a true or false relationship.", "n", "validated"], ["Causal connections (“part of the reason... may be due to...”) in both the context and the statement are expressed as possibilities and not certainties, making inference status undetermined.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 3}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "61429c", "premise": "In this enclosed but airy building, you'll find ladies with large machetes expertly chopping off hunks of kingfish, tuna, or shark for eager buyers.", "hypothesis": "You'll find small lepers chopping of chunks of tuna, its the only place they can work.", "generated_explanations": [["The context mentions \"ladies with large machetes\" but does not specify anything about \"small lepers.\"", "n", "validated"], ["The context does not address whether this is the only place a particular group (such as lepers) can work.", "n", "validated"], ["The context describes general fishmongering activity but does not provide information about who is permitted or able to work there beyond the described \"ladies.\"", "n", "validated"], ["The context describes \"ladies with large machetes\" as the people chopping fish, not \"small lepers.\"", "c", "validated"], ["The statement claims \"it's the only place they can work,\" but the context provides no information about employment restrictions or exclusivity for lepers.", "c", "validated"], ["The context mentions the chopping of \"kingfish, tuna, or shark,\" but does not restrict to only tuna.", "c", "not_validated"], ["The context does not mention leprosy or lepers at all.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 4}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "54811c", "premise": "The park on the hill of Monte makes a good playground, while the ride down in a wicker toboggan is straight out of an Old World theme park (though surely tame for older kids).", "hypothesis": "the park on the Hill of Monte is only for children.", "generated_explanations": [["The context mentions the park \"makes a good playground,\" but does not specify it is exclusively for children.", "n", "validated"], ["The context references both playground and an activity for \"older kids,\" implying multiple age groups may use the park or its features.", "n", "validated"], ["The context does not specify that the park is exclusively for children; it only mentions that it makes a good playground, which can include people of various ages.", "c", "validated"], ["The ride down in a wicker toboggan being \"tame for older kids\" implies that both children and older individuals can participate, suggesting the park is not solely for children.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "12601n", "premise": "I touched my palm to his mutilated cheek, and tried to stem my instinctive revulsion.", "hypothesis": "You could see where the bear had scratched across his cheek.", "generated_explanations": [["The use of the word \"mutilated\" suggests an injury consistent with severe trauma, such as scratches from a bear.", "e", "not_validated"], ["The description implies visible damage to the cheek, which aligns with the idea that scratches from a bear would be apparent.", "e", "validated"], ["The context mentions the cheek is \"mutilated\" but does not specify the cause of the injury.", "n", "validated"], ["There is no mention of a bear or any description of the specific pattern or source of the wounds.", "n", "validated"], ["The context does not mention a bear or any cause of the mutilation, so there is no evidence that a bear scratched his cheek.", "c", "validated"], ["The context only refers to the cheek as \"mutilated,\" without specifying the nature or appearance of the injury, so it is not confirmed that scratches are visible.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "38477c", "premise": "She wears either revealing clothes or professional clothes (or perhaps both).", "hypothesis": "She only wears short skirts.", "generated_explanations": [["The context allows for professional clothes, which are not necessarily short skirts, so it is undetermined if she only wears short skirts.", "n", "validated"], ["The context mentions \"revealing clothes or professional clothes (or perhaps both)\" but does not specify the types of clothes within those categories, so it is unclear if all are short skirts.", "n", "validated"], ["\"Only wears short skirts\" is a stronger claim than the context provides, as the context allows for a variety of clothing within the categories given.", "n", "validated"], ["The context allows for professional clothes, which are not necessarily short skirts, so she may wear other types of clothing.", "c", "validated"], ["The context mentions the possibility of revealing clothes, but \"revealing\" does not exclusively mean \"short skirts,\" so other revealing clothes could be worn.", "c", "validated"], ["The word \"only\" in the statement conflicts with the context's implication that she has multiple options for clothing style.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "1735n", "premise": "that doesn't seem fair does it", "hypothesis": "That might possibly be fair.", "generated_explanations": [["The context expresses doubt or skepticism about fairness, which leaves open the possibility that fairness is still being considered or debated.", "e", "not_validated"], ["The statement introduces uncertainty (“might possibly”), acknowledging that although it seems unfair, it could still be fair from another perspective.", "e", "not_validated"], ["The context expresses doubt or disagreement about fairness, but does not provide objective information about the situation’s fairness, leaving open the possibility that it could still be fair under different interpretations.", "n", "validated"], ["The context conveys a subjective perception, which does not rule out alternative perspectives or additional facts that could justify the statement.", "n", "validated"], ["The context explicitly states that something does not seem fair, directly contradicting the statement's suggestion that it might be fair.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "7449e", "premise": "In 1982, Wallace won his last race for governor with a quarter of the black votes cast in the Democratic primary, a fact alluded to in a written epilogue at the end of the film.", "hypothesis": "Wallace was reelected as governor.", "generated_explanations": [["Wallace won his last race for governor, indicating he was elected to the position again.", "e", "validated"], ["The context states Wallace won his last race for governor, but does not specify if this resulted in being reelected or if it was a non-consecutive term.", "n", "validated"], ["The context refers specifically to the Democratic primary and does not confirm victory in the general election.", "n", "validated"], ["The context does not clarify if Wallace was the incumbent governor at the time, so winning may not indicate reelection.", "n", "validated"], ["The context only states that Wallace won his last race for governor, not that he was actually reelected; it does not specify whether he was already governor before this race.", "c", "validated"], ["\"Last race for governor\" could refer to an unsuccessful attempt or a primary victory rather than an actual reelection to office.", "c", "validated"], ["Winning votes in the Democratic primary does not guarantee winning the general election and becoming governor.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "24385e", "premise": "farmworkers conducted by the U.S.", "hypothesis": "Some farm laborers were sampled.", "generated_explanations": [["The term \"farmworkers\" includes \"farm laborers\" as a subset, so sampling farmworkers implies that some farm laborers were sampled.", "e", "validated"], ["The use of \"conducted by the U.S.\" suggests an official study or survey, supporting that a sample of individuals from the broader group, including farm laborers, was taken.", "e", "validated"], ["The context does not specify whether farm laborers were included among the farmworkers surveyed.", "n", "validated"], ["The term \"farmworkers\" in the context may refer to a broader or different group than \"farm laborers\" in the statement.", "n", "validated"], ["The context does not explicitly mention that any individuals were actually sampled, only that something was conducted.", "n", "validated"], ["It is unclear whether the survey was intended to represent all farmworkers or only a specific subset, which may or may not include farm laborers.", "n", "validated"], ["The context specifies \"farmworkers\" but does not indicate that any were sampled.", "c", "validated"], ["The context mentions a survey was conducted, but it does not explicitly state that any farm laborers were included in the sample.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "49807n", "premise": "The next year, he built himself a palace, Iolani, which can still be toured in Honolulu.", "hypothesis": "Lolani was built in only 1 year.", "generated_explanations": [["The phrase \"the next year, he built himself a palace, Iolani,\" suggests that the construction occurred within a single year.", "e", "validated"], ["The context only states that the palace was built \"the next year,\" but does not specify whether the construction took exactly one year, started and finished within that year, or if it simply began or ended that year.", "n", "validated"], ["There is no information given about how long the construction process took, only about when it was initiated relative to previous events.", "n", "validated"], ["The context states he built Iolani the next year, but does not specify that the construction took only one year; the palace could have taken longer to build.", "c", "validated"], ["The statement refers to \"Lolani,\" which may be a misspelling or different from \"Iolani\" mentioned in the context, so it is unclear if they refer to the same building.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "138448c", "premise": "Indeed, recent economic research suggests that investment in information technology explains most of the acceleration in labor productivity growth-a major component of overall economic growth-since 1995.", "hypothesis": "Investment in the financial sector explains most of the acceleration in labor productivity.", "generated_explanations": [["The context attributes the acceleration in labor productivity growth to investment in information technology, not the financial sector, and does not provide information about the impact of investment in the financial sector.", "n", "validated"], ["The context does not mention the financial sector in relation to labor productivity, so it is unclear whether investment in the financial sector has any explanatory power for productivity acceleration.", "n", "validated"], ["The context attributes the acceleration in labor productivity growth to investment in information technology, not the financial sector.", "c", "validated"], ["The statement incorrectly identifies the financial sector as the primary driver, whereas the context specifies information technology as the cause.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "48454c", "premise": "These revelations were embarrassing to Clinton's opponents, wrote the Washington Post . The Sun-Times quoted Rahm Emanuel, Stephanopoulos' successor, on the  From Day One I always thought this was politically motivated and had politics written all over it; after five years, it is nice to have the truth catch up with the president's political opponents.", "hypothesis": "Clinton's supporters were pleased with how the hearings went.", "generated_explanations": [["Rahm Emanuel, identified as a successor to Stephanopoulos and thus a supporter of Clinton, expressed satisfaction that the truth favored Clinton after five years.", "e", "validated"], ["The revelations were described as embarrassing to Clinton's opponents, implying a positive outcome for Clinton and his supporters.", "e", "validated"], ["The general tone indicates that those aligned with Clinton viewed the hearings as vindicating their position and exposing political motivations of the opposition.", "e", "validated"], ["The context does not mention the overall reaction of Clinton's supporters to the hearings.", "n", "validated"], ["The statement refers to all supporters, but the context only quotes one individual (Rahm Emanuel), who may not represent the views of all supporters.", "n", "validated"], ["The context discusses embarrassment for Clinton's opponents and the opinion of one supporter, but does not explicitly state how the supporters felt about the hearings as a whole.", "n", "validated"], ["The context only mentions that Clinton's opponents were embarrassed, not that Clinton's supporters were pleased.", "c", "validated"], ["The context provides a quote from Rahm Emanuel suggesting vindication but does not explicitly state that supporters were pleased with the hearings as a whole.", "c", "validated"], ["The focus is on the political motivation of the hearings and the embarrassment of opponents, not on the emotional response of Clinton's supporters to the proceedings.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "73260n", "premise": "The disputes among nobles were not the first concern of ordinary French citizens.", "hypothesis": "Ordinary French citizens were not concerned with the disputes among nobles.", "generated_explanations": [["The context states that the disputes among nobles were not the first concern of ordinary French citizens, indicating that these disputes were not a primary issue for them.", "e", "validated"], ["If something is not a first concern for a group, it implies they are not significantly concerned with it, supporting the statement that ordinary French citizens were not concerned with the disputes among nobles.", "e", "validated"], ["Ordinary French citizens may have been somewhat concerned with the disputes among nobles, just not as their primary concern.", "n", "validated"], ["The context only establishes priorities, not total lack of concern, so it is possible ordinary citizens did care about noble disputes to some extent.", "n", "validated"], ["The statement implies complete lack of concern, while the context only establishes that it was not their first concern, leaving open the possibility that it was a secondary or lesser concern.", "n", "validated"], ["Ordinary French citizens may have been concerned with the disputes among nobles, but these were not their primary or first concern.", "c", "validated"], ["The statement implies complete lack of concern, while the context only indicates lesser or secondary concern.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "76219n", "premise": "and i and i may have been the only one that did both because the mentality in Dallas was that you couldn't like both you had to like one and hate the other", "hypothesis": "I did not follow the mentality in Dallas, of liking only one team.", "generated_explanations": [["The speaker states they may have been the only one who liked both, implying they did not adhere to the mentality of liking only one.", "e", "validated"], ["The statement \"you had to like one and hate the other\" describes the prevailing mentality, but the speaker's actions were different as they liked both.", "e", "validated"], ["The context states \"i may have been the only one that did both,\" which suggests but does not confirm that the speaker actually did not follow the Dallas mentality; \"may have been\" introduces uncertainty.", "n", "validated"], ["The context does not explicitly state whether the speaker actually liked both teams or simply considered the possibility.", "n", "validated"], ["The context says \"I may have been the only one that did both,\" which suggests the speaker did not follow the mentality in Dallas.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "10229n", "premise": "The governing statute provides that a committee consisting of the Comptroller General, the Speaker of the House and President Pro Tempore of the Senate, the Majority and Minority leaders, and the Chairmen and Ranking Minority Members of the Senate Governmental Affairs and House Government Reform Committees recommend an individual to the President for appointment.", "hypothesis": "The process is long and will be reformed in the coming years.", "generated_explanations": [["The context does not specify the duration of the appointment process, so it is unclear whether the process is long.", "n", "validated"], ["The context makes no mention of any plans or proposals to reform the process in the coming years.", "n", "validated"], ["There is no information in the context about dissatisfaction or issues with the current process that would suggest a need for reform.", "n", "validated"], ["The context only describes the composition and role of the committee, not the timeline or potential for future changes.", "n", "validated"], ["The context does not provide any information about the duration or length of the appointment process.", "c", "validated"], ["There is no mention in the context of any plans or intentions to reform the process in the coming years.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "99791n", "premise": "Even analysts who had argued for loosening the old standards, by which the market was clearly overvalued, now think it has maxed out for a while.", "hypothesis": "Some analysts wanted to make the old standards less restrictive for investors.", "generated_explanations": [["Analysts argued for loosening the old standards, which implies making them less restrictive for investors.", "e", "validated"], ["The context states that some analysts argued for \"loosening the old standards,\" but it is not specified whether their motivation was specifically to make the standards less restrictive for investors.", "n", "validated"], ["The context does not explicitly mention the identity or intended beneficiaries of the analysts' proposed loosening of standards.", "n", "validated"], ["The context indicates analysts argued for loosening \"the old standards,\" but it does not specify that their motivation was to make them less restrictive for investors; they could have had other reasons for wanting the standards loosened.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "13964e", "premise": "uh plastic is just too easy i mean that's the that's the whole problem with it um have", "hypothesis": "I find plastic to be too easy to use.", "generated_explanations": [["The context asserts that plastic is \"just too easy,\" directly supporting the statement about finding plastic too easy to use.", "e", "validated"], ["The speaker identifies this ease of use as \"the whole problem with it,\" implying personal familiarity and agreement with the statement.", "e", "validated"], ["The context discusses plastic being \"too easy\" but does not specify whether the speaker personally finds it easy to use or is referring to a general property of plastic.", "n", "validated"], ["The context does not make clear if the speaker agrees with or endorses the statement at a personal level; they could be reporting a general sentiment or societal problem.", "n", "validated"], ["The context criticizes the ease of using plastic as a general problem, but does not state the speaker personally finds it too easy to use.", "c", "validated"], ["The context uses \"that's the whole problem with it,\" indicating a critique of society's or people’s general attitude toward plastic, not a personal admission.", "c", "validated"], ["\"I find plastic to be too easy to use\" is an explicit personal statement that is not directly made or implied by the speaker in the context provided.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "66185c", "premise": "The political cleansing that did not happen through the impeachment process leaves Clinton with a great and serious burden.", "hypothesis": "There was no such instance of political cleansing.", "generated_explanations": [["The context explicitly states that political cleansing \"did not happen through the impeachment process,\" indicating its absence.", "e", "validated"], ["The use of the phrase \"that did not happen\" refers directly to political cleansing, confirming that it did not occur.", "e", "validated"], ["The context states that political cleansing did not happen through the impeachment process, but it does not clarify whether political cleansing occurred through other means.", "n", "validated"], ["The phrase \"that did not happen through the impeachment process\" implies the possibility of political cleansing occurring in other forms, so it is undetermined whether there was no such instance at all.", "n", "validated"], ["The context explicitly mentions a \"political cleansing that did not happen,\" implying that an instance of political cleansing was a possibility but did not occur, not that there was no such instance at all.", "c", "validated"], ["The phrase \"did not happen through the impeachment process\" suggests that the concept or attempt at political cleansing existed but failed to materialize in that specific way, rather than being entirely absent.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "65066n", "premise": "Larger ski resorts are 90 minutes away.", "hypothesis": "The largest resort is actually 100 minutes away.", "generated_explanations": [["The largest resort being 100 minutes away is consistent with the statement that larger ski resorts are 90 minutes away, as 100 minutes is still considered within the range of \"larger\" and can be interpreted as \"around\" 90 minutes away.", "e", "not_validated"], ["\"90 minutes away\" could be an approximation, and 100 minutes would fit within a reasonable margin of error for such an estimate.", "e", "not_validated"], ["The context specifies that larger resorts are 90 minutes away, but does not detail the travel time to the largest resort specifically, so it is unclear whether the largest resort follows the same travel time as other larger resorts.", "n", "validated"], ["The description \"larger ski resorts\" could refer to a group of resorts, while \"the largest resort\" may or may not be included in that group or could have a different travel time.", "n", "validated"], ["There is no explicit mention of the travel time to the single largest resort, so it is unknown if it fits within the 90-minute range or is an exception.", "n", "validated"], ["The context only specifies that larger ski resorts are 90 minutes away, not that the largest resort is 100 minutes away.", "c", "not_validated"], ["The statement contradicts the context by claiming a different travel time specifically for the largest resort.", "c", "validated"], ["The context does not mention any resort being 100 minutes away, making the statement unsupported.", "c", "not_validated"], ["\"Larger ski resorts\" could include the largest one, implying it should also be 90 minutes away, not 100.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2, "c": 2}}
{"id": "76020e", "premise": "The city was founded in the third millennium b.c. on the north shore of the bay, and reached a peak during the tenth century b.c. , when it was one of the most important cities in the Ionian Federation the poet Homer was born in S myrna during this period.", "hypothesis": "The city was founded in the third millennium", "generated_explanations": [["The context states the city was founded in the third millennium b.c., which directly supports the statement.", "e", "validated"], ["The context specifies the city was founded in the third millennium b.c., but the statement omits \"b.c.\", so it is unclear whether it refers to the same time period.", "n", "validated"], ["\"Third millennium\" could refer to either b.c. or a.d., and without the qualifier, the statement is ambiguous.", "n", "validated"], ["The statement omits \"b.c.,\" which is a crucial part of the time reference given in the context. Without it, the date could be interpreted as the third millennium a.d., which would be incorrect.", "c", "not_validated"], ["The statement omits the location detail \"on the north shore of the bay,\" which is specified in the context.", "c", "not_validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "83248c", "premise": "Her state is probably to be attributed to the mental shock consequent on recovering her memory.\"", "hypothesis": "It is too bad that she never regained her memory.", "generated_explanations": [["The context states that she recovered her memory, but the statement asserts she never regained it, making the truth of the statement indeterminate without further clarifying information about her memory state.", "n", "validated"], ["The word \"probably\" in the context introduces some uncertainty about whether the memory was fully recovered or only partially regained.", "n", "validated"], ["The context states that she did recover her memory, while the statement claims she never regained it.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "79141n", "premise": "Isn't a woman's body her most personal property?", "hypothesis": "Women's bodies belong to themselves, they should decide what to do with it.", "generated_explanations": [["The context asserts that a woman's body is her most personal property, implying ownership and control by the woman herself.", "e", "validated"], ["If a woman's body is her property, she has the right to make decisions regarding it, supporting the idea that women should decide what to do with their bodies.", "e", "validated"], ["The context questions whether a woman's body is her most personal property but does not explicitly state that it is, leaving ambiguity about the speaker's stance and making it unclear if the statement holds true.", "n", "validated"], ["The context centers on the notion of ownership and personal property but does not directly address autonomy or decision-making, so it is undetermined whether the conclusion about decision rights logically follows.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "97926n", "premise": "General Motors, for instance, lost $460 million to strikes in 1997, but investors treated the costs as a kind of extraordinary charge and valued the company as if the losses had never happened.", "hypothesis": "GM lost a lot of money in labor disputes but was victorious in the end.", "generated_explanations": [["Investors ignored the financial impact of the strikes and continued to value GM highly, suggesting that the company emerged from the situation without lasting negative effects on its valuation.", "e", "validated"], ["The context does not define what \"victorious in the end\" means, so it is unclear whether investors' valuation equates to actual victory for GM.", "n", "validated"], ["The context only discusses how investors valued GM, not the ultimate financial or operational outcomes for the company following the labor disputes.", "n", "validated"], ["There is no information about whether GM recovered the losses or achieved any specific goal related to the labor disputes.", "n", "validated"], ["The statement implies a definitive outcome (\"victorious\"), but the context only provides a snapshot of investor sentiment at a particular time.", "n", "validated"], ["The context does not indicate any kind of \"victory\" for GM; it only states that investors overlooked the losses in their valuation, not that GM won or prevailed in the labor disputes.", "c", "validated"], ["The statement implies a competition or contest with a clear winner, but the context discusses financial loss and investor perception, without any mention of an outcome against another party.", "c", "validated"], ["The context only mentions financial loss due to strikes, not any resolution or favorable result for GM.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 4, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "45957e", "premise": "Bauerstein had been at Styles on the fatal night, and added: \"He said twice: 'That alters everything.' And I've been thinking.", "hypothesis": "The fact that Styles was at Bauerstein changes everything.", "generated_explanations": [["The context states that Bauerstein had been at Styles, not that Styles was at Bauerstein, so it is unclear if the statement is addressing the same facts.", "n", "validated"], ["The statement interprets someone’s reaction (\"That alters everything\") without clarifying what specifically alters everything, making the link ambiguous.", "n", "validated"], ["The context does not specify that the presence of Styles at Bauerstein is relevant or mentioned, leaving the impact of such a fact undetermined.", "n", "validated"], ["The context indicates that Bauerstein was at Styles, not that Styles was at Bauerstein.", "c", "validated"], ["The statement confuses the location and the individuals involved, reversing their roles.", "c", "validated"], ["There is no evidence in the context suggesting that Styles being at Bauerstein would change anything, only that Bauerstein being at Styles was significant.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "24126n", "premise": "The door did not budge.", "hypothesis": "The door was stuck, so it did not move.", "generated_explanations": [["If the door was stuck, it would not move when someone tried to open or close it, which explains why it did not budge.", "e", "validated"], ["The lack of movement described as \"did not budge\" can be caused by the door being stuck.", "e", "not_validated"], ["The context states only that the door did not budge, but does not provide the reason—other possibilities like the door being locked or someone holding it closed are not ruled out.", "n", "validated"], ["The statement assumes the door was stuck, but the context does not confirm this specific cause for the lack of movement.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 1, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "135251n", "premise": "it's like but the time we went to Florida and needed to rent a car you know he believed in it", "hypothesis": "We rented a car while we were in Florida.", "generated_explanations": [["The context mentions a time when they went to Florida and needed to rent a car, which implies that a car was rented during their trip.", "e", "validated"], ["The context only mentions the need to rent a car in Florida, not whether a car was actually rented.", "n", "validated"], ["The context references a belief but does not specify if the action of renting occurred.", "n", "validated"], ["The context only mentions the need to rent a car in Florida, not that a car was actually rented.", "c", "validated"], ["The phrase \"he believed in it\" does not confirm that the rental occurred.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "48223n", "premise": "yeah although i do worry that how easy this one was might be a bad lesson uh to the to the younger people um you know than there is the other generation", "hypothesis": "I do worry that it might be a bad lesson for the kids.", "generated_explanations": [["The speaker expresses concern that the ease of \"this one\" might teach a bad lesson.", "e", "validated"], ["The speaker specifically mentions worries about the impact on \"the younger people,\" which is synonymous with \"kids.\"", "e", "validated"], ["The context refers to \"the younger people\" and \"the other generation,\" which could include but does not explicitly specify \"kids,\" leaving it unclear if \"kids\" are meant.", "n", "validated"], ["The concern expressed in the context is about \"a bad lesson,\" but it is not clear if the lesson is specifically for kids or for a broader group.", "n", "validated"], ["The speaker's worry in the context is connected to the lesson's ease, but the statement does not specify this detail, creating uncertainty about whether both are referring to the same issue.", "n", "validated"], ["The statement refers specifically to \"kids,\" while the context refers to \"the younger people\" and \"the other generation,\" which may imply a broader age group than just children.", "c", "not_validated"], ["The statement omits the specific reason mentioned in the context, which is that the lesson was \"how easy this one was,\" altering the focus of the concern.", "c", "not_validated"], ["The statement simplifies the worry to \"it might be a bad lesson,\" whereas the context highlights concern about the _ease_ providing a potentially bad lesson, not a general concern.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 3}}
{"id": "73518n", "premise": "no North Carolina State", "hypothesis": "North Carolina is a county", "generated_explanations": [["The context only states that \"North Carolina State\" does not exist, but does not specify whether \"North Carolina\" refers to a county, a state, or something else.", "n", "validated"], ["The context does not provide any information about the political or administrative status of \"North Carolina.\"", "n", "validated"], ["The term \"North Carolina\" in the context could refer to something other than a county or state, leaving the statement's truth undetermined.", "n", "validated"], ["North Carolina is a state, not a county.", "c", "validated"], ["There is no entity called \"North Carolina\" that is officially designated as a county.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "16996e", "premise": "In the short term, U.S. consumers will benefit from cheap imports (as will U.S. multinationals that use parts made in East Asian factories).", "hypothesis": "U.S. consumers and factories in East Asia benefit from imports.", "generated_explanations": [["U.S. consumers benefit from cheap imports.", "e", "not_validated"], ["Factories in East Asia benefit by supplying parts to U.S. multinationals, increasing their sales.", "e", "validated"], ["The context specifies that East Asian factories provide parts used by U.S. multinationals but does not state that these factories themselves benefit from imports.", "n", "validated"], ["The context only mentions U.S. consumers benefiting, not directly addressing whether East Asian factories benefit from imports.", "n", "validated"], ["The context states that U.S. consumers and U.S. multinationals benefit, not the factories in East Asia.", "c", "validated"], ["The statement claims factories in East Asia benefit from imports, but the context does not mention them benefiting from imports.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "69815n", "premise": "yeah it's a U S territory and it's just we own it or", "hypothesis": "I used to be great at remembering this type of thing, but now I don't.", "generated_explanations": [["The speaker may be struggling to recall specific information about U.S. territories, despite knowing general facts.", "e", "not_validated"], ["The conversation about ownership and territories may have reminded the speaker of their past ability to remember such details.", "e", "not_validated"], ["The context discusses the status of a territory, while the statement refers to the speaker’s memory ability, so there is no clear informational connection between them.", "n", "validated"], ["The context does not provide any evidence about the speaker’s memory skills or changes therein.", "n", "validated"], ["The statement does not reference or relate specifically to the topic or details in the context.", "n", "validated"], ["The context discusses the status of a U.S. territory, while the statement is about someone's memory ability, making them unrelated.", "c", "validated"], ["There is no information in the context about anyone's past or current memory abilities.", "c", "validated"], ["The statement refers to personal memory, but the context only covers political ownership, not individual cognitive abilities.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "35809n", "premise": "Evaluating the intent of the six principles, we observed that they naturally fell into three distinct sets, which we refer to as critical success factors.", "hypothesis": "All three distinct sets need to be filled in order to be considered successful.", "generated_explanations": [["The context does not specify whether all three sets need to be filled for success; it only mentions that principles fall into three sets called critical success factors.", "n", "validated"], ["The context does not define what \"filled\" means or whether it is a necessary criterion for success.", "n", "validated"], ["The context does not state any requirement or condition for being considered successful.", "n", "validated"], ["The context states that the principles \"naturally fell into three distinct sets,\" but does not mention that all three sets need to be filled or completed to be considered successful.", "c", "validated"], ["The context refers to the sets as \"critical success factors,\" not as requirements that all must be fulfilled for success; it only describes categorization, not necessity.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "30282n", "premise": "wow who can afford that  my God i can't afford to miss a day let alone six", "hypothesis": "It's amazing that some people can afford to miss days from work, whereas I can't even afford to miss one.", "generated_explanations": [["The context expresses amazement at others' ability to afford missing work contrasted with the speaker's inability to miss even a single day, which matches the content of the statement.", "e", "validated"], ["Both the context and statement highlight a financial or personal hardship that prevents the speaker from missing work, while noting that others are in a more comfortable situation.", "e", "validated"], ["The context does not specify whether the speaker is amazed by others being able to miss work, only that they personally cannot afford to miss work.", "n", "validated"], ["The context expresses disbelief or surprise at the possibility of affording time off, but does not explicitly describe it as \"amazing.\"", "n", "validated"], ["There is ambiguity regarding whether the speaker is making a general observation about others or focusing on their own situation.", "n", "validated"], ["The context does not state that some people can afford to miss days from work; it only expresses disbelief at the possibility, not confirmation of its occurrence.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "142430c", "premise": "Flying at a discount should be more dangerous.", "hypothesis": "It's totally safe to take advantage of discounted flying.", "generated_explanations": [["The context suggests a possible increase in danger with discounted flying but does not provide concrete evidence or data about actual safety levels.", "n", "validated"], ["The statement makes an absolute claim about safety, but the context only raises a suspicion or hypothesis without confirming it.", "n", "validated"], ["The actual safety record of discounted flying is not addressed in the context, leaving the truth of the statement indeterminate.", "n", "validated"], ["The context suggests that discounted flying is associated with increased danger, which directly contradicts the statement that it is totally safe.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "127290n", "premise": "The logic of analysis in case studies is the same", "hypothesis": "The logic for the case studies is the same thing as in the data collection.", "generated_explanations": [["The statement may be true if \"data collection\" in this context refers to the procedural logic used within case studies, meaning the approach or reasoning applied during both analysis and data collection in case studies is aligned.", "e", "not_validated"], ["If both analysis and data collection in case studies are governed by an identical underlying logic or methodological framework, the statement holds.", "e", "not_validated"], ["The context asserts similarity in the logic of analysis in case studies but does not mention the logic used in data collection.", "n", "validated"], ["It is unclear whether \"the logic of analysis\" and \"the logic of data collection\" refer to the same process or criteria.", "n", "validated"], ["The statement equates \"case studies\" with \"data collection,\" but the relationship between these two is not specified in the context.", "n", "validated"], ["The context does not clarify if analysis and data collection occur using the same logic.", "n", "validated"], ["The logic of analysis in case studies refers to how data is interpreted or examined, not how data is collected.", "c", "validated"], ["Data collection and data analysis are distinct phases in a case study, each with its own logic and methodology.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "100792c", "premise": "yeah but uh do you have small kids", "hypothesis": "It matters not if children are involved.", "generated_explanations": [["The presence or absence of small kids is irrelevant to the topic under discussion.", "e", "not_validated"], ["The issue being considered applies equally regardless of whether children are present.", "e", "not_validated"], ["Any argument or concern about the situation does not change based on whether children are involved.", "e", "not_validated"], ["The context inquires about the presence of small kids, but does not provide any information on whether children are actually involved, leaving it unclear if their involvement is relevant to the conversation.", "n", "validated"], ["The statement makes a general claim about the (ir)relevance of children being involved, but the context does not specify the topic or reason for discussing small kids, making it impossible to determine if the claim appropriately applies.", "n", "validated"], ["The context suggests that whether someone has small kids is relevant to the conversation, implying that the involvement of children does matter.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 3}}
{"id": "75572n", "premise": "Marriage is an important institution.", "hypothesis": "Marriage is crucial to society.", "generated_explanations": [["Marriage is described as an important institution, and institutions that are important generally play a crucial role in society.", "e", "validated"], ["The context indicates marriage is \"important,\" but it does not specify whether it is specifically \"crucial\" to society, so the degree of importance and its relation to society are not clear.", "n", "validated"], ["The context does not explicitly mention society or societal structures, so the specific impact of marriage on society cannot be determined.", "n", "validated"], ["The context describes marriage as \"important,\" which does not necessarily mean it is \"crucial\"; something can be important without being essential or indispensable.", "c", "validated"], ["The statement claims marriage is \"crucial to society,\" introducing the role of marriage in society broadly, while the context only asserts its general importance, not its societal significance.", "c", "not_validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "22235n", "premise": "yeah really no kidding", "hypothesis": "It's crazy!", "generated_explanations": [["The use of \"yeah really no kidding\" indicates strong agreement or confirmation, which supports the idea that something surprising or \"crazy\" has occurred.", "e", "validated"], ["Both statements express a reaction to something unexpected or unbelievable, reinforcing each other.", "e", "validated"], ["The phrase \"yeah really no kidding\" only expresses agreement or emphasis and does not specifically indicate whether something is \"crazy.\"", "n", "validated"], ["\"It's crazy!\" introduces a subjective evaluation that is not explicitly supported or contradicted by the context.", "n", "validated"], ["The context expresses agreement or acknowledgment without indicating anything surprising or extraordinary, while the statement asserts that something is crazy, which implies a high level of surprise or extremity.", "c", "validated"], ["The phrase \"no kidding\" in the context downplays exaggeration, whereas \"It's crazy!\" exaggerates the situation.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "40486n", "premise": "The Women's Haven, which provides shelter and outreach to domestic-violence victims, already has a full-time attorney.", "hypothesis": "The Haven is a useful resource in the community.", "generated_explanations": [["The Women's Haven provides shelter and outreach services to victims of domestic violence, addressing a critical need in the community.", "e", "validated"], ["The presence of a full-time attorney suggests that The Women's Haven offers legal assistance, which can help victims navigate complex legal situations, increasing its utility to the community.", "e", "validated"], ["Supporting victims of domestic violence contributes to the overall safety and well-being of the community.", "e", "validated"], ["The context provides only information about staffing (having a full-time attorney), but does not directly state or provide evidence about the usefulness of The Women's Haven in the community.", "n", "validated"], ["It is possible to have a full-time attorney without being a useful resource; no impact or effectiveness metrics are given.", "n", "validated"], ["The term \"useful resource\" is subjective and the context does not clarify how the services are received or their effectiveness for the community.", "n", "validated"], ["There is no information about community needs or comparison to other resources, so the actual utility of the Haven is undetermined.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 4}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 4}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "13133n", "premise": "The newspaper publishes just one letter a week from a reader, always with an editorial riposte at the bottom.", "hypothesis": "There are many letters submitted each week, but only one is chosen.", "generated_explanations": [["The statement that only one letter is published each week implies that more than one letter may be submitted, from which one is selected.", "e", "not_validated"], ["The need to \"choose\" one letter suggests the existence of multiple options, i.e., multiple letters submitted.", "e", "validated"], ["Newspapers typically receive more submissions than they publish, and the fact that they feature just one per week implies a selective process.", "e", "validated"], ["The context does not specify how many letters are submitted each week; it only mentions that one letter is published.", "n", "validated"], ["There is no information about whether more than one letter is received by the newspaper, so it is unclear if only one is chosen from many or if only one is submitted.", "n", "validated"], ["The context does not mention whether many letters are submitted each week.", "c", "validated"], ["The context only states that one letter is published, not that one is chosen from many.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "94674c", "premise": "Meanwhile, a site established for the WorldAid '96 Global Expo and Conference on Emergency Relief, which took place last fall, gives you a firsthand glimpse of the frequently crass world of the relief business (note the long list of commercial exhibitors in attendance).", "hypothesis": "WorldAid had a GLobal expo in 2002.", "generated_explanations": [["The context only confirms that WorldAid had a Global Expo in 1996, with no mention of any event in 2002.", "n", "validated"], ["There is no information about whether WorldAid held a Global Expo in subsequent years, including 2002.", "n", "validated"], ["The context specifies that the WorldAid Global Expo and Conference took place \"last fall,\" which indicates it occurred before 2002.", "c", "validated"], ["There is no mention in the context of a WorldAid Global Expo happening in 2002.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "101525c", "premise": "Monday's Question (No.", "hypothesis": "There was a question on Tuesday.", "generated_explanations": [["The context only mentions a question on Monday, giving no information about Tuesday.", "n", "validated"], ["It is possible that no question was asked on Tuesday, but the context does not confirm or deny this.", "n", "validated"], ["The schedule or pattern of questions on other days besides Monday is not specified.", "n", "validated"], ["The context specifies Monday, not Tuesday, so there is no information about a question on Tuesday.", "c", "validated"], ["The statement refers to Tuesday, which is a different day from Monday, and the context does not mention events from Tuesday.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "145495c", "premise": "The students' reaction was swift and contentious, as if their feelings had been hurt.", "hypothesis": "The students reacted with horror.", "generated_explanations": [["The phrase \"as if their feelings had been hurt\" suggests an emotional and negative reaction, which aligns with feelings of horror.", "e", "not_validated"], ["The word \"contentious\" implies a strong, possibly fearful or shocked response, consistent with horror.", "e", "not_validated"], ["A \"swift\" reaction can indicate immediate shock or distress, which are elements of a horrified response.", "e", "not_validated"], ["\"Swift and contentious\" describes the speed and argumentative nature of the reaction but does not specify horror.", "n", "validated"], ["The phrase \"as if their feelings had been hurt\" suggests emotional pain but not necessarily horror.", "n", "validated"], ["There is no explicit mention of fear, shock, or terror, which are components of horror.", "n", "validated"], ["The context describes the students' reaction as swift and contentious, suggesting argument or disagreement, not necessarily horror.", "c", "validated"], ["The context mentions that the students' feelings may have been hurt, which implies emotional pain or offense rather than fear or terror, as suggested by horror.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 3}}
{"id": "93357c", "premise": "So is the salt, drying in the huge, square pans at Las Salinas in the south.", "hypothesis": "Pepper is made wet in Las Salinas.", "generated_explanations": [["The context mentions only salt being dried at Las Salinas, with no information given about pepper or whether it is made wet there.", "n", "validated"], ["There is no indication in the context that pepper is present or processed in any way at Las Salinas.", "n", "validated"], ["The context only mentions salt drying in Las Salinas, not pepper.", "c", "validated"], ["The process described in the context involves drying, not making something wet.", "c", "validated"], ["There is no information in the context about pepper being at Las Salinas.", "c", "not_validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "42388e", "premise": "Daniel took it upon himself to explain a few things.", "hypothesis": "Daniel explained what was happening.", "generated_explanations": [["Daniel took the initiative to explain, which implies he provided information or clarification.", "e", "validated"], ["Explaining \"a few things\" suggests Daniel addressed aspects of what was happening.", "e", "not_validated"], ["The context states that Daniel explained \"a few things,\" but does not specify whether \"what was happening\" was among them.", "n", "validated"], ["\"A few things\" could refer to topics unrelated to what was happening.", "n", "validated"], ["The context does not detail the content or scope of Daniel's explanations.", "n", "validated"], ["The context states Daniel explained \"a few things,\" but does not specify that he explained what was happening.", "c", "validated"], ["\"What was happening\" may not be included among the \"few things\" Daniel chose to explain.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "22587e", "premise": "Classic Castilian restaurant.", "hypothesis": "The restaurant is based off a classic Castilian style.", "generated_explanations": [["A restaurant described as \"Classic Castilian\" suggests it follows traditional elements associated with Castilian (from the Castile region of Spain) cuisine or decor.", "e", "validated"], ["The term \"Classic Castilian restaurant\" implies that the restaurant draws inspiration from or emulates the classic style of Castilian culture.", "e", "validated"], ["The term \"Classic Castilian restaurant\" could refer to the cuisine served rather than the architectural or interior design style, so it's unclear if the restaurant's style is actually based on classic Castilian aesthetics.", "n", "validated"], ["The restaurant may serve classic Castilian cuisine but not have its decor, architecture, or overall style based on Castilian traditions.", "c", "validated"], ["The restaurant might be modern or fusion in design and ambiance, drawing only culinary inspiration from classic Castilian elements.", "c", "validated"], ["The term \"classic Castilian restaurant\" could refer strictly to the type of food offered rather than the overall style or theme of the establishment.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 1, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 1, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "131261n", "premise": "But I'll take up my stand somewhere near, and when he comes out of the building I'll drop a handkerchief or something, and off you go!\"", "hypothesis": "I want you to follow him, so watch for the signal that I give.", "generated_explanations": [["Dropping a handkerchief or something similar is intended as a signal to start following the person.", "e", "validated"], ["The speaker instructs the listener to watch for the signal when the person comes out of the building, indicating that the listener is supposed to follow him after receiving that signal.", "e", "validated"], ["The context describes someone planning to drop a handkerchief or something similar as a signal, but it does not explicitly say that the purpose is for the listener to follow the person who exits the building.", "n", "validated"], ["The context does not specify what action should be taken when the signal is given, only implying that \"off you go\" will occur, leaving the specific action ambiguous.", "n", "validated"], ["It is unclear in the context who is meant to act when the signal is given, so the identity of the person being instructed is not explicitly established.", "n", "not_validated"], ["The context does not directly state that the person who is being watched for is to be followed after the signal, so the intention to follow is not unambiguously confirmed.", "n", "validated"], ["The context suggests that the speaker will give a visual signal (\"drop a handkerchief or something\") when the person comes out of the building, not necessarily that the listener should follow the man, only that action should be taken \"off you go\" which could be interpreted differently.", "c", "not_validated"], ["The statement specifies \"watch for the signal,\" but the context does not explicitly mention watching; it only discusses giving a signal, possibly implying a physical cue rather than needing to be visually observed.", "c", "not_validated"], ["The context does not state directly that the desired action after the signal is to follow the person, only that the listener should go after the signal is given.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"n": 1, "c": 3}}
{"id": "51353c", "premise": "It is not a surprise, either, that Al Pacino chews the scenery in Devil's Advocate . And the idea that if the devil showed up on Earth he'd be running a New York corporate-law firm is also, to say the least, pre-chewed.", "hypothesis": "Nobody expects that the devil would take the form of a lawyer.", "generated_explanations": [["The context states that the idea of the devil running a New York corporate-law firm is \"pre-chewed,\" implying it is a familiar or clichéd idea, not an unexpected one.", "e", "validated"], ["The phrase \"It is not a surprise\" indicates that the devil appearing as a lawyer is not unexpected in the context.", "e", "validated"], ["The context suggests that the idea of the devil taking the form of a lawyer is already familiar or cliché, but it does not specify whether there are people who do or do not expect it, leaving the statement undetermined.", "n", "validated"], ["The context critiques the originality of the idea but does not directly address people's expectations, so it is unclear whether \"nobody expects\" this scenario.", "n", "validated"], ["The context states that the idea of the devil running a corporate law firm is already well-established and familiar, implying that people do expect the devil to take the form of a lawyer.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "10547c", "premise": "He jumped up, planting one hand on the charging horse, and came at the brute with the axe.", "hypothesis": "He swung at the brute with his sword.", "generated_explanations": [["The context mentions the use of an axe, but does not specify if he also had a sword or used one.", "n", "validated"], ["The statement introduces a sword, which is not referenced in the context, so it is unclear if he had one or used it.", "n", "validated"], ["The context states he attacked with an axe, not a sword.", "c", "validated"], ["There is no mention of him holding or using a sword in the context.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "136360e", "premise": "I can FEEL him.\"", "hypothesis": "I can sense his presence.", "generated_explanations": [["\"Feel\" in this context can mean being aware of or perceiving someone's presence, which is synonymous with \"sensing\" their presence.", "e", "validated"], ["Both \"feel\" and \"sense\" can refer to non-physical, intuitive perception rather than physical touch, making the statements equivalent.", "e", "validated"], ["\"Feel\" could refer to physical touch, emotions, or intuition, while \"sense his presence\" specifically refers to an awareness of someone being nearby, which may or may not involve physical or emotional sensation.", "n", "validated"], ["The context does not specify what \"feel\" means, so it is unclear if the person is referring to sensing presence or something else (e.g., feeling emotions associated with him).", "n", "validated"], ["\"Feel\" can refer to physical contact, while \"sense his presence\" refers to an awareness without direct physical interaction.", "c", "not_validated"], ["\"Feel him\" could mean perceiving emotion or energy during a conversation, without implying awareness of physical presence.", "c", "not_validated"], ["The context of \"FEEL\" may indicate literal tactile sensation, not an intuitive sensing of someone being nearby.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 3}}
{"id": "113193n", "premise": "of course you could annex Cuba but they wouldn't like that a bit", "hypothesis": "Cubans would go up in arms if we tried to annex Cuba.", "generated_explanations": [["The context states that Cubans \"wouldn't like\" the annexation, implying strong disapproval.", "e", "not_validated"], ["The phrase \"wouldn't like that a bit\" suggests a reaction of significant resistance or hostility, which supports the idea of them taking up arms.", "e", "validated"], ["The context states that Cubans \"wouldn't like that a bit,\" but it does not specify whether their dislike would manifest as armed resistance or through non-violent opposition.", "n", "validated"], ["The statement asserts that Cubans \"would go up in arms\" (implying violent rebellion), which is a stronger claim than the dissatisfaction expressed in the context. The escalation from \"not liking\" to \"armed uprising\" is not confirmed.", "n", "validated"], ["The context indicates that Cubans wouldn't like annexation, but it does not state or imply that they would actively resist or \"go up in arms.\"", "c", "validated"], ["Disliking annexation does not necessarily mean organizing a violent or armed response.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "120955n", "premise": "Another thing those early French and Dutch settlers agreed upon was that their island should be free of levies on any imported goods.", "hypothesis": "The French settlers did not mind income taxes at all.", "generated_explanations": [["The context only mentions agreement about the absence of levies on imported goods, not about income taxes.", "n", "validated"], ["There is no information in the context regarding the French settlers' opinions or attitudes toward income taxes.", "n", "validated"], ["The context refers specifically to levies on imported goods, not income taxes, so there is no information about the French settlers' attitudes toward income taxes.", "c", "validated"], ["The statement assumes the existence or relevance of income taxes, which is not supported by the context that only discusses import levies.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "88188e", "premise": "The air is warm.", "hypothesis": "The arid air permeates the surrounding land.", "generated_explanations": [["The context does not specify whether the air is arid or moist.", "n", "validated"], ["The context does not indicate whether the air is permeating the surrounding land.", "n", "validated"], ["Warm air does not necessarily imply that the air is arid; warmth and dryness are distinct properties.", "c", "validated"], ["The context provides no evidence that the air is arid.", "c", "validated"], ["The context does not mention the air permeating the land or interacting with the land at all.", "c", "validated"], ["\"Warm\" air could be humid or moist, contradicting the implication of aridity in the statement.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 4}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 4}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "138966n", "premise": "It's thought he used the same architect who worked on the Taj Mahal.", "hypothesis": "In reality, he did not use the Taj Mahal's architect.", "generated_explanations": [["The context uses the phrase \"it's thought,\" indicating uncertainty or speculation, not confirmation.", "n", "validated"], ["There is no definitive information in the context about whether he actually did or did not use the Taj Mahal's architect.", "n", "validated"], ["The context only states it is \"thought\" he used the same architect, but does not provide evidence for or against the reality; therefore, it does not confirm that he did not use the Taj Mahal's architect.", "c", "validated"], ["The use of \"it's thought\" suggests uncertainty and rumor, rather than fact, so the context does not definitively establish the truth of the statement.", "c", "not_validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "48222n", "premise": "News berates computer users for picking obvious, easily cracked passwords and chastises system administrators for ignoring basic security precautions.", "hypothesis": "Users and system administrators both do not prioritize security.", "generated_explanations": [["The news criticizes users for choosing obvious, easily cracked passwords, indicating that users do not prioritize security.", "e", "not_validated"], ["The news chastises system administrators for ignoring basic security precautions, indicating that system administrators also do not prioritize security.", "e", "validated"], ["The context indicates that users pick weak passwords and system administrators ignore basic precautions, but it does not provide information about their overall prioritization of security beyond these specific actions.", "n", "validated"], ["It is possible that users and system administrators do prioritize security in other ways not mentioned in the context.", "n", "validated"], ["The context only indicates that system administrators ignore basic security precautions, not that they do not prioritize security overall.", "c", "validated"], ["The news chastising system administrators for ignoring precautions does not necessarily mean all system administrators do not prioritize security.", "c", "validated"], ["Users picking obvious, easily cracked passwords suggests poor individual choices, but does not definitively prove they do not prioritize security in general.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "18428n", "premise": "Companies that were foreign had to accept Indian financial participation and management.", "hypothesis": "Foreign companies had to take Indian money in order to operate their businesses.", "generated_explanations": [["The requirement for Indian financial participation means foreign companies were obligated to accept investment or funding from Indian sources, which necessitates taking Indian money to operate.", "e", "validated"], ["The context states that foreign companies had to accept Indian financial participation, but does not specify whether this participation was mandatory to operate or simply a requirement if they wished to have foreign status.", "n", "validated"], ["The context mentions acceptance of management along with financial participation, but does not clarify if accepting Indian money was the sole or necessary condition for operation.", "n", "validated"], ["The context does not explicitly state that the acceptance of Indian financial participation was a precondition for operation, only that foreign companies \"had to accept\" it, leaving ambiguity about operational requirements.", "n", "validated"], ["The context states that foreign companies had to accept Indian financial participation, but it does not specify that they were required to take Indian money for operational purposes; financial participation could refer to ownership or equity involvement rather than funding for operations.", "c", "validated"], ["The context mentions both financial participation and management, indicating requirements beyond just accepting money, while the statement focuses solely on taking Indian money for operations, which is a narrower claim.", "c", "validated"], ["The requirement could have been about Indian investment or shareholding, not necessarily about operational funding.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "116059n", "premise": "These days, newspaper writers are no longer allowed the kind of license he took.", "hypothesis": "Newspaper writers need to be more factual and careful these days.", "generated_explanations": [["The phrase \"no longer allowed the kind of license he took\" implies that current newspaper writers face stricter standards than before.", "e", "validated"], ["\"License\" in this context refers to creative or factual freedom, suggesting that now writers cannot be as free with facts or interpretations.", "e", "validated"], ["Increased restrictions on writers necessitate greater adherence to facts and carefulness in writing.", "e", "validated"], ["The context states that writers are \"no longer allowed the kind of license he took,\" but does not specify what \"license\" refers to—whether it means creative license, lack of fact-checking, or something else—so the exact requirement for newspaper writers now is unclear.", "n", "validated"], ["The context does not state directly that being more factual and careful is required; it only mentions a change in what is allowed.", "n", "validated"], ["The phrase \"these days\" in both the context and statement refers to the present, but without explicit details about what constitutes current expectations for newspaper writers.", "n", "validated"], ["It's possible that the restriction is about style, opinion, or other forms of expression, not strictly about being factual and careful.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 4}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 4}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "67610c", "premise": "Sorry but that's how it is.", "hypothesis": "This is how things are and there are no apologies about it.", "generated_explanations": [["The statement \"Sorry but that's how it is\" communicates an acceptance of the situation as unchangeable, which matches \"this is how things are.\"", "e", "validated"], ["Although an apology is made, the overall message conveys inevitability or resignation, which aligns with the idea of there being \"no apologies about it\" in the sense that the situation itself cannot be altered regardless of feelings.", "e", "not_validated"], ["The context includes an apology (\"Sorry\") while the statement denies the existence of any apologies, making it unclear whether apologies are actually being offered.", "n", "validated"], ["The context affirms the state of things but does not explicitly state there are \"no apologies,\" leaving uncertainty about whether apologies are generally made regarding the situation.", "n", "validated"], ["The context includes an explicit apology (\"Sorry\"), while the statement claims there are no apologies.", "c", "validated"], ["The statement denies the presence of apologies, which contradicts the context where one is clearly given.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "95186n", "premise": "The cane plantations, increasingly in the hands of American tycoons, found a ready market in the US.", "hypothesis": "The US market was ready for the cane plantations, according to the economists.", "generated_explanations": [["The context states that cane plantations found a ready market in the US, indicating existing high demand.", "e", "validated"], ["The acquisition of plantations by American tycoons suggests investment based on anticipated strong market demand in the US.", "e", "not_validated"], ["The phrase \"found a ready market\" aligns with the economists' assessment that the US market was prepared or suitable for products from the cane plantations.", "e", "validated"], ["The context does not mention economists or attribute any analysis or opinion to them.", "n", "validated"], ["The context indicates the market was \"ready,\" but does not specify whether this assessment is based on economic analysis or another perspective.", "n", "validated"], ["The context mentions that the US market was ready for the products from cane plantations, but does not mention anything about economists or their opinions.", "c", "validated"], ["The statement attributes the readiness of the US market to the opinion of economists, which is not supported by the context.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "77875e", "premise": "As legal scholar Randall Kennedy wrote in his book Race, Crime, and the Law , Even if race is only one of several factors behind a decision, tolerating it at all means tolerating it as potentially the decisive factor.", "hypothesis": "Race is one of several factors in some judicial decisions", "generated_explanations": [["The context explicitly states that race is only one of several factors behind a decision.", "e", "validated"], ["The context discusses a hypothetical scenario—if race is one of several factors—without confirming that this occurs in reality.", "n", "validated"], ["The context is a quotation expressing an opinion or argument rather than stating a factual occurrence.", "n", "validated"], ["The context does not provide evidence or specific examples that race has actually been a factor in judicial decisions.", "n", "validated"]], "label_count_round_1": {"e": 1, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 1, "n": 3}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "65879c", "premise": "After the recovery of Jerusalem in 1099, it took four hundred years of sieges and battles, treaties, betrayals, and yet more battles, before Christian kings and warlords succeeded in subduing the Moors.", "hypothesis": "The Moors were able to subdue the Christian kings after just a decade of war.", "generated_explanations": [["The context does not specify any instance where the Moors subdued the Christian kings.", "n", "validated"], ["The timeframe in the statement (\"just a decade of war\") is inconsistent with the context, which mentions a period of four hundred years.", "n", "validated"], ["The direction of subjugation in the context is from Christian kings to the Moors, not the other way around.", "n", "validated"], ["The context does not provide information about the outcomes of any wars specifically after a decade.", "n", "validated"], ["The context states that it took four hundred years, not just a decade, for the conflict to be resolved.", "c", "validated"], ["The context indicates that the Christian kings and warlords succeeded in subduing the Moors, not the other way around.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "86331e", "premise": "'Would you like some tea?'", "hypothesis": "DO you want a cup of tea?", "generated_explanations": [["\"Would you like some tea?\" and \"Do you want a cup of tea?\" both ask if the other person desires tea to drink.", "e", "validated"], ["Both sentences are polite offers, inviting the listener to accept tea.", "e", "validated"], ["\"Some tea\" and \"a cup of tea\" are functionally equivalent in this context, as tea is typically served by the cup.", "e", "validated"], ["The use of \"would you like\" and \"do you want\" both serve to inquire about the listener’s preference or desire for tea.", "e", "validated"], ["The context asks about offering tea, but it does not specify whether the person actually wants it.", "n", "validated"], ["The statement inquires directly about desire, while the context is an offer that may be politely refused.", "n", "not_validated"], ["The context contains a question, not an answer, so the actual preference or desire of the person is unknown.", "n", "not_validated"]], "label_count_round_1": {"e": 4, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 4, "n": 1}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {"n": 2}}
{"id": "65130n", "premise": "In Mumbai, both Juhu and Chowpatty beaches are, for instance, definitely a bad idea, and though the Marina beaches in Chennai are cleaner, there may be sharks.", "hypothesis": "The beaches are very dirty in Mumbai.", "generated_explanations": [["The context states that Juhu and Chowpatty beaches are \"definitely a bad idea,\" which, in contrast to the mention of cleanliness regarding Marina beaches in Chennai, suggests the Mumbai beaches are dirty.", "e", "validated"], ["The specific mention that Marina beaches in Chennai are cleaner implies that Mumbai beaches are not clean, supporting the claim that they are very dirty.", "e", "validated"], ["The context mentions only Juhu and Chowpatty beaches as being \"definitely a bad idea,\" but does not specify if all beaches in Mumbai are dirty.", "n", "validated"], ["The description of Juhu and Chowpatty being a bad idea does not explicitly state the reason is dirtiness; other factors could be involved.", "n", "validated"], ["There is no quantification or generalization about the condition of all beaches in Mumbai in the context.", "n", "validated"], ["The statement only specifies that Juhu and Chowpatty beaches are a bad idea, but does not explicitly state that all beaches in Mumbai are very dirty.", "c", "validated"], ["The context does not provide information about all beaches in Mumbai, so it cannot be inferred that all beaches there are very dirty.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "19578n", "premise": "Moreover, Las Vegas has recently started to show signs of maturity in its cultural status as well.", "hypothesis": "The culture of Las Vegas has a lot of room for improvement.", "generated_explanations": [["The mention of Las Vegas only recently starting to show signs of maturity in its cultural status implies that it was previously lacking in cultural development, suggesting there is still significant potential for improvement.", "e", "not_validated"], ["The phrase \"signs of maturity\" indicates an early stage in cultural development, which generally means more growth and enhancement is possible.", "e", "validated"], ["The context mentions that Las Vegas has started to show signs of maturity in its cultural status, but does not quantify or evaluate the current state or amount of improvement needed, leaving it unclear whether there remains \"a lot of room for improvement.\"", "n", "validated"], ["The term \"signs of maturity\" does not explicitly address the overall level or quality of culture in Las Vegas, so it's not possible to determine if there is still \"a lot\" left to improve.", "n", "validated"], ["The context states that Las Vegas has started to show signs of maturity in its cultural status, which contradicts the idea that its culture still has a lot of room for improvement.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "83657c", "premise": "Think of it this  When consumer confidence declines, it is as if, for some reason, the typical member of the co-op had become less willing to go out, more anxious to accumulate coupons for a rainy day.", "hypothesis": "Coupon collecting is no longer allowed in most US stores.", "generated_explanations": [["The context describes consumers' increased desire to accumulate coupons, but does not mention any prohibition or policy change about coupon collecting in stores.", "n", "validated"], ["There is no information provided in the context about store policies or legal regulations regarding coupon collecting.", "n", "validated"], ["The context describes people becoming more anxious to accumulate coupons, which implies that coupon collecting is still possible and allowed.", "c", "validated"], ["The scenario assumes the ongoing possibility of coupon accumulation as a response to declining consumer confidence, contradicting the claim that most US stores prohibit it.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "102817c", "premise": "yes they would they just wouldn't be able to own the kind of automobiles that they think they deserve to own or the kind of homes that we think we deserve to own we might have to you know just be able to i think if we a generation went without debt then the next generation like if if our our generation my husband and i we're twenty eight if we lived our lives and didn't become you know indebted like you know our generation before us that um the budget would balance and that we became accustomed to living with what we could afford which we wouldn't be destitute i mean we wouldn't be living on the street by any means but just compared to how spoiled we are we would be in our own minds but i feel like the generation after us would oh man it it would be so good it would be so much better it wouldn't be perfect but then they could learn to live with what what they could afford to save to buy and if you want a nicer car than that well you save a little longer", "hypothesis": "I am glad our generation has no debt.", "generated_explanations": [["The context discusses the benefits of a generation living without debt, implying relief or positivity associated with being debt-free.", "e", "not_validated"], ["The speaker expresses that living without debt would result in balanced budgets and adjustment to living within means, which are favorable outcomes.", "e", "not_validated"], ["The statement \"we wouldn't be destitute\" suggests that not having debt doesn't result in severe negative consequences, supporting the idea of feeling glad about having no debt.", "e", "not_validated"], ["The context implies that setting an example of living without debt would benefit future generations, giving further reason to be glad about the current generation having no debt.", "e", "not_validated"], ["The speaker discusses a hypothetical situation in which their generation lives without debt, but does not state that this is currently the case.", "n", "validated"], ["The speaker refers to “if we lived our lives and didn’t become...indebted,” indicating this is a scenario, not a reflection of their present reality.", "n", "validated"], ["There is no expression of gladness or any emotion regarding the current debt status of their generation in the context.", "n", "validated"], ["The actual debt status of their generation is not explicitly stated, leaving the truth of the statement uncertain.", "n", "validated"], ["The context discusses a hypothetical situation in which the speaker's generation lives without debt, but does not state that the current generation actually has no debt.", "c", "validated"], ["The speaker says \"if we lived our lives and didn't become...indebted,\" indicating that currently they may have debt, and the no-debt scenario is merely imagined.", "c", "validated"], ["The use of conditional language (\"if we lived our lives...without debt\") implies the present reality is different and likely includes debt.", "c", "validated"]], "label_count_round_1": {"e": 4, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 4, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 4}}
{"id": "124590c", "premise": "The great attraction of the church is the splendid exterior, which is crowned by golden onion-shaped cupolas.", "hypothesis": "The outside of the church isn't much to look at, but the inside is intricately decorated.", "generated_explanations": [["The context only describes the exterior of the church and does not mention the interior, so there is no information about whether the inside is intricately decorated.", "n", "validated"], ["The statement claims the outside isn't much to look at, but the context describes the exterior as splendid and attractive, creating a contradiction; however, there is no information about the interior to determine if that part of the statement is true or false.", "n", "validated"], ["The context states that the splendid exterior with golden onion-shaped cupolas is the great attraction, directly contradicting the statement that the outside of the church isn't much to look at.", "c", "validated"], ["The context provides no information about the interior decoration, so the claim about an intricately decorated inside is unsupported.", "c", "not_validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "96583n", "premise": "Mack Lee, Body Servant of General Robert E. Lee Through the Civil War , published in 1918.", "hypothesis": "The book was first drafted in early 1915.", "generated_explanations": [["The book was published in 1918, making it plausible that the first draft could have been completed in early 1915, allowing time for editing, revisions, and publication processes.", "e", "not_validated"], ["The context provides only the publication year (1918), not information about when the book was first drafted.", "n", "validated"], ["There is no mention of the drafting process or timeline in the context.", "n", "validated"], ["The context only provides information about the publication year (1918), not when the book was first drafted, so there is no evidence in the context confirming that it was first drafted in early 1915.", "c", "not_validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2}, "label_set_round_2": ["n"], "error": ["c", "e"], "not_validated_exp": {"e": 1, "c": 1}}
{"id": "132525n", "premise": "She had the pathetic aggression of a wife or mother--to Bunt there was no difference.", "hypothesis": "Bunt was raised motherless in an orphanage.", "generated_explanations": [["The context does not mention Bunt's childhood or upbringing.", "n", "validated"], ["The context does not state whether Bunt had a mother or describe his family situation.", "n", "validated"], ["The context does not specify if Bunt ever lived in an orphanage.", "n", "validated"], ["The context implies that Bunt is familiar with the roles of both wives and mothers, suggesting he had experience with at least one maternal figure, contradicting the claim that he was raised motherless in an orphanage.", "c", "validated"], ["The context does not mention an orphanage or Bunt being motherless, so there is no support for the statement in the provided information.", "c", "validated"], ["The statement asserts a specific upbringing (in an orphanage, motherless) that is not addressed or implied anywhere in the context.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "11362e", "premise": "The volumes are available again but won't be returned to the stacks until the damp library itself gets renovated.", "hypothesis": "The volumes will be available to the public after renovation.", "generated_explanations": [["The volumes are currently not in the stacks because the library needs renovation.", "e", "not_validated"], ["The statement implies the volumes can return to public stacks after the renovation is complete.", "e", "validated"], ["The reason for unavailability is tied to the state of the library, not to the volumes themselves.", "e", "validated"], ["The context states the volumes won't be returned to the stacks until after renovation, but it does not specify whether they will be available to the public at that time.", "n", "validated"], ["The volumes are \"available again,\" but it is unclear if this availability is restricted to library staff or includes the public.", "n", "validated"], ["The process or timeline for returning the volumes to public access after renovation is not detailed in the context.", "n", "validated"], ["There may be other factors affecting public access that are not addressed by the information given.", "n", "validated"], ["The context says the volumes are available again now, not necessarily only after renovation.", "c", "validated"], ["The statement assumes the volumes will be available to the public after renovation, but the context does not specify their public availability post-renovation, only that they won't be returned to the stacks until then.", "c", "validated"], ["Availability to the public is not clearly established by the context; the volumes might be available in some other form or to a restricted group, not necessarily to the public.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "107468n", "premise": "You have to walk through it).", "hypothesis": "Walking is the best way to get through it.", "generated_explanations": [["The context directly states that you have to walk through it, implying that walking is required, which aligns with the statement that walking is the best way to get through it.", "e", "validated"], ["The context only indicates that walking through \"it\" is required, not that it is necessarily the best way, so other methods could exist that are better but not mentioned.", "n", "validated"], ["The context does not provide any comparison to alternate ways of getting through \"it,\" so it is unknown whether walking is superior to other possible methods.", "n", "validated"], ["The context does not specify why walking is necessary, leaving open the possibility that walking is required due to external constraints, not because it is optimal.", "n", "validated"], ["The context only states that walking is required to get through it, not that walking is the best way.", "c", "validated"], ["There could be other ways to get through it (e.g., running, biking, driving) that are better, but the context does not provide enough information to establish walking as the best.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "145047e", "premise": "The management of the cafe has established the rules for the use of their facility.", "hypothesis": "The management of the cafe is strict about how they manage it.", "generated_explanations": [["Establishing rules for the use of the facility indicates that the management is attentive and intentional about how the cafe is managed.", "e", "validated"], ["Creating specific rules demonstrates a desire to control and regulate behavior within the cafe, suggesting a strict management style.", "e", "validated"], ["The context only states that rules have been established, but does not specify how strictly they are enforced.", "n", "validated"], ["Establishing rules does not necessarily imply strictness; it could be a formality or standard practice.", "n", "validated"], ["There is no information about the nature, number, or enforcement of the rules, so the level of strictness cannot be determined.", "n", "validated"], ["Establishing rules does not necessarily indicate strictness; rules can exist alongside a lenient or flexible management style.", "c", "validated"], ["The context only confirms that rules were established, not that they are enforced strictly or rigidly.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "55888c", "premise": "You've got the keys still, haven't you, Poirot? I asked, as we reached the door of the locked room.", "hypothesis": "I had the keys in my pocket.", "generated_explanations": [["The speaker is asking Poirot if he still has the keys, implying that the keys have remained with him, which supports that he would still have them in his pocket.", "e", "validated"], ["The context indicates they reached a locked room and reference having the keys, logically matching the statement that the keys are in the speaker's pocket.", "e", "not_validated"], ["The context does not specify who currently possesses the keys; it only shows the speaker asking Poirot if he has them.", "n", "validated"], ["The context does not indicate whether the statement \"I had the keys in my pocket\" refers to the speaker or Poirot.", "n", "validated"], ["There is no confirmation in the context about the location of the keys at the time in question.", "n", "validated"], ["The context only shows the speaker asking Poirot if he has the keys, not stating that the speaker themselves has the keys in their pocket.", "c", "validated"], ["The question implies uncertainty about who has the keys, suggesting the speaker may not have them.", "c", "validated"], ["The context could indicate that Poirot, not the speaker, has the keys.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "138285n", "premise": "i cried when the horse got killed and when the wolf got killed", "hypothesis": "Animal killings make me want to cry.", "generated_explanations": [["The mention of crying in response to the horse and wolf being killed implies an emotional reaction to animal deaths.", "e", "validated"], ["Both examples given involve animals being killed and both events elicited the same emotional response of crying.", "e", "validated"], ["The context generalizes a pattern: when an animal is killed (horse, wolf), it triggers sadness strong enough to cause tears, suggesting this reaction could occur with other animal killings as well.", "e", "validated"], ["The context only mentions crying in response to the deaths of a horse and a wolf, which may not generalize to all animal killings.", "n", "validated"], ["The context does not clarify whether the crying was specifically due to the fact that the animals were killed, or other emotional factors related to those particular scenes.", "n", "validated"], ["There is no information about the person's reaction to other instances of animal killings, so it is unclear if this response is consistent across all cases.", "n", "validated"], ["The context only mentions crying at the deaths of a horse and a wolf, not at all animal killings, so it's possible the speaker doesn't react this way to all animal killings.", "c", "validated"], ["The context suggests an emotional response to specific animals, which might not generalize to all animal killings.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "57454c", "premise": "what does um is Robby Robin Williams does he have a funny part in the movie or is", "hypothesis": "How much went into making the movie?", "generated_explanations": [["The context discusses Robby Robin Williams' role and whether it is funny, but does not mention any information about the movie's budget or production costs.", "n", "validated"], ["There is no reference to financial aspects or the amount spent on making the movie in the context.", "n", "validated"], ["The context is focused on cast and character traits, not on production details.", "n", "validated"], ["The context is about whether Robin Williams has a funny role in the movie, not about the production cost.", "c", "validated"], ["The context does not mention financial or production aspects of the movie at all.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "88605n", "premise": "The remaining parts of the north, although enticing, are difficult to explore.", "hypothesis": "Inexperienced explorers should take care to avoid dangerous areas of the north.", "generated_explanations": [["The north is described as difficult to explore, implying there are dangers present.", "e", "validated"], ["Inexperienced explorers are more likely to struggle with difficult and potentially hazardous environments.", "e", "not_validated"], ["The context mentions that the north is difficult to explore but does not specify whether it is dangerous, so it is unclear if inexperienced explorers need to exercise caution specifically due to danger.", "n", "validated"], ["The context does not mention the experience level of explorers or provide advice for inexperienced individuals, so it is undetermined if caution is especially warranted for them.", "n", "validated"], ["The context mentions that the north is difficult to explore but does not state that it is dangerous.", "c", "validated"], ["The statement specifically targets inexperienced explorers, whereas the context does not mention experience level as a factor.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "72721e", "premise": "no i i i don't i it completely beyond me i went to my under graduate uh education", "hypothesis": "I can't remember, I did my undergraduate education.", "generated_explanations": [["The speaker expresses confusion or lack of recollection about something and mentions going to undergraduate education, which suggests an inability to remember details about their past, including their undergraduate education.", "e", "validated"], ["The repeated hesitation and phrase \"it's completely beyond me\" imply forgetfulness, which supports the idea that the speaker can't remember their undergraduate education.", "e", "validated"], ["The speaker references \"my undergraduate uh education,\" indicating they attended undergraduate education, matching the statement's claim.", "e", "validated"], ["The context expresses confusion or lack of comprehension but does not explicitly mention memory loss.", "n", "validated"], ["The context includes mention of undergraduate education but does not clarify whether the speaker remembers it or not.", "n", "validated"], ["The context indicates confusion or lack of understanding (\"it completely beyond me\") rather than memory loss.", "c", "validated"], ["The context does not explicitly state any issue with remembering, only that the topic is beyond comprehension.", "c", "validated"], ["The speaker explicitly mentions attending undergraduate education, contradicting the idea that they can't remember it.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "49611e", "premise": "How did you get it?\" A chair was overturned.", "hypothesis": "\"How did you get your hands on this object?\"", "generated_explanations": [["The phrase \"How did you get it?\" could be referring to an object, and since a chair is mentioned, it is reasonable to infer the question is about how the person obtained the chair.", "e", "not_validated"], ["The statement \"How did you get your hands on this object?\" is a more specific version of \"How did you get it?\" with \"this object\" referring to the chair that is present in the context.", "e", "validated"], ["The context does not specify what \"it\" refers to, so it is unclear if \"this object\" in the statement matches.", "n", "validated"], ["The context does not indicate whether \"getting\" was accomplished by using hands, as implied in the statement.", "n", "validated"], ["The overturned chair in the context is not explicitly connected to any acquisition of an object.", "n", "validated"], ["The context refers to \"it\" without specifying an object, and only mentions an overturned chair, whereas the statement explicitly refers to \"this object,\" implying a specific object that is not clearly identified in the context.", "c", "validated"], ["The context suggests the focus is on an event or situation involving an overturned chair, not on acquiring an object, so the statement's question about obtaining an object does not match the provided context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "16989c", "premise": "Auditors from another country engaged to conduct audits in their country should meet the professional qualifications to practice under that country's laws and regulations or other acceptable standards, such as those issued by the International Organization of Supreme Audit Institutions.", "hypothesis": "All auditors report to a globally managed governing body.", "generated_explanations": [["The context only discusses the need for auditors to meet local or international standards, not about their reporting structure or governance.", "n", "validated"], ["No information is provided about the existence or authority of a globally managed governing body overseeing all auditors.", "n", "validated"], ["Auditors are required to meet the professional qualifications and standards specific to the country in which they are auditing, not necessarily report to a single global governing body.", "c", "validated"], ["The context refers to standards like those from the International Organization of Supreme Audit Institutions as acceptable, implying multiple authorities rather than one global governing body.", "c", "validated"], ["Laws and regulations governing auditors vary by country, indicating oversight is managed locally or nationally, not globally.", "c", "validated"], ["There is no mention in the context of the existence of a globally managed governing body to which all auditors must report.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 4}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 4}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "112349c", "premise": "The idea that Clinton's approval represents something new and immoral in the country is historically shortsighted.", "hypothesis": "It's accurate to conclude that Clinton's approvals signify the start of a new form of immorality in the country.", "generated_explanations": [["The context criticizes the notion that Clinton's approval represents something new and immoral as \"historically shortsighted,\" but does not provide enough information about the historical context or evidence regarding morality trends to decisively accept or reject the statement.", "n", "validated"], ["The context introduces an opinion about the interpretation of Clinton's approval but does not provide factual or comprehensive historical data to confirm or refute whether Clinton's approvals signify a new form of immorality.", "n", "validated"], ["The context challenges the novelty and moral judgment associated with Clinton's approval but does not specify what Clinton's approvals are or what specific immoral actions or societal changes they might represent.", "n", "validated"], ["The context argues that viewing Clinton's approval as representing something new and immoral ignores historical precedent, implying that similar situations have occurred before and thus Clinton's approvals do not signify the start of a new form of immorality.", "c", "validated"], ["The context explicitly calls such a conclusion \"historically shortsighted,\" directly rejecting the statement's claim that Clinton's approvals signify a novel moral decline.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "119768n", "premise": "I had rejected it as absurd, nevertheless it persisted.", "hypothesis": "I rejected it as absurd but it persisted out of protest.", "generated_explanations": [["The context states that the thing persisted despite being rejected as absurd, allowing the inference that its persistence was in opposition to the rejection, which could be interpreted as a form of protest.", "e", "not_validated"], ["The context does not specify any reason or motivation for why it persisted.", "n", "validated"], ["There is no information indicating protest as the cause of its persistence.", "n", "validated"], ["The context does not indicate that the persistence was motivated by protest; it simply states that it persisted, without specifying a reason.", "c", "validated"], ["The statement adds a justification (\"out of protest\") for the persistence that is not supported or suggested by the context.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "111680e", "premise": "He dismounted and Ca'daan saw he was smaller than the rest.", "hypothesis": "He was shorter than the others.", "generated_explanations": [["The phrase \"he was smaller than the rest\" implies a comparison in physical size, which commonly includes height.", "e", "validated"], ["\"Smaller\" can be reasonably interpreted as \"shorter\" when referring to people, as height is a primary dimension of physical size among individuals.", "e", "validated"], ["The context of dismounting and comparison to \"the rest\" suggests a visible, physical difference such as height.", "e", "validated"], ["The term \"smaller\" could refer to overall body size, build, or frame rather than specifically height.", "n", "validated"], ["\"Smaller\" might describe age, youthfulness, or physical presence instead of height.", "n", "validated"], ["\"Smaller\" could refer to overall body size, build, or physique, not specifically to height.", "c", "validated"], ["The others might vary in height, so being \"smaller\" does not guarantee that he is actually \"shorter\" than each one.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "43440n", "premise": "And you are wrong in condemning it.", "hypothesis": "Everybody does it; it's normal.", "generated_explanations": [["The context implies defending an action against condemnation, and the statement justifies the action by claiming it is common and accepted by everyone.", "e", "not_validated"], ["The explanation suggests that something done by everybody and considered normal should not be condemned, supporting the context’s stance against condemnation.", "e", "not_validated"], ["The context does not specify what \"it\" refers to, so it is unclear whether everybody does it or if it is considered normal.", "n", "validated"], ["There is no information in the context about the behavior of the general population regarding \"it.\"", "n", "validated"], ["The context does not describe social norms or common practices related to \"it.\"", "n", "validated"], ["The context criticizes the act, implying it is not universally accepted or normal.", "c", "validated"], ["The context suggests disagreement, indicating that not everybody does it.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "91709c", "premise": "San'doro didn't make it sound hypothetical, thought Jon.", "hypothesis": "San'doro's words were hollow, and Jon knew the truth of that immediately.", "generated_explanations": [["The context only indicates Jon's perception that San'doro wasn't being hypothetical, but does not address whether San'doro's words were hollow.", "n", "validated"], ["There is no information about Jon's belief regarding the truthfulness or hollowness of San'doro's words, only about the hypothetical nature.", "n", "validated"], ["The context does not confirm if Jon immediately knew any truth about the quality or sincerity of San'doro's words.", "n", "validated"], ["Jon did not perceive San'doro's words as hypothetical, suggesting he took them seriously rather than as hollow.", "c", "validated"], ["There is no indication that Jon recognized San'doro's words as lacking substance; instead, he noted their certainty.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "47798n", "premise": "On the west side of the square is Old King's House (built in 1762), which was the official residence of the British governor; it was here that the proclamation of emancipation was issued in 1838.", "hypothesis": "The Old King's House had an incident where the King was murdered inside of it.", "generated_explanations": [["The context does not mention any incident involving the King being murdered inside Old King's House.", "n", "validated"], ["The context only states that Old King's House was the residence of the British governor, not the King.", "n", "validated"], ["The events described in the context are limited to the issuance of the proclamation of emancipation and do not reference any murder or violent event.", "n", "validated"], ["There is no information provided about any King ever being present at Old King's House.", "n", "validated"], ["The context does not mention any king being present or residing in Old King's House; rather, it was the residence of the British governor.", "c", "validated"], ["There is no information or reference in the context to any murder, let alone the murder of a king, occurring at Old King's House.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "103364n", "premise": "Several of its beaches are officially designated for nudism (known locally as naturisme) the most popular being Pointe Tarare and a functionary who is a Chevalier de la L??gion d'Honneur has been appointed to supervise all aspects of sunning in the buff.", "hypothesis": "They do not mind having nude people.", "generated_explanations": [["Official designation of beaches for nudism indicates acceptance of nude people.", "e", "validated"], ["Appointment of a functionary to supervise nudism shows institutional support and organization for nude sunbathing.", "e", "validated"], ["The context mentions official designation for nudism and supervision but does not specify the attitudes of local residents or authorities toward nude people.", "n", "validated"], ["Official policies or management may not reflect the personal opinions of individuals in the area.", "n", "validated"], ["The statement generalizes an attitude (\"they do not mind\") without clarifying whose attitude is being referenced, while the context only provides information about regulations and appointments.", "n", "validated"], ["The appointment of a functionary to supervise all aspects of nudist sunning implies that there are regulations and oversight, suggesting that nudism is not simply accepted without concern.", "c", "validated"], ["The need for official designation of certain beaches for nudism indicates that nudity is not universally tolerated and only permitted in specific areas.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "49462c", "premise": "The village is Sainte-Marie, named by the explorer when he landed on 4 November 1493, attracted by the waterfalls and river he could see flowing down the green inland mountains.", "hypothesis": "The village is not named after the settling explorer.", "generated_explanations": [["The village is named Sainte-Marie, which suggests it is named after a saint (Saint Mary) rather than the explorer.", "e", "validated"], ["The explorer named the village, but the name chosen was not his own, indicating it was not named after him.", "e", "validated"], ["The context states that the explorer named the village but does not specify whether the village is named after the explorer himself or after something else (e.g., a religious figure or event).", "n", "validated"], ["The statement refers to being \"named after the settling explorer,\" but the context only mentions that the explorer named the village, not that he was also the settler or that the name was taken from him.", "n", "validated"], ["The village is named by the explorer, indicating it is indeed named after him, contradicting the statement.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "97011c", "premise": "Expectations that the ANC would oversee land reform--returning land seized during apartheid's forced migrations--and wealth redistribution have not been met.", "hypothesis": "The ANC would not be in charge of land reform.", "generated_explanations": [["The context mentions expectations that the ANC would oversee land reform but does not specify whether the ANC is or is not in charge, only that the expectations have not been met.", "n", "validated"], ["The context does not clarify whether another entity is responsible for land reform or if the ANC's lack of action is despite being in charge.", "n", "validated"], ["There is no information on the actual administrative structure or government responsibility provided in the context.", "n", "validated"], ["The context indicates that there were expectations for the ANC to oversee land reform, which implies that the ANC is or was supposed to be in charge of land reform.", "c", "validated"], ["The statement directly contradicts the context, which presupposes the ANC's role in overseeing land reform efforts.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "56743e", "premise": "I found her leaning against the bannisters, deadly pale.", "hypothesis": "She couldn't stand on her own so she leaned against the bannisters until I found her.", "generated_explanations": [["The description \"deadly pale\" suggests she was unwell or weak, possibly unable to stand steadily on her own.", "e", "not_validated"], ["Leaning against the bannisters indicates she required physical support, implying difficulty in standing unaided.", "e", "validated"], ["The context states she was leaning against the bannisters and appeared deadly pale, but does not clarify whether she was unable to stand on her own or simply chose to lean.", "n", "validated"], ["The context does not specify the duration for which she had been leaning against the bannisters before being found.", "n", "validated"], ["The context does not establish that her leaning was due to inability to stand as opposed to other reasons, such as fatigue, dizziness, or emotional distress.", "n", "validated"], ["The context does not state or imply that she was unable to stand on her own; it only describes her as leaning against the bannisters and being pale.", "c", "validated"], ["There is no evidence in the context that her leaning was due to inability to stand rather than personal choice or comfort.", "c", "validated"], ["The context does not indicate how long she was leaning against the bannisters prior to being found.", "c", "validated"], ["The reason for her leaning or her physical capabilities is not provided in the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 4}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "48300c", "premise": "The activities included in the Unified Agenda are, in general, those expected to have a regulatory action within the next 12 months, although agencies may include activities with an even longer time frame.", "hypothesis": "Some actions were implemented for being shorter than 12 months.", "generated_explanations": [["The context states that activities included are those expected to have a regulatory action within the next 12 months, but it does not specify whether any actions were actually implemented because they were shorter than 12 months.", "n", "validated"], ["The context allows for inclusion of activities with a longer time frame but does not discuss or imply implementation decisions based on being shorter than 12 months.", "n", "validated"], ["There is no information in the context about the duration of specific actions that were implemented or the reasons for their implementation.", "n", "validated"], ["The context states that activities are included based on when regulatory action is expected, not on the length of time required to implement them.", "c", "validated"], ["The context does not mention implementation timing as a criterion, only the expected timing of regulatory action.", "c", "validated"], ["There is no information in the context indicating that being \"shorter than 12 months\" is a reason for inclusion or implementation of actions.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "105769c", "premise": "yeah yeah i i went i went off to school wanting to either be a high school algebra teacher or high school French teacher because my two favorite people in the in high school were my algebra teacher and French teacher and uh and i was going to do that until the end of our sophomore year when we wanted uh we came time to sign up for majors and i had taken chemistry for the first time that year and surprised myself i did well in it", "hypothesis": "You are required to sign up for a major freshman year.", "generated_explanations": [["The context specifies that the speaker signed up for a major at the end of their sophomore year, which does not clarify when others are required to sign up for a major.", "n", "validated"], ["The context only describes the speaker's personal experience and does not provide information about general requirements for all students.", "n", "validated"], ["The speaker mentions that the requirement to sign up for majors occurred at the end of sophomore year, not freshman year.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "53866e", "premise": "kind of kind of nothing i won't have anything to do with", "hypothesis": "I don't want anything to do with it, no doubts about it.", "generated_explanations": [["The context expresses a clear refusal to be involved by saying \"i won't have anything to do with.\"", "e", "validated"], ["The statement reinforces the disinterest and adds emphasis by mentioning \"no doubts about it,\" aligning with the context’s strong dismissal.", "e", "validated"], ["The context is fragmented and informal, making it unclear whether the speaker is expressing a definitive stance or hesitancy.", "n", "validated"], ["The phrase \"kind of kind of nothing\" could indicate uncertainty or reluctance, but it is not explicit enough to confirm a definite refusal.", "n", "validated"], ["The context does not clearly specify what \"it\" refers to, leaving ambiguity about the subject of refusal.", "n", "validated"], ["The tone of the context might suggest partial disengagement rather than absolute certainty, making the strength of the claim in the statement undetermined.", "n", "validated"], ["The context expresses ambiguity or uncertainty (\"kind of kind of nothing\"), while the statement asserts definite certainty (\"no doubts about it\").", "c", "validated"], ["The context does not explicitly mention not wanting anything to do with something, only hints indirectly at avoidance.", "c", "not_validated"], ["The context is vague and uncertain, whereas the statement is clear and resolute.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "136752e", "premise": "The questions may need to be tailored to", "hypothesis": "There are some questions that may or may not need to be tailored to.", "generated_explanations": [["The context mentions that questions \"may need to be tailored to,\" which implies the existence of questions that are considered for tailoring, aligning with the statement that \"there are some questions that may or may not need to be tailored to.\"", "e", "validated"], ["The use of \"may\" in both the context and statement indicates uncertainty or the possibility that not all questions necessarily require tailoring, meaning some might need it and some might not.", "e", "validated"], ["The context mentions that questions \"may need\" to be tailored, but does not specify whether all, some, or none require tailoring.", "n", "validated"], ["The statement introduces ambiguity (\"may or may not\") regarding whether any questions actually require tailoring, which is not clarified by the context.", "n", "validated"], ["The context does not indicate the existence of questions that definitively do not need tailoring, making it impossible to confirm or deny the statement.", "n", "validated"], ["The context implies that tailoring is necessary, not optional, for the questions, whereas the statement introduces uncertainty about the necessity.", "c", "validated"], ["The statement suggests the existence of questions that do not need to be tailored, but the context does not mention or imply such cases.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "14388e", "premise": "life in prison then he's available for parole if it's if it's life and a day then he's not eligible for parole so what you know let's quit BSing with the system", "hypothesis": "The system is corrupt because he won't be able to get parole if it's life and a day.", "generated_explanations": [["The parole eligibility rule appears arbitrary, potentially manipulating sentences so that individuals are denied parole based on technicalities rather than justice.", "e", "not_validated"], ["The discrepancy between \"life in prison\" and \"life and a day\" may be used to prevent parole intentionally, suggesting the system is set up to unfairly restrict second chances.", "e", "not_validated"], ["The speaker's frustration implies the system's rules are designed or exploited in a way that undermines fairness and transparency in sentencing.", "e", "not_validated"], ["The context discusses parole eligibility rules, but does not provide evidence about corruption in the system.", "n", "validated"], ["The context does not indicate whether denying parole after \"life and a day\" reflects corruption or simply legal policy.", "n", "validated"], ["It is unclear from the context whether the speaker believes the policy itself is corrupt or just wants changes to it.", "n", "validated"], ["The context explains the parole eligibility rules but does not provide evidence or examples of corruption within the system.", "c", "validated"], ["The inability to get parole under a \"life and a day\" sentence is described as a function of the established rules, not as an act of corruption.", "c", "validated"], ["The statement equates lack of parole eligibility with systemic corruption without justification from the context.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 3}}
{"id": "103559e", "premise": "A martini should be gin and vermouth and a twist.", "hypothesis": "A martini must be composed by gin and vermouth.", "generated_explanations": [["The context specifies that a martini should consist of gin and vermouth, which supports the claim that these two ingredients are essential for a martini.", "e", "validated"], ["The statement is consistent with the context, as it includes both gin and vermouth as required components of a martini.", "e", "validated"], ["The context specifies gin, vermouth, and a twist as the components, but the statement omits the twist, so it’s unclear if a martini must be only gin and vermouth or if the twist is also essential.", "n", "validated"], ["The context uses the term “should,” which implies recommendation, not necessity, while the statement uses “must,” indicating a requirement; it is undetermined whether the context intends the ingredients as an absolute requirement.", "n", "validated"], ["The statement omits the \"twist\" specified in the context as a necessary component of a martini.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "132019n", "premise": "and uh really they're about it they've got a guy named Herb Williams that that i guess sort of was supposed to take the place of uh Tarpley but he uh he just doesn't have the offensive skills", "hypothesis": "Tarpley is a better offensive player that Herb Williams.", "generated_explanations": [["Herb Williams was supposed to take the place of Tarpley but is described as lacking offensive skills.", "e", "validated"], ["The comparison specifically notes that Herb Williams \"just doesn't have the offensive skills,\" implying Tarpley does.", "e", "validated"], ["The context states that Herb Williams \"just doesn't have the offensive skills\" in comparison to Tarpley, but it does not explicitly compare their offensive abilities or definitively say that Tarpley is better; the judgment is implied but not directly stated, making the exact relationship undetermined.", "n", "validated"], ["The context does not provide specific evidence or examples of Tarpley's offensive skills, only implying a difference without establishing it as a fact.", "n", "validated"], ["The context is based on the speaker’s perception (\"i guess sort of was supposed to take the place...\"), introducing subjectivity and potential bias that prevents a definitive conclusion.", "n", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "118999n", "premise": "that's true i didn't think about that", "hypothesis": "You've changed my mind with a new perspective.", "generated_explanations": [["The context acknowledges agreement with a point not previously considered, suggesting the speaker's thinking has shifted due to the other person's input.", "e", "validated"], ["The statement \"i didn't think about that\" implies new information was presented, which led to a change in viewpoint.", "e", "validated"], ["The context acknowledges agreement or realization but does not explicitly indicate a change of mind.", "n", "validated"], ["The context does not specify that a new perspective was introduced, only that something had not been considered.", "n", "validated"], ["The context only acknowledges consideration of a new point, not a change of mind.", "c", "validated"], ["The context does not indicate acceptance or agreement with the new perspective.", "c", "validated"], ["No explicit mention of a new perspective being presented is made in the context.", "c", "validated"], ["The context does not specify who provided the idea or perspective.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 4}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "47404e", "premise": "do you really romance", "hypothesis": "Do you really have an affair?", "generated_explanations": [["\"Romance\" can colloquially mean having an affair, so the statement rephrases the context using a synonymous expression.", "e", "validated"], ["Both sentences question the existence of a romantic or extramarital relationship involving the person addressed.", "e", "validated"], ["The word \"romance\" in the context could refer to the genre or act of expressing love, which does not necessarily imply having an affair.", "n", "validated"], ["\"Romance\" can involve emotions or actions that fall short of an actual affair, such as flirting or dating.", "n", "validated"], ["The context does not specify whether the romance is within or outside a committed relationship, leaving ambiguity about whether it constitutes an affair.", "n", "validated"], ["The statement assumes that \"romance\" equates to \"affair,\" but without additional context, this equivalence cannot be established.", "n", "validated"], ["\"Romance\" does not necessarily imply \"having an affair\"; romance can occur within a committed relationship without infidelity.", "c", "validated"], ["The context question is ambiguous and does not specify involvement in an extramarital or secret relationship, which is implied by \"affair\".", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "30171n", "premise": "Until all members of our society are afforded that access, this promise of our government will continue to be unfulfilled.", "hypothesis": "The government is flawed and unfulfilled.", "generated_explanations": [["The government's promise remains unfulfilled because not all members of society have access.", "e", "validated"], ["The unfulfilled promise implies a flaw in the government's ability to deliver on its commitments.", "e", "validated"], ["The context only states that a specific promise of the government remains unfulfilled until universal access is achieved, but does not indicate that the government as a whole is unfulfilled.", "n", "validated"], ["The context does not mention or imply that the government is flawed, only that a promise remains unmet.", "n", "validated"], ["The context says the promise of the government is unfulfilled, not the government itself.", "c", "validated"], ["The statement claims the government is flawed, but the context does not mention any flaw, only an unfulfilled promise.", "c", "validated"], ["The context references an ongoing situation (\"will continue to be unfulfilled\") rather than declaring the government wholly unfulfilled.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "134514c", "premise": "However, co-requesters cannot approve additional co-requesters or restrict the timing of the release of the product after it is issued.", "hypothesis": "They will restrict timing of the release of the product.", "generated_explanations": [["The context states co-requesters cannot restrict the timing of the release after issuance, but does not specify what happens before the product is issued.", "n", "validated"], ["The reference of \"they\" in the statement is ambiguous and may not refer to co-requesters.", "n", "validated"], ["Co-requesters are explicitly prohibited from restricting the timing of the release of the product after it is issued.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "52542n", "premise": "The long-sought, the mysterious, the elusive Jane Finn!", "hypothesis": "Jane Finn is as beautiful as she is mysterious.", "generated_explanations": [["Jane Finn is described as \"the mysterious,\" which supports the claim that she is mysterious.", "e", "not_validated"], ["The phrases \"long-sought\" and \"elusive\" suggest that Jane Finn is highly desirable or intriguing, which can imply a notable attractiveness or beauty.", "e", "not_validated"], ["The context confirms Jane Finn is mysterious and elusive but provides no information about her physical appearance or beauty.", "n", "validated"], ["There is no comparative information in the context about how Jane Finn's beauty matches her level of mystery.", "n", "validated"], ["The description \"long-sought\" does not imply anything about her appearance.", "n", "validated"], ["The context only describes Jane Finn as \"long-sought,\" \"mysterious,\" and \"elusive,\" but does not mention anything about her beauty, so there is no evidence to support the claim that she is beautiful.", "c", "validated"], ["The statement assumes Jane Finn's beauty based solely on her mysteriousness and elusiveness, which are unrelated qualities.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "47408n", "premise": "the net cost of operations.", "hypothesis": "That's how it expensive it runs.", "generated_explanations": [["\"Net cost of operations\" refers to the overall expenses incurred to run something, indicating how costly it is to operate.", "e", "validated"], ["The statement equates the net cost of operations with the expense required to run the operation, directly explaining how expensive it is.", "e", "validated"], ["The context provides information about the \"net cost of operations\" but does not specify whether the operations are expensive or inexpensive.", "n", "validated"], ["The statement makes a qualitative claim about expense (\"expensive\") that is not directly supported or contradicted by the context.", "n", "validated"], ["The context is neutral and only references cost without any evaluation or comparison needed to judge expensiveness.", "n", "validated"], ["The statement contains incorrect grammar and does not clearly convey a logical meaning that can be evaluated against the context.", "c", "validated"], ["The phrase \"That's how it expensive it runs\" does not logically follow from or accurately describe \"the net cost of operations.\"", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "135021n", "premise": "you know we keep a couple hundred dollars um if that much charged on those which isn't too bad it's just your normal", "hypothesis": "We have money on there, which isn't great", "generated_explanations": [["The context mentions keeping a couple hundred dollars charged on \"those,\" implying that there is money present on whatever \"those\" refers to.", "e", "validated"], ["The statement \"which isn't too bad\" in the context suggests some ambivalence or mild negativity, aligning with the statement's \"which isn't great.\"", "e", "validated"], ["The context states that keeping a couple hundred dollars charged \"isn't too bad,\" while the statement claims that having money on there \"isn't great,\" so the evaluation of the situation differs and it's unclear which sentiment is accurate.", "n", "validated"], ["The context does not explicitly state whether having money on there is good or bad, only that the amount is \"normal,\" leaving the overall judgment undetermined.", "n", "validated"], ["The context says having a couple hundred dollars charged is \"not too bad,\" indicating a neutral or positive view, whereas the statement says \"isn't great,\" expressing a negative view.", "c", "validated"], ["The context refers to being \"charged\" on something, suggesting debit or credit/electronic cards, rather than simply \"having money on there.\"", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "88605e", "premise": "The remaining parts of the north, although enticing, are difficult to explore.", "hypothesis": "The rest of the north presents a steep challenge.", "generated_explanations": [["The context describes the remaining parts of the north as difficult to explore, indicating that they are challenging.", "e", "validated"], ["The use of the word \"enticing\" in the context implies that there is an appeal despite the presence of difficulty, aligning with the idea of a steep challenge.", "e", "validated"], ["The term \"steep challenge\" could imply physical steepness or general difficulty, while the context only mentions that the area is \"difficult to explore\" without specifying the nature or source of the difficulty.", "n", "validated"], ["\"Steep challenge\" carries a somewhat stronger or more specific connotation than \"difficult to explore,\" and the context does not clarify the degree or type of challenge.", "n", "validated"], ["The context describes the remaining parts of the north as \"difficult to explore,\" but does not specifically mention or imply that the challenge is \"steep,\" which typically refers to something physically abrupt or sharply rising.", "c", "not_validated"], ["The use of the term \"steep challenge\" in the statement may suggest a particular kind of difficulty (e.g., extreme, intense, or physical steepness), whereas the context only states that exploration is difficult, without clarifying the nature or degree of the challenge.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "98710n", "premise": "well Jerry do you have a favorite team", "hypothesis": "Jerry, do you follow any sports?", "generated_explanations": [["Asking if someone has a favorite team implies an interest in following sports, as favorite teams are typically associated with sports fandom.", "e", "validated"], ["The context question suggests a discussion about sports, which is directly related to following sports.", "e", "not_validated"], ["The context only asks Jerry about having a favorite team but does not mention sports in general, so it's unclear whether Jerry follows any sports at all.", "n", "validated"], ["Having a favorite team does not necessarily imply that Jerry follows sports; he could have a favorite team for reasons unrelated to following sports.", "n", "validated"], ["The context does not indicate Jerry's response, so we do not know if he follows any sports from the information given.", "n", "validated"], ["The context asks about Jerry's favorite team, not whether he follows sports in general.", "c", "validated"], ["The statement inquires about general sports following, while the context assumes Jerry already follows sports and narrows the discussion to his favorite team.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "30894c", "premise": "Earlier this week, the Pakistani paper Dawn ran an editorial about reports that Pakistani poppy growers are planning to recultivate opium on a bigger scale because they haven't received promised compensation for switching to other crops.", "hypothesis": "It is illegal to grow opium in Pakistan.", "generated_explanations": [["The context discusses \"promised compensation for switching to other crops,\" implying that growing opium is not permitted and requires incentive to switch away from.", "e", "validated"], ["The editorial frames poppy growers' recultivation plans as newsworthy and problematic, which suggests that such cultivation is against the law.", "e", "not_validated"], ["The mention of compensation for not growing opium implies that the government wants to prevent the practice, consistent with it being illegal.", "e", "not_validated"], ["The context discusses plans to recultivate opium and issues with compensation, but does not specify whether growing opium is legal or illegal in Pakistan.", "n", "validated"], ["The mention of \"promised compensation for switching to other crops\" implies incentives to stop growing opium, but does not directly state the legal status of opium cultivation.", "n", "validated"], ["The context does not reference any laws, regulations, or enforcement related to opium cultivation in Pakistan.", "n", "validated"], ["The context does not state that growing opium is illegal in Pakistan; it only mentions poppy growers planning to recultivate opium due to lack of compensation.", "c", "validated"], ["The context implies government involvement in incentivizing crop switching, but does not confirm that cultivation of opium is prohibited by law.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 2}}
{"id": "81356e", "premise": "In keeping with other early Buddhist tenets, there is no figurative representation of Buddha here, However, there is a large gilded statue from a later period inside, and behind the temple are the spreading branches and trunks of the sacred Bodhi Tree, which is said to have grown from a sapling of the first one that stood here 2,500 years ago.", "hypothesis": "There is no statue of Buddha located there.", "generated_explanations": [["The context mentions that in keeping with early Buddhist tenets, there is no figurative representation of Buddha present.", "e", "not_validated"], ["The phrase \"no figurative representation of Buddha here\" explicitly states the absence of a Buddha statue originally.", "e", "not_validated"], ["The context states that there is a large gilded statue from a later period inside, but it does not explicitly specify that the statue is of Buddha.", "n", "validated"], ["The context refers to \"no figurative representation of Buddha\" according to early tenets, but acknowledges changes in later periods, leaving ambiguity about whether the existing statue depicts Buddha.", "n", "validated"], ["There is a large gilded statue of Buddha from a later period inside the temple.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "132516n", "premise": "right right they left a woman and a child or the cat the sheep yeah", "hypothesis": "They were merciful in this regard, only taking the men as slaves.", "generated_explanations": [["The context suggests that only a woman, a child, a cat, and a sheep were left behind, implying the men were taken and the others were spared.", "e", "validated"], ["Sparing the woman, child, and animals while only taking the men aligns with the idea of showing mercy “in this regard.”", "e", "validated"], ["The context does not specify why the woman and child or the cat and sheep were left behind, nor does it indicate whether only men were taken as slaves.", "n", "validated"], ["The context does not describe the motivations or emotions (such as mercy) of those who left the woman and child or the cat and sheep.", "n", "validated"], ["The context is ambiguous about what happened to the men, and whether any group was actually taken as slaves at all.", "n", "validated"], ["The context mentions a woman and a child or animals being left, but it does not specify that only men were taken as slaves.", "c", "validated"], ["The context does not indicate the motivations behind leaving the woman and child or animals, so it cannot be concluded that it was an act of mercy.", "c", "validated"], ["The statement asserts that only men were taken as slaves, but the context is ambiguous about who, if anyone, was taken as slaves.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "34176n", "premise": "The rustic Bras-David picnic area, for example, is set alongside a burbling stream.", "hypothesis": "The stream is always burbling.", "generated_explanations": [["The context describes the stream as \"burbling,\" which may imply that it is a defining and ongoing characteristic of the stream at the Bras-David picnic area.", "e", "not_validated"], ["The context states that the stream is burbling at the time of mention, but does not provide information about whether it is always burbling.", "n", "validated"], ["There may be times when the stream is not burbling, such as during droughts or when the water level is low, but the context does not specify such conditions.", "n", "validated"], ["The context only mentions that the stream is burbling, not that it is always burbling.", "c", "validated"], ["Streams can vary with weather and seasons, so it may not burble at all times.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "77116e", "premise": "The third row of Exhibit 17 shows the Krewski, et al.", "hypothesis": "Exhibit 17 has many rows.", "generated_explanations": [["The mention of a \"third row\" in Exhibit 17 implies there are at least three rows, suggesting the existence of multiple rows.", "e", "validated"], ["The context only mentions the existence of a third row but does not specify the total number of rows in Exhibit 17.", "n", "validated"], ["\"Many\" is a subjective term, and the context does not provide enough information to determine whether the total number of rows qualifies as \"many.\"", "n", "validated"], ["The context only mentions the third row, so there is no evidence that Exhibit 17 has many rows.", "c", "validated"], ["It is possible that Exhibit 17 has exactly three rows or fewer, which would not qualify as \"many\".", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "76947n", "premise": "i think we have too thank you very much you too bye-bye", "hypothesis": "I don't think we can thank you enough for your help.", "generated_explanations": [["The phrase \"thank you very much\" in the context suggests a strong expression of gratitude, which aligns with the statement's implication that the gratitude might not be fully conveyed.", "e", "not_validated"], ["The polite and emphatic tone in the context implies a deep appreciation, supporting the idea that the help received is seen as invaluable or significant.", "e", "not_validated"], ["The context expresses thanks but does not provide enough information to determine whether the speaker feels they cannot thank the other person enough.", "n", "validated"], ["The emotional depth or adequacy of the gratitude conveyed in the context is not specified.", "n", "validated"], ["The context expresses gratitude and farewell, but does not mention any sense of insufficiency or inability to thank enough.", "c", "validated"], ["The context uses \"too thank you\" (likely meaning \"to thank you\") but does not suggest that the gratitude is inadequate or cannot be fully expressed.", "c", "validated"], ["The statement introduces \"for your help,\" but the context does not mention or reference any specific help received.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "139635n", "premise": "have that well and it doesn't seem like very many people uh are really i mean there's a lot of people that are on death row but there's not very many people that actually um do get killed", "hypothesis": "Most people on death row end up living out their lives awaiting execution.", "generated_explanations": [["The context states that there are not very many people who actually get killed despite many being on death row, implying most do not get executed.", "e", "validated"], ["The context suggests a discrepancy between the number of people sentenced to death and those actually executed, supporting the idea that most remain alive on death row.", "e", "validated"], ["The context states there are not many people who actually get killed on death row, but it doesn’t specify whether they live out their natural lives or if they are eventually executed after a long period, leaving it undetermined.", "n", "validated"], ["The context does not provide information about what ultimately happens to most people on death row, only that not many are actually killed, so it is unclear if they die by other causes or are released.", "n", "validated"], ["The context states that not very many people on death row actually get killed, but it does not provide information about whether they live out their natural lives awaiting execution; some could be executed eventually, released, or die of other causes.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "101245n", "premise": "we were lucky in that in one respect in that after she had her stroke she wasn't really you know really much aware of what was going on", "hypothesis": "She had a very serious stroke.", "generated_explanations": [["The context describes that after her stroke, she was not very aware of what was happening, which is indicative of a serious neurological impact consistent with a very serious stroke.", "e", "validated"], ["The context mentions that she was not \"really much aware of what was going on\" after her stroke, but it does not specify the severity of the stroke, so it is unclear whether it was \"very serious.\"", "n", "validated"], ["The phrase \"lucky in that... she wasn't really much aware\" could imply a less severe stroke if interpreted as reduced suffering or awareness, but it does not provide medical detail about seriousness.", "n", "validated"], ["Lack of explicit description of medical consequences or long-term effects leaves the seriousness of the stroke undetermined.", "n", "validated"], ["The context suggests she was not much aware of what was happening after the stroke, but it does not specify the severity of the stroke; being unaware does not necessarily mean the stroke was very serious.", "c", "validated"], ["The statement adds the qualifier \"very serious,\" which is not supported by the context, as there is no direct mention of the stroke's seriousness or medical impact beyond her subsequent lack of awareness.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "8545c", "premise": "He hadn't seen even pictures of such things since the few silent movies run in some of the little art theaters.", "hypothesis": "He had recently seen pictures depicting those things.", "generated_explanations": [["The context states he hadn't seen pictures of such things since a past time, but does not specify exactly how long ago that was, so \"recently\" is not clearly addressed.", "n", "validated"], ["The context mentions \"few silent movies\" but doesn't specify what \"those things\" refers to, leaving ambiguity about whether his recent experiences included pictures of those things.", "n", "validated"], ["He hadn't seen even pictures of such things since the time of silent movies, which implies he has not seen any recently.", "c", "validated"], ["The statement contradicts the context, as the context indicates a long period has passed since he last saw such pictures.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "8219n", "premise": "it depends a lot of uh a lot of things were thought that uh as you know the farmers thought okay we got chemicals we're putting chemicals on the field well the ground will naturally filter out the", "hypothesis": "The farming chemicals are filtered by the ground.", "generated_explanations": [["The farmers believed that the ground would naturally filter out the chemicals they applied to the field.", "e", "validated"], ["The context states that farmers thought the ground would naturally filter out the chemicals, but it does not confirm whether this actually happens.", "n", "validated"], ["There is no direct information in the context specifying the effectiveness or reality of the ground filtering the chemicals.", "n", "validated"], ["The phrase \"were thought\" suggests it is an assumption or belief, not a verified fact.", "n", "validated"], ["The context says that farmers *thought* the ground would naturally filter out the chemicals, implying this belief might not reflect reality.", "c", "validated"], ["The statement presents the filtering as a fact, whereas the context only discusses it as an assumption or expectation, not as an established outcome.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "115247c", "premise": "oh really yeah so he he's uh he's probably going to be going to jail and and the problem with him is he's on a guaranteed salary like for three years so whether he plays or not they've got to pay him ten million dollars so if they", "hypothesis": "He is so hardworking and has helped the team achieve so much, I don't see anything wrong with paying him a million dollar salary.", "generated_explanations": [["The context does not provide any information about his work ethic or contributions to the team.", "n", "validated"], ["The context focuses on his guaranteed salary in spite of potential jail time, not his deservingness or performance.", "n", "validated"], ["The context does not address whether paying him a million dollar salary is justified.", "n", "validated"], ["The context states he is going to jail, which likely means he cannot play or contribute to the team, contradicting the claim that he is helping the team achieve.", "c", "validated"], ["The context describes a guaranteed salary of ten million dollars, not a million dollar salary, as the reason for concern.", "c", "validated"], ["The context implies the salary is being paid regardless of his performance or presence due to legal troubles, countering the idea that the payment is justified by hard work or team contributions.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "99708e", "premise": "It was made up to look as much like an old-fashioned steam train as possible.", "hypothesis": "It was built in the modern era to look like something built in the past.", "generated_explanations": [["The phrase \"made up to look as much like an old-fashioned steam train as possible\" implies that the subject is not actually an old-fashioned steam train but is intended to resemble one.", "e", "validated"], ["The use of \"made up\" suggests construction or creation in a time later than when actual old-fashioned steam trains were built.", "e", "validated"], ["The context differentiates between the appearance (old-fashioned) and the construction (imitation), indicating the actual building occurred in a later, modern period.", "e", "validated"], ["The context mentions the train was \"made up\" to look like an old-fashioned steam train but does not specify when it was made, so it is unclear if it was built in the modern era.", "n", "validated"], ["The context does not clarify whether it is actually a modern construction or an authentic old train that was restored or modified.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "82415n", "premise": "Then he sobered.", "hypothesis": "He was drunk.", "generated_explanations": [["The act of sobering typically implies that he was previously under the influence of alcohol, i.e., drunk.", "e", "validated"], ["The context does not specify his prior state; \"sobered\" could mean becoming more serious or calm rather than ceasing to be drunk.", "n", "validated"], ["The word \"sobered\" can be used figuratively to indicate a change in mood or attitude, not necessarily implying previous intoxication.", "n", "validated"], ["Sobered can refer to becoming more serious or thoughtful, not necessarily to recovering from drunkenness.", "c", "validated"], ["There is no explicit mention of him having consumed alcohol or being drunk prior to sobering.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "82700c", "premise": "During his disastrous campaign in Russia, he found time in Moscow to draw up a new statute for the Com??die-Francaise (the national theater), which had been dissolved during the Revolution.", "hypothesis": "Russia has been successfully invaded hundreds of times.", "generated_explanations": [["The context mentions a campaign in Russia but does not provide information about the history or frequency of successful invasions of Russia.", "n", "validated"], ["The statement makes a general claim about Russian history that is not addressed or supported by the specific details given in the context.", "n", "validated"], ["The context describes a disastrous campaign in Russia, implying that the invasion was not successful.", "c", "validated"], ["There is no evidence or mention in the context that Russia has been successfully invaded hundreds of times; in fact, the example given highlights a failure.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "1073c", "premise": "News ' cover says the proliferation of small computer devices and the ascendance of Web-based applications are eroding Microsoft's dominance.", "hypothesis": "Microsoft is a more profitable company than Apple.", "generated_explanations": [["The context does not discuss or compare the profits or profitability of Microsoft and Apple.", "n", "validated"], ["The context only mentions changes in Microsoft's dominance, not its financial performance relative to Apple.", "n", "validated"], ["No financial data or metrics are provided for either company in the context.", "n", "validated"], ["The context discusses Microsoft’s declining dominance due to competition from small devices and web applications, but provides no information comparing profitability between Microsoft and Apple.", "c", "validated"], ["The statement asserts a financial comparison, which is unrelated to the information in the context regarding market dominance and technology trends.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "120149c", "premise": "There's a lot of villas all the way along, but by degrees they seemed to get more and more thinned out, and in the end we got to one that seemed the last of the bunch.", "hypothesis": "There were only a few villas the whole way along, until we reached a small village that seemed to be the end.", "generated_explanations": [["The context describes many villas that become fewer as they proceed, while the statement claims there were only a few villas the whole way along, creating uncertainty about the actual number of villas present along the route.", "n", "validated"], ["The context does not mention reaching a small village at the end, only the last villa, leaving it unclear whether a village was reached as the statement asserts.", "n", "validated"], ["The context states there were a lot of villas all the way along, not only a few.", "c", "validated"], ["The context mentions reaching the last villa, not a small village.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "124037n", "premise": "The park was established in 1935 and was given Corbett's name after India became independent.", "hypothesis": "The park changed names due to the independence.", "generated_explanations": [["The park was given Corbett's name after India became independent, indicating its name changed as a result of independence.", "e", "validated"], ["The context states the park was given Corbett's name after independence but does not clarify what its name was before independence, so it is not clear if a name change occurred specifically as a result of independence.", "n", "validated"], ["The reasoning or causality—whether independence was the reason for the name change or if it was coincidental—is not explicitly stated in the context.", "n", "validated"], ["The context only says the park was given Corbett's name after independence, not that it changed names because of independence.", "c", "validated"], ["The timing of the name change (after independence) does not imply causation (due to independence).", "c", "validated"], ["The context does not mention what the park's original name was or that it had a different name prior to being named after Corbett.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "92062c", "premise": "Krugman's column will henceforth be known as The Dismal Science, a phrase too famous to be ownable by anyone, except possibly British essayist Thomas Carlyle (1795-1881), who coined it.", "hypothesis": "Krugman writes novels.", "generated_explanations": [["The context discusses Krugman's column and its title but does not mention anything about Krugman writing novels.", "n", "validated"], ["There is no information provided about Krugman's professional activities beyond journalism or column writing.", "n", "validated"], ["The context focuses on the origin of the phrase \"The Dismal Science,\" not on Krugman's literary works or fiction writing.", "n", "validated"], ["The context discusses Krugman's column and its naming, but does not mention Krugman writing novels.", "c", "validated"], ["There is no evidence or information in the context indicating that Krugman is a novelist.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "131235c", "premise": "Even if the entire unified surplus were saved, GDP per capita would fall somewhat short of the U.S. historical average of doubling every 35 years.", "hypothesis": "Even if the entire unified surplus were lost, GDP per capita would fall somewhat short of the U.S. historical average of doubling every 35 years.", "generated_explanations": [["The context discusses the scenario where the surplus is saved, not lost, so the effect of losing the surplus on GDP per capita is not addressed.", "n", "validated"], ["The impact on GDP per capita when the surplus is lost could differ from when it is saved; losing the surplus might decrease GDP per capita even further or have a different effect altogether.", "n", "validated"], ["No quantitative information is given about the magnitude of the surplus or the economic mechanisms involved in losing it, so the specific outcome for GDP per capita in that case is unknown.", "n", "validated"], ["The context discusses the outcome if the entire surplus were saved, but the statement changes this to the entire surplus being lost, which would likely lead to a far worse outcome for GDP per capita.", "c", "validated"], ["Saving the surplus implies a positive contribution to economic growth, while losing it implies a negative impact; therefore, the effect on GDP per capita would be significantly different in each scenario.", "c", "validated"], ["The context indicates that even the most optimistic scenario (saving the entire surplus) only marginally fails to meet the doubling rate, whereas losing the surplus would presumably cause GDP per capita growth to fall much further below the historical average.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "46820e", "premise": "and my and my part-time work you know it's not our the restaurant our favorite restaurant in the town of Salisbury where actually we live you know where my where i'll return to my job or whatever we can normally eat out for um under fourteen dollars", "hypothesis": "My first part time job was in a restaurant in Salisbury where you could eat out for under $14.", "generated_explanations": [["The context mentions having part-time work at a restaurant in Salisbury.", "e", "validated"], ["The context states that at this restaurant, it is possible to eat out for under fourteen dollars.", "e", "not_validated"], ["The context does not specify whether the speaker's first part-time job was at the restaurant in Salisbury; it only mentions \"my part-time work\" and refers to returning to a job.", "n", "validated"], ["The context does not clarify whether the restaurant mentioned is the same place as the speaker's part-time job.", "n", "validated"], ["The statement implies a first part-time job, but the context does not indicate if this was the speaker's first or only part-time job.", "n", "validated"], ["While it is mentioned that one can eat out for under fourteen dollars at the restaurant in Salisbury, it is not clear if this was true at the time of the speaker's first part-time job or just currently.", "n", "validated"], ["The context does not state that the restaurant was the speaker's first part-time job, only that it is their current part-time work.", "c", "validated"], ["The context does not specify that the speaker works at the restaurant; it only mentions that the restaurant is their favorite in Salisbury and where they live.", "c", "validated"], ["The context does not establish any order of employment, so it is not clear whether this was the first part-time job.", "c", "validated"], ["The statement assumes the restaurant where you can eat for under $14 is where the speaker’s first part-time job was, but the context does not link those details.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 4, "c": 4}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "77590c", "premise": "do you think most states have that or", "hypothesis": "I think most states have that.", "generated_explanations": [["The statement directly repeats the main idea of the context, affirming agreement.", "e", "validated"], ["The context presents a yes/no question, and the statement offers a positive belief in response.", "e", "validated"], ["The context is a question, and the statement expresses a belief, making it unclear whether the statement is an answer, an assumption, or unrelated.", "n", "validated"], ["The context lacks information about the referent of \"that,\" so it is unknown if the speaker's belief is about the same thing mentioned in the context.", "n", "validated"], ["The context does not confirm or deny whether most states actually have \"that,\" so the truth of the statement is indeterminate.", "n", "validated"], ["The context does not indicate the identity or authority of the speaker asserting the statement, leaving uncertainty about their knowledge or reliability.", "n", "validated"], ["The context is a question asking for an opinion or confirmation, not a statement asserting that most states have that, so the statement attributes an assertion that isn't present in the context.", "c", "validated"], ["The statement expresses a personal belief, while the context does not reveal any inclination toward agreement or belief, only curiosity.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "128542e", "premise": "There should be someone here who knew more of what was going on in this world than he did now.", "hypothesis": "He knew things, but hoped someone else knew more.", "generated_explanations": [["The context states a desire for someone present who possesses more knowledge than he currently does, implying he already has some knowledge but believes others may have greater understanding.", "e", "validated"], ["The statement reflects that he acknowledges his own knowledge yet wishes or hopes for someone else to surpass his current level of understanding, aligning with the context’s sentiment.", "e", "validated"], ["The context suggests a desire or expectation that someone else should be more knowledgeable, but does not specify what he himself knows or hopes.", "n", "validated"], ["The context does not mention whether he actually hopes someone else knows more, only that there should be such a person.", "n", "validated"], ["The context leaves ambiguous what \"knew more\" refers to—relative knowledge is implied but not confirmed.", "n", "validated"], ["The context makes no explicit claim about the character's self-assessment or acknowledgment of his own knowledge.", "n", "validated"], ["The context expresses uncertainty about whether such a knowledgeable person exists, whereas the statement assumes his hope for someone else knowing more.", "c", "not_validated"], ["The context emphasizes the need or expectation for someone else with more knowledge, not necessarily his own hope or belief.", "c", "not_validated"], ["The context does not confirm that he himself has any knowledge, while the statement asserts that he \"knew things.\"", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 2}}
{"id": "74768e", "premise": "She admits to Dorcas, 'I don't know what to do; scandal between husband and wife is a dreadful thing.' At 4 o'clock she has been angry, but completely mistress of herself.", "hypothesis": "She had remained in control despite her anger.", "generated_explanations": [["The context states she was \"completely mistress of herself\" at 4 o'clock, indicating she maintained control of her emotions.", "e", "validated"], ["The passage explicitly contrasts her anger with her self-mastery, supporting that she did not let her anger override her self-control.", "e", "validated"], ["The context indicates she was \"completely mistress of herself\" at 4 o'clock, implying control, but does not specify whether this self-mastery continued beyond that point.", "n", "validated"], ["The admission to Dorcas, \"I don't know what to do,\" suggests uncertainty or distress, which could indicate a lapse in control after 4 o'clock, but this is not explicitly confirmed.", "n", "validated"], ["The context only states she was \"completely mistress of herself\" at 4 o'clock, not that she remained in control throughout or despite her anger.", "c", "validated"], ["The phrase \"has been angry, but completely mistress of herself\" does not specify that control was maintained despite anger, just that the states coexisted at that moment.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "122928e", "premise": "A small page-boy was waiting outside her own door when she returned to it.", "hypothesis": "When she came back to her door she found something waiting.", "generated_explanations": [["The small page-boy was waiting outside her door, which means something (the page-boy) was waiting when she returned.", "e", "validated"], ["The context specifies that a small page-boy was waiting, but the statement refers vaguely to \"something,\" which could imply an object or an unspecified thing, leaving it unclear whether the waiting entity matches in both.", "n", "validated"], ["The gender pronoun \"her\" is used for the person returning to the door and also for the door's owner, but it is not explicitly confirmed that they are the same individual.", "n", "validated"], ["The context specifies that the page-boy was waiting, not just \"something,\" which could refer to an object or anything unspecified.", "c", "not_validated"], ["The context identifies the thing waiting as a person (the page-boy), while the statement is vague and does not convey this specific information.", "c", "not_validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "139409e", "premise": "Then, all the time, it was in the spill vase in Mrs. Inglethorp's bedroom, under our very noses? I cried.", "hypothesis": "You mean we were so near it constantly?", "generated_explanations": [["The spill vase was located in Mrs. Inglethorp's bedroom, which means the object of interest was physically close to where the people were present.", "e", "validated"], ["The phrase \"under our very noses\" implies that they were frequently in proximity to the spill vase and thus to \"it\" without realizing its significance.", "e", "validated"], ["The context mentions the object was in Mrs. Inglethorp's bedroom, but does not explicitly state whether \"we\" were near the spill vase or in her bedroom frequently.", "n", "validated"], ["The context does not clarify who \"we\" refers to or how often they were physically present near the vase.", "n", "validated"], ["The context specifies the location as Mrs. Inglethorp's bedroom, implying proximity specifically there, whereas \"we\" in the statement may refer to people in general, not necessarily present in that room constantly.", "c", "not_validated"], ["The phrase \"under our very noses\" may be figurative, meaning it was overlooked despite being accessible, not that the individuals were physically near it at all times.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "59208n", "premise": "He's chosen Meg Ryan.", "hypothesis": "A possible selection would be Meg Ryan or Jon Doe.", "generated_explanations": [["He chose Meg Ryan, so Meg Ryan is a possible selection.", "e", "validated"], ["The statement includes Meg Ryan as one of the possible selections, which aligns with the fact that he chose her.", "e", "validated"], ["The context confirms only the selection of Meg Ryan but does not specify whether Jon Doe was also an available or considered option.", "n", "validated"], ["The context does not clarify if choices other than Meg Ryan were possible at the time of selection.", "n", "validated"], ["The context does not indicate whether Meg Ryan and Jon Doe were both possible selections before the choice was made.", "n", "validated"], ["Jon Doe cannot be a possible selection since \"he's chosen Meg Ryan,\" implying the selection has already been made and is not between both individuals.", "c", "validated"], ["The use of \"or\" suggests multiple options are available, but the context indicates only Meg Ryan was chosen, not Jon Doe.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "133597n", "premise": "In manual systems, attestations, verifications, and approvals are usually shown by a signature or initial of an individual on a hard copy document.", "hypothesis": "The only things that signatures in manual systems show are attestations, verifications, or approvals.", "generated_explanations": [["The context states that signatures \"are usually shown\" for attestations, verifications, and approvals, but does not exclude the possibility that signatures may also represent other things in manual systems.", "n", "validated"], ["The context does not specify that attestations, verifications, and approvals are the exclusive functions of signatures in manual systems; signatures could also be used for acknowledgments, receipts, or other purposes.", "n", "validated"], ["The context mentions how attestations, verifications, and approvals are indicated, but does not provide a comprehensive or exhaustive list of all purposes for which signatures might be used in manual systems.", "n", "validated"], ["Signatures in manual systems can also indicate receipt or acknowledgment of a document, not just attestation, verification, or approval.", "c", "validated"], ["Signatures may be used to indicate responsibility or accountability for a particular task or section of a document.", "c", "validated"], ["Signatures could serve as confirmation of having read or reviewed a document, without necessarily attesting, verifying, or approving its content.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "80517e", "premise": "This doesn't look good.", "hypothesis": "This looks really bad.", "generated_explanations": [["Saying \"this doesn't look good\" implies a negative assessment, which aligns with \"this looks really bad,\" expressing a stronger form of negativity.", "e", "validated"], ["\"Doesn't look good\" is a mild way to say something is bad, so \"looks really bad\" intensifies the sentiment but does not contradict it.", "e", "validated"], ["The context expresses a negative sentiment but does not specify the severity, so “really bad” might be an exaggeration not supported by the context.", "n", "validated"], ["“Doesn’t look good” could mean anything from mildly negative to terrible, making it unclear if “really bad” accurately captures the intended intensity.", "n", "validated"], ["\"Doesn't look good\" could mean it looks mediocre or just not great, rather than \"really bad,\" which is more extreme.", "c", "validated"], ["The speaker might mean that it simply fails to meet expectations, rather than being outright bad.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "93236c", "premise": "The word itself, tapa, is translated as  lid  and derives from the old custom of offering a bite of food along with a drink, the food being served on a saucer sitting on top of the glass like a lid.", "hypothesis": "Tapas are large portions and are a very filling meal.", "generated_explanations": [["The context only explains the origin of the word \"tapa\" and the custom of serving it with drinks, but does not mention the portion size or whether they are filling.", "n", "validated"], ["There is no information in the context about the quantity of food served as tapas, so it is undetermined whether they are large portions or a filling meal.", "n", "validated"], ["Tapas are traditionally small portions meant to accompany drinks, not large portions.", "c", "validated"], ["Tapas are designed to be snacks or appetizers, not to constitute a full or very filling meal.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "142643c", "premise": "The standard technology assumptions of scenario A were used by EIA in the development of the AEO2001 reference case projections.", "hypothesis": "EIA used the standard technology assumptions to eliminate the AEO2001 reference case projections.", "generated_explanations": [["The context states that the standard technology assumptions were used in the development of the projections, but it does not specify that these assumptions were used to eliminate the projections.", "n", "validated"], ["The context does not mention anything about eliminating the reference case projections, only about developing them.", "n", "validated"], ["The context states that the standard technology assumptions were used \"in the development\" of the AEO2001 reference case projections, not to eliminate them.", "c", "validated"], ["There is no indication in the context that anything was eliminated; rather, the projections were created or developed.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "31113e", "premise": "One wag, J., wrote in to ask, Is there a difference between pests and airlines?", "hypothesis": "J. thinks there is no difference between pests and airlines.", "generated_explanations": [["J.'s question implies a comparison between pests and airlines in a way that suggests similarity, possibly sarcastically indicating he sees no meaningful difference.", "e", "validated"], ["The phrasing of J.'s question is structured to suggest that pests and airlines are equally objectionable or annoying, indicating he equates the two.", "e", "validated"], ["The context does not reveal J.'s actual opinion; it only shows that J. asked a question about the difference.", "n", "validated"], ["The statement interprets the question as an expression of belief, but asking whether a difference exists does not confirm J.'s belief one way or the other.", "n", "validated"], ["The phrase \"Is there a difference between pests and airlines?\" is a question, not a statement of belief, so it does not indicate J.’s opinion about whether a difference exists.", "c", "validated"], ["J. may be making a joke or sarcastic remark by asking the question, rather than sincerely expressing the belief that no difference exists.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "34776c", "premise": "We did not study the reasons for these deviations specifically, but they likely result from the context in which federal CIOs operate.", "hypothesis": "The Context in which federal CIOs operate is no different from other CIOs.", "generated_explanations": [["The context does not compare federal CIOs directly to other CIOs, so there is no information about whether the contexts are the same or different.", "n", "validated"], ["The statement assumes knowledge about other CIOs’ contexts that is not provided in the context.", "n", "validated"], ["The statement implies that there is no difference in context for federal CIOs compared to other CIOs, but the context suggests that deviations are attributed specifically to the context in which federal CIOs operate, indicating it is indeed different.", "c", "validated"], ["If the context were no different, there would be no reason to cite it as a likely cause for deviations among federal CIOs.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "121422c", "premise": "it it like strange that it you're right in the middle of the mountains and it's so brown and dry but boy you just didn't feel", "hypothesis": "you are in the right part of the mountains.", "generated_explanations": [["The speaker mentions being \"right in the middle of the mountains,\" indicating correct location within the mountains.", "e", "validated"], ["The use of present experience (\"you're right in the middle\") suggests the person is currently situated in the correct mountainous area.", "e", "validated"], ["The context describes the speaker being in the mountains but does not specify which part of the mountains they are in.", "n", "validated"], ["The statement \"the right part of the mountains\" is subjective; the context does not clarify what qualifies as the \"right\" part.", "n", "validated"], ["The description of the area as \"brown and dry\" does not indicate whether this is characteristic of the \"right\" part of the mountains.", "n", "validated"], ["The speaker describes the surroundings as \"so brown and dry,\" which may imply they are not in the typical verdant or lush part of the mountains one might expect.", "c", "validated"], ["The use of \"strange\" suggests that the appearance doesn't match what is usually characteristic of being in the right or expected area of mountains.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "104805e", "premise": "California is high", "hypothesis": "California is hyped up!", "generated_explanations": [["The phrase \"high\" can be interpreted metaphorically as being in a state of excitement or popularity, which aligns with \"hyped up.\"", "e", "not_validated"], ["\"Hyped up\" is slang that can mean overly excited or energized, similar to a non-literal interpretation of \"high.\"", "e", "validated"], ["Both phrases suggest California is in an elevated or intensified state, either emotionally, socially, or energetically.", "e", "not_validated"], ["The word \"high\" in the context could refer to geographical elevation, emotional state, or drug use, while \"hyped up\" specifically refers to excitement or exaggerated promotion, making the connection between the two uncertain.", "n", "validated"], ["\"High\" and \"hyped up\" are not direct synonyms and can represent different conditions, so it's unclear if one implies the other in this context.", "n", "validated"], ["The context does not specify whether \"high\" is being used figuratively or literally, whereas the statement assumes a figurative sense related to excitement or publicity, leading to ambiguity.", "n", "validated"], ["Describing California as \"high\" refers to physical elevation or altitude, not excitement, popularity, or enthusiasm, which \"hyped up\" implies.", "c", "validated"], ["\"High\" could also refer to legal cannabis culture, whereas \"hyped up\" refers to social excitement, making the two statements unrelated.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 2}}
{"id": "115821n", "premise": "The Chinese calendar was used to calculate the year of Japan's foundation by counting back the 1,260 years of the Chinese cosmological cycle.", "hypothesis": "The calculation of Japan's year of foundation was very exact.", "generated_explanations": [["The calculation was based on the fixed length of the Chinese cosmological cycle, which is 1,260 years, providing a clear and systematic method.", "e", "validated"], ["The Chinese calendar is a well-documented and structured system, lending precision to any historical calculations based on it.", "e", "not_validated"], ["The context does not specify whether the Chinese cosmological cycle accurately corresponds to historical events or records in Japan.", "n", "validated"], ["The process of counting back using the cosmological cycle does not guarantee historical accuracy due to potential mythologization or retrospective assumptions.", "n", "validated"], ["The context does not provide information about the specific methods or standards of accuracy used in the calculation.", "n", "validated"], ["The calculation was based on a cosmological cycle rather than concrete historical evidence, making it symbolic rather than precise.", "c", "validated"], ["Counting back from the present using cycles does not account for possible errors or uncertainties in the original record-keeping.", "c", "validated"], ["The use of the Chinese calendar for Japanese history involves cultural adaptation and may not reflect actual historical chronology.", "c", "validated"], ["The calculation assumes uninterrupted cycles and does not adjust for differences in calendar systems or reforms over time.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 4}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "80630e", "premise": "The tree-lined avenue extends less than three blocks to the sea.", "hypothesis": "The sea isn't even three blocks away.", "generated_explanations": [["The avenue, which reaches to the sea, measures less than three blocks long, indicating the sea is located within that distance.", "e", "validated"], ["If the avenue extends to the sea and is less than three blocks, the sea must be situated less than three blocks from the start of the avenue.", "e", "validated"], ["The context specifies the avenue extends less than three blocks to the sea but does not state whether the sea itself is within three blocks or if there is additional distance beyond the avenue before reaching the sea.", "n", "validated"], ["It is unclear if the measurement (\"less than three blocks\") is direct or refers only to the portion of the avenue, not the total distance to the sea.", "n", "not_validated"], ["The starting point of the measurement (where the avenue begins) is not defined, so the total distance from an arbitrary reference point to the sea is ambiguous.", "n", "not_validated"], ["The avenue could end before it reaches the sea, so the sea might not actually be within three blocks from the avenue's end.", "c", "validated"], ["The context specifies the length of the avenue, not the distance from where the avenue starts or ends to the sea, so the actual distance to the sea could be more than three blocks depending on where the measurement is taken.", "c", "validated"], ["\"Extends less than three blocks to the sea\" might mean the avenue heads in the direction of the sea for less than three blocks, but the sea could be farther away off the avenue's extension.", "c", "validated"], ["The statement implies an exact distance, but the context only gives an approximate direction and range, not a precise measurement.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 1, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"n": 2, "c": 1}}
{"id": "138862c", "premise": "Also, other sorbent-based approaches in development may prove in time to be preferable to ACI, making the use of ACI only a conservative assumption.", "hypothesis": "Hydrogen-based approaches in development may be preferable to ACl.", "generated_explanations": [["The context discusses sorbent-based approaches, not hydrogen-based approaches, so it does not provide information about hydrogen-based methods.", "n", "validated"], ["There is no mention of ACl in the context; the context refers to ACI, so the relationship between hydrogen-based approaches and ACl is undetermined.", "n", "validated"], ["The preference for hydrogen-based approaches over ACl is not addressed or implied by the information given in the context.", "n", "validated"], ["The context discusses \"sorbent-based approaches,\" not \"hydrogen-based approaches.\"", "c", "validated"], ["The context references \"ACI,\" not \"ACl.\"", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "105179c", "premise": "I was to watch for an advertisement in the Times.", "hypothesis": "I looked for an ad in my mailbox.", "generated_explanations": [["The context specifies watching for an advertisement in the Times (a newspaper), but the statement describes looking for an ad in a mailbox, which typically contains postal mail, not newspapers.", "n", "validated"], ["There is no explicit information linking the advertisement in the Times to something being received in the mailbox.", "n", "validated"], ["The statement does not clarify whether the advertisement in the Times could or would also appear in the mailbox, leaving the relationship ambiguous.", "n", "validated"], ["The context specifies watching for an advertisement in the Times (a newspaper), not in a mailbox.", "c", "validated"], ["Looking in a mailbox implies expecting a physical delivery, not a newspaper advertisement.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "109876n", "premise": "Text Box 2.1: Gross Domestic Product and Gross National Product 48Text Box 4.1: How do the NIPA and federal unified budget concepts of", "hypothesis": "This text displays how GDP and GNP is calculated.", "generated_explanations": [["The text box titles explicitly reference Gross Domestic Product (GDP) and Gross National Product (GNP), indicating the content likely covers their calculation.", "e", "validated"], ["The text box is labeled with a section number and title focused specifically on GDP and GNP, which are commonly explained via their calculation methods in economics texts.", "e", "validated"], ["The context mentions national income accounting concepts, which typically include explanations of how GDP and GNP are computed.", "e", "validated"], ["The context mentions Text Boxes discussing GDP, GNP, NIPA, and federal budget concepts but does not explicitly state that the calculation methods for GDP and GNP are displayed.", "n", "validated"], ["The content of the referenced text boxes is not provided, so it is unclear whether they present calculation methods or only discuss concepts and definitions.", "n", "validated"], ["The text does not display the actual calculations of GDP and GNP but rather discusses their definitions or conceptual differences.", "c", "validated"], ["The text refers to the concepts used in NIPA and the federal budget rather than providing step-by-step calculations for GDP and GNP.", "c", "validated"], ["The titles suggest the focus is on explaining terms and distinctions, not performing or showing detailed calculations.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "65353n", "premise": "Don't take it to heart, lad, he said kindly.", "hypothesis": "He was trying to console the lad.", "generated_explanations": [["The phrase \"Don't take it to heart\" is commonly used to comfort someone who may be upset or offended.", "e", "validated"], ["The addition of \"he said kindly\" indicates a gentle and supportive tone, suggesting an attempt to provide comfort or reassurance.", "e", "validated"], ["The context shows the speaker addressing the lad \"kindly,\" but it does not specify the speaker's intent beyond the manner of speaking.", "n", "validated"], ["The statement interpreting the words as an attempt to \"console\" relies on inferring the speaker's motive, which is not explicitly provided in the context.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "16494c", "premise": "It cannot be outlawed.", "hypothesis": "It has to be made illegal.", "generated_explanations": [["The context states that \"it cannot be outlawed,\" which means making it illegal is not possible, but the statement claims it \"has to be made illegal,\" leaving uncertainty about whether the statement is discussing a legal requirement, a moral imperative, or simply expressing an opinion.", "n", "validated"], ["The context does not specify the subject (\"it\"), creating ambiguity about whether there might be conditions or exceptions under which \"it\" could actually be made illegal.", "n", "validated"], ["The relationship between the ability to outlaw something and the necessity to do so is not clear—something that cannot be outlawed in practice might still be argued (in the statement) as needing to be outlawed in principle, making the inference undetermined.", "n", "validated"], ["The context asserts that it cannot be outlawed, which directly contradicts the statement that it has to be made illegal, since making something illegal is equivalent to outlawing it.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "60732n", "premise": "It started with The Wild Bunch : We sexualized violence, we made it beautiful.", "hypothesis": "Violence is now look at in the positive due to The Wild Bunch.", "generated_explanations": [["The context indicates that \"we made [violence] beautiful,\" suggesting a shift in the aesthetic portrayal of violence initiated by The Wild Bunch, which could be interpreted as fostering a more positive or appealing view of violence.", "e", "not_validated"], ["The context claims \"we sexualized violence,\" implying an added allure or desirability to violent acts, potentially causing them to be regarded more positively.", "e", "not_validated"], ["The context states that violence was sexualized and made beautiful, but does not explicitly say that violence is now viewed positively as a result.", "n", "validated"], ["The context describes how violence was presented, but does not detail the public or critical reception or attitude towards violence after The Wild Bunch.", "n", "validated"], ["The phrase \"we made it beautiful\" describes aestheticization, not necessarily a positive moral evaluation.", "n", "validated"], ["The context mentions that violence was sexualized and made beautiful, but does not state that violence is now viewed positively as a result.", "c", "validated"], ["The context describes a change in presentation (making violence beautiful), not a change in moral evaluation (considering violence as positive).", "c", "validated"], ["The context refers specifically to the film \"The Wild Bunch\" and its influence on the depiction of violence, not on societal attitudes towards violence overall.", "c", "validated"], ["The context does not claim a causal link between The Wild Bunch and a general positive view of violence.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 4}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "88646c", "premise": "You see, he said sadly, \"you have no instincts.\"", "hypothesis": "He said that I had no willpower.", "generated_explanations": [["The context mentions \"instincts,\" while the statement refers to \"willpower,\" and it is unclear whether he equates the two concepts or if the statement is a paraphrase or interpretation.", "n", "validated"], ["The context does not mention \"willpower\" directly, so it is undetermined if he actually said or implied that.", "n", "validated"], ["The context shows that he specifically said, \"you have no instincts,\" not \"you have no willpower.\"", "c", "validated"], ["Instincts and willpower are different concepts; lacking instincts does not imply lacking willpower.", "c", "validated"], ["The statement misquotes what was actually said in the context.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "53074n", "premise": "ooh it's kind of tough to think of some of the others although i do watch some of some of those frivolous things uh like on Thursday nights at nine o'clock when i get home from aerobics i will watch uh Knots Landing", "hypothesis": "I only watch frivolous things on Thursday nights.", "generated_explanations": [["The context mentions watching \"some of those frivolous things\" but does not state that Thursday night is the only time the speaker watches frivolous things.", "n", "validated"], ["The phrase \"some of the others\" implies the speaker may watch other frivolous things at times not specified.", "n", "validated"], ["The statement generalizes to \"only\" Thursday nights, but the context does not exclude the possibility of watching frivolous things on other nights.", "n", "validated"], ["The context states \"I do watch some of those frivolous things,\" which implies the speaker watches frivolous things at times other than Thursday night.", "c", "validated"], ["The word \"although\" suggests watching frivolous things is not limited to Thursday nights.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "61818n", "premise": "Kutchins and Kirk cite a particularly amusing example of such  Robert Spitzer, the man in charge of DSM-III , was sitting down with a committee that included his wife, in the process of composing a criteria-set for Masochistic Personality Disorder--a disease that was suggested for, but never made it into, the DSM-III-R (a revised edition).", "hypothesis": "DSM-III-R is a book of personality disorders.", "generated_explanations": [["DSM-III-R is mentioned in the context of composing criteria for a personality disorder, implying it contains information about personality disorders.", "e", "validated"], ["The DSM series (including DSM-III-R) is known for cataloging mental disorders, including personality disorders.", "e", "validated"], ["The context mentions that DSM-III-R is a revised edition and discusses deliberations about including a personality disorder, but it does not state that the book exclusively contains personality disorders; it could cover other types of mental disorders as well.", "n", "validated"], ["The context does not clarify whether DSM-III-R is a book, a manual, or some other type of publication.", "n", "validated"], ["DSM-III-R is not exclusively a book of personality disorders; it is a comprehensive manual that covers a wide range of mental disorders, not just personality disorders.", "c", "validated"], ["Masochistic Personality Disorder was suggested for DSM-III-R but was never actually included, indicating that not all proposed personality disorders were included in the book.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "46003n", "premise": "trying to keep grass alive during a summer on a piece of ground that big was expensive", "hypothesis": "The watering and fertilizer, can cost a lot to keep grass alive in the summer months.", "generated_explanations": [["Keeping grass alive during the summer typically requires regular watering and fertilizing, which both incur costs.", "e", "validated"], ["The context mentions expense related to grass maintenance, implying costs such as watering and fertilizer are contributing factors.", "e", "validated"], ["Large areas of grass require significant resources, increasing the amount and cost of water and fertilizer needed during hot months.", "e", "validated"], ["The context mentions expense but does not specify whether the cost is due to watering, fertilizer, or other factors.", "n", "validated"], ["The context does not confirm if fertilizer was used or contributed to the expense.", "n", "validated"], ["The statement suggests that both watering and fertilizer can be costly, but the context only references the overall expense of keeping grass alive, without itemizing specific costs.", "n", "validated"], ["The context refers to \"a piece of ground that big,\" leaving it unclear if the expense is primarily due to the size rather than the inputs listed in the statement.", "n", "validated"], ["The context only mentions the overall expense of keeping grass alive, but does not specify that the cost comes from watering and fertilizer.", "c", "validated"], ["Other potential expenses besides watering and fertilizer (such as soil treatment, mowing, pest control, or equipment maintenance) could be significant contributors to the cost.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "6386n", "premise": "isn't it i can remember i've only been here eight years but i can remember coming to work from i used to live in Wylie and i could see downtown Dallas", "hypothesis": "Downtown Dallas was a short drive from where I lived in Wylie.", "generated_explanations": [["The speaker mentions coming to work from Wylie and being able to see downtown Dallas, suggesting the two locations are close enough for visibility, which often implies a relatively short drive.", "e", "validated"], ["The context only mentions that the speaker could see downtown Dallas from Wylie but does not specify how long the drive was.", "n", "validated"], ["The ability to see downtown Dallas does not necessarily indicate physical proximity or a short driving distance.", "n", "validated"], ["No information is given about typical travel routes or traffic conditions between Wylie and downtown Dallas.", "n", "validated"], ["The context only mentions being able to see downtown Dallas from Wylie, not the distance or duration of a drive.", "c", "validated"], ["Visibility of a location does not imply that it is a short drive away; distant landmarks can be seen from far away.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "98739n", "premise": "The living is not equal to the Ritz, he observed with a sigh.", "hypothesis": "The living is nothing compared to the glamour of the Ritz, he said sadly.", "generated_explanations": [["Both the context and statement express that \"the living\" is inferior or less desirable than the Ritz.", "e", "validated"], ["Both indicate the speaker's emotional response (sigh/sadly) when making the comparison.", "e", "not_validated"], ["Both highlight a contrast between the quality of \"the living\" and the luxury or glamour associated with the Ritz.", "e", "validated"], ["The context mentions a sigh, while the statement describes him as saying something \"sadly\"; it is unclear whether sighing equates to speaking sadly.", "n", "validated"], ["The context notes that \"the living is not equal to the Ritz,\" whereas the statement claims \"the living is nothing compared to the glamour of the Ritz\"; \"not equal to\" and \"nothing compared to\" may differ in strength of meaning.", "n", "validated"], ["The context does not specifically reference \"the glamour\" of the Ritz, only the Ritz itself, so it is uncertain if the comparison is drawn specifically to its glamour.", "n", "validated"], ["The context says \"he observed,\" while the statement says \"he said,\" making it unclear if he voiced the thought or merely thought it.", "n", "not_validated"], ["The context uses the phrase \"not equal to the Ritz,\" which implies a comparison but not an absolute negation, while the statement says \"nothing compared to the glamour of the Ritz,\" which is a stronger, more absolute comparison.", "c", "validated"], ["The context describes the speaker's emotion as a \"sigh,\" whereas the statement says he spoke \"sadly,\" which explicitly labels the emotion.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1, "n": 1, "c": 1}}
{"id": "108624c", "premise": "Exhibit 3 presents total national emissions of NOx and SO2 from all sectors, including power.", "hypothesis": "In Exhibit 3 there are the total regional emissions od NOx and SO2 from all sectors.", "generated_explanations": [["The context specifies national emissions, while the statement refers to regional emissions, and it is unclear if national data are broken down by regions in Exhibit 3.", "n", "validated"], ["The context confirms the presence of total emissions for the nation, but it does not mention whether regional totals are displayed.", "n", "validated"], ["Exhibit 3 presents total national emissions, not regional emissions.", "c", "validated"], ["The statement refers to \"od,\" which appears to be a typo or unclear term.", "c", "not_validated"], ["The context specifies “from all sectors, including power,” but the statement does not mention the inclusion of the power sector.", "c", "not_validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 2}}
{"id": "106013c", "premise": "Ca'daan heard the Kal grunt and felt the horse lift.", "hypothesis": "The Kal heard Ca'daan grunt.", "generated_explanations": [["The context only mentions Ca'daan hearing the Kal grunt; it does not specify whether the Kal heard any sound from Ca'daan.", "n", "validated"], ["There is no information about the Kal's attention or ability to hear in the given scenario.", "n", "validated"], ["There is no information indicating that Ca'daan grunted.", "c", "validated"], ["There is no information indicating that the Kal heard any sound from Ca'daan.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "37407n", "premise": "5 are highly correlated during summer months in some areas.", "hypothesis": "Six are correlated to winter in certain areas.", "generated_explanations": [["The exact number of correlated entities differs between the context and the statement (five vs. six), so there is insufficient information to determine whether six are correlated.", "n", "validated"], ["The correlation is specified for different seasons (\"summer\" in the context and \"winter\" in the statement), so it is unclear if the same or different entities are involved in correlation during different seasons.", "n", "validated"], ["The geographic locations (\"some areas\" vs. \"certain areas\") may or may not overlap, leaving uncertainty about whether the correlation in one scenario applies to the other.", "n", "validated"], ["The context mentions five items, while the statement refers to six, indicating a mismatch in quantity.", "c", "validated"], ["The context specifies correlation during summer months, whereas the statement claims correlation to winter, indicating a mismatch in season.", "c", "validated"], ["The context uses \"highly correlated,\" but the statement only says \"correlated,\" which may imply a different strength or type of correlation.", "c", "not_validated"], ["The context limits correlation to \"some areas,\" while the statement says \"certain areas,\" which could refer to a different set of locations.", "c", "not_validated"]], "label_count_round_1": {"n": 3, "c": 4}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 2}}
{"id": "70590c", "premise": "China's civil war sent distressing echoes to Hong Kong.", "hypothesis": "Japan fought a civil war.", "generated_explanations": [["The context discusses China's civil war but does not mention Japan or provide any information about Japan's history.", "n", "validated"], ["There is no indication in the context about whether Japan experienced a civil war, making it impossible to determine the truth of the statement based on the given information.", "n", "validated"], ["The context refers specifically to China's civil war, not Japan.", "c", "validated"], ["There is no mention of Japan being involved in a civil war in the context given.", "c", "validated"], ["Historically, Japan did not have a civil war that is relevant to the context; Japan's most notable civil conflict, the Boshin War, occurred in the 19th century, not contemporaneous with the Chinese civil war.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "23901e", "premise": "Then Shuman claims that Linux provides no graphical user interface.", "hypothesis": "They made accusations about the platform.", "generated_explanations": [["Shuman's claim that Linux provides no graphical user interface is an accusation about the platform.", "e", "validated"], ["The context only mentions Shuman's claim about Linux lacking a graphical user interface and does not specify whether this was characterized as an accusation or simply a claim.", "n", "validated"], ["The statement \"They made accusations about the platform\" refers to \"they,\" but the context mentions only Shuman and does not clarify whether more than one person was involved.", "n", "not_validated"], ["It is unclear whether Shuman's claim was intended as an accusation or as a factual observation or critique, so it cannot be determined if it qualifies as making accusations.", "n", "validated"], ["The statement refers to \"they\" making accusations, but only Shuman is mentioned as making a claim.", "c", "validated"], ["Shuman's statement is a claim about a specific feature (lack of graphical user interface) rather than a general accusation about the platform.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "23280n", "premise": "Sphinxes were guardian deitiesinEgyptianmythologyandthis was monumentalprotection,standing73 m (240 ft)longand20 m (66 feet) high.", "hypothesis": "Sphinxes were put in the tombs to protect the dead.", "generated_explanations": [["Sphinxes were considered guardian deities in Egyptian mythology, implying a protective role over important sites such as tombs.", "e", "not_validated"], ["The monumental size and presence of sphinxes indicate their function as protectors, which could extend to guarding tombs and the dead within.", "e", "not_validated"], ["The context states that sphinxes were guardian deities and describes a monumental statue, but does not specify that they were placed inside tombs.", "n", "validated"], ["The context does not mention any association between sphinxes and the protection of the dead specifically.", "n", "validated"], ["The context refers to sphinxes as providing \"monumental protection,\" but it is unclear whether this protection was directed at tombs or something else.", "n", "validated"], ["The context specifies that sphinxes were monumental guardians, not placed inside tombs but rather as large statues, implying their protective role was external and ceremonial rather than being physically placed within tombs.", "c", "validated"], ["The given dimensions (73 m long and 20 m high) indicate that sphinxes, at least the famous examples like the Great Sphinx, were too large to be placed inside tombs.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "135247c", "premise": "The original wax models of the river gods are on display in the Civic Museum.", "hypothesis": "They have models made out of clay.", "generated_explanations": [["The context specifies the models are made of wax, but does not provide information about the existence of clay models.", "n", "validated"], ["The presence of wax models does not necessarily imply that clay models exist.", "n", "validated"], ["The museum may have only wax models and not clay ones; the context does not clarify this.", "n", "validated"], ["The context specifies that the models are made of wax, not clay.", "c", "validated"], ["There is no information in the context indicating the existence of clay models.", "c", "not_validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "58357c", "premise": "What changed?", "hypothesis": "Nothing changed.", "generated_explanations": [["The context explicitly indicates nothing changed, matching the statement exactly.", "e", "validated"], ["The context does not specify if any changes occurred, so it is unknown whether the statement accurately reflects the situation.", "n", "validated"], ["The context could be asking about specific types of changes (e.g., physical, emotional, situational), but this is not clarified, making it undetermined if \"nothing changed\" applies to all aspects.", "n", "validated"], ["The question form of the context suggests a request for information rather than providing facts, so no evidence is given to support or deny the statement.", "n", "validated"], ["The context asks \"What changed?\", which implies that something did change, contradicting the statement that \"Nothing changed.\"", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "19803e", "premise": "But there's SOMETHING.", "hypothesis": "Surely there's something.", "generated_explanations": [["Both the context and statement assert the existence of \"something,\" indicating agreement on the presence of an undefined thing.", "e", "validated"], ["The use of \"surely\" in the statement reinforces the confidence implied by \"But there's SOMETHING\" in the context.", "e", "not_validated"], ["The context expresses uncertainty or vagueness (\"there's SOMETHING\"), while the statement uses a word (\"Surely\") that implies confidence or certainty, so it is unclear if the intent in both matches.", "n", "validated"], ["The context does not indicate whether the speaker is being serious, sarcastic, or questioning, leaving the level of conviction ambiguous compared to the statement.", "n", "validated"], ["The context does not reveal whether the \"something\" is known or assumed by the speaker, while the statement presents it as an assured fact.", "n", "not_validated"], ["The context lacks information about the surrounding conversation or situation, so it is unclear whether \"something\" is meant to be definite or speculative.", "n", "validated"], ["The use of \"Surely\" in the statement indicates strong confidence or certainty, while the context \"But there's SOMETHING\" suggests an element of doubt, ambiguity, or contradiction, so the levels of certainty do not align.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"e": 1, "n": 1, "c": 1}}
{"id": "144753n", "premise": "When he's ready for a major strike, how many innocents do you suppose are going to suffer? To quote one of your contemporaries; 'The needs of the many outweigh the needs of the few.' '", "hypothesis": "He won't care how many innocent people will suffer.", "generated_explanations": [["The question implies that innocent people will inevitably suffer as a result of his actions, suggesting he is unconcerned with their wellbeing.", "e", "validated"], ["The reference to \"the needs of the many outweigh the needs of the few\" justifies sacrificing innocents, implying he accepts or disregards their suffering for a perceived greater cause.", "e", "validated"], ["The context questions the number of innocents who will suffer without stating whether he cares or not.", "n", "validated"], ["The context references the philosophy 'the needs of the many outweigh the needs of the few', but does not specify his personal feelings toward the suffering of innocents.", "n", "validated"], ["There is no direct information about his motivations, values, or emotional response to innocent suffering.", "n", "validated"], ["The context suggests a concern about the suffering of innocents, implying that it matters how many will suffer, which contradicts the statement that he \"won't care.\"", "c", "validated"], ["The quotation \"The needs of the many outweigh the needs of the few\" indicates an ethical consideration regarding the impact on people, suggesting that such suffering is indeed a subject of concern.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "15100e", "premise": "but uh that has been the major change that we have noticed in gardening and that's about the extent of what we've done just a little bit on the patio and uh and waiting for the the rain to subside so we can  mow we after about a month we finally got to mow this weekend", "hypothesis": "We have not done much gardening yet because of the rain.", "generated_explanations": [["The context states that they have only done a little bit of gardening on the patio, indicating minimal gardening activity.", "e", "validated"], ["The context mentions that they are waiting for the rain to subside before they can mow or do more gardening, implying the rain is the reason for delaying gardening activities.", "e", "validated"], ["The context mentions only minor gardening activity on the patio and waiting for rain to subside before mowing, but it does not explicitly state that rain is the reason for not doing much gardening.", "n", "validated"], ["The context does not specify whether the decision to do little gardening was solely due to the rain or for other reasons.", "n", "validated"], ["They have done \"just a little bit on the patio,\" indicating that they have done some gardening despite the rain.", "c", "validated"], ["They mention mowing after about a month, which suggests they have taken some action related to garden maintenance.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "28507n", "premise": "It is, as you see, highly magnified.", "hypothesis": "It is plain for you to see that it is amplified.", "generated_explanations": [["\"Highly magnified\" implies that the object or subject has been made larger or increased in size, which aligns with the meaning of \"amplified.\"", "e", "validated"], ["The phrase \"as you see\" indicates that the amplification or magnification is clear and evident to the observer.", "e", "validated"], ["\"Plain for you to see\" suggests that the change (magnification/amplification) is obvious and not hidden.", "e", "validated"], ["\"Magnified\" and \"amplified\" are often used synonymously in contexts involving increasing size, extent, or intensity.", "e", "not_validated"], ["The context mentions the subject is \"highly magnified,\" but does not state whether this magnification is obvious or plain to see.", "n", "validated"], ["The context uses the term \"magnified,\" while the statement uses \"amplified,\" which could have a different meaning (e.g., increase in volume rather than size).", "n", "validated"], ["There is no information about the observer's perception or ability to plainly see the magnification/amplification.", "n", "validated"], ["\"Magnified\" refers to an increase in visual size, while \"amplified\" refers to an increase in volume or intensity, not necessarily visual size.", "c", "validated"], ["The context describes a visual property (magnification), not an auditory or non-visual enhancement (amplification).", "c", "validated"], ["\"Amplified\" is not synonymous with \"magnified\" in the context presented, so the statement misrepresents the nature of the change.", "c", "validated"]], "label_count_round_1": {"e": 4, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "123748n", "premise": "There are many such at the present time.", "hypothesis": "There are over two currently.", "generated_explanations": [["The phrase \"many\" implies a quantity greater than two.", "e", "validated"], ["\"At the present time\" and \"currently\" both refer to the same time frame, making them temporally compatible.", "e", "validated"], ["The phrase \"many\" is vague and does not specify an exact quantity, so it is unclear whether it implies more than two.", "n", "validated"], ["\"At the present time\" in the context does not specify a precise number, making it indeterminate whether \"over two\" is accurate.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "111338c", "premise": "He threw one of them and shot the other.", "hypothesis": "He kept his gun holstered.", "generated_explanations": [["The context mentions that he \"shot the other,\" which implies he used a gun, but it doesn't specify whether the gun was holstered before or after the shooting.", "n", "validated"], ["There is no explicit information about the condition or placement of the gun at any point other than it being used to shoot, so it is unclear whether it was ever holstered.", "n", "validated"], ["The statement is contradicted because he shot the other, indicating the gun was not holstered.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "52171c", "premise": "For such a governmentwide review, an entrance conference is generally held with applicable central agencies, such as the Office of Management and Budget (OMB) or the Office of Personnel Management.", "hypothesis": "An entrance conference is held with specialized agencies.", "generated_explanations": [["The Office of Management and Budget (OMB) and the Office of Personnel Management are considered specialized agencies within the government, as they focus on specific aspects like budget and personnel management.", "e", "not_validated"], ["The context states that entrance conferences are held with \"applicable central agencies,\" which implies specialized functions, aligning with the term \"specialized agencies.\"", "e", "not_validated"], ["The context specifies \"central agencies\" but does not provide information about whether \"specialized agencies\" are included or excluded from the entrance conference.", "n", "validated"], ["The terms \"central agencies\" and \"specialized agencies\" are not defined in the context, so their overlap or distinction is unclear.", "n", "validated"], ["The context specifies that the entrance conference is held with central agencies, not specialized agencies.", "c", "validated"], ["The agencies mentioned (OMB and OPM) are central agencies, not specialized agencies.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "90548e", "premise": "Splendid!", "hypothesis": "The speaker is excited by the situation.", "generated_explanations": [["The word \"Splendid!\" is an exclamation commonly used to express excitement or enthusiasm.", "e", "validated"], ["The exclamation mark indicates heightened emotion, supporting the idea of excitement.", "e", "validated"], ["\"Splendid\" can express approval or satisfaction rather than excitement.", "n", "validated"], ["The speaker’s tone or emotional state is not specified beyond the single word.", "n", "validated"], ["\"Splendid\" could be used sarcastically, implying a lack of excitement.", "n", "validated"], ["\"Splendid!\" can be used sarcastically or ironically, meaning the speaker may not actually be excited.", "c", "validated"], ["\"Splendid!\" could indicate approval or satisfaction without necessarily implying excitement.", "c", "validated"], ["The statement does not provide enough information about the speaker's emotional state beyond their spoken word.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "81842c", "premise": "Answer? said Julius.", "hypothesis": "Julius already knew the answer.", "generated_explanations": [["Julius asked \"Answer?\" which suggests he was prompting someone to provide the answer, possibly because he already knew it and wanted to see if others did as well.", "e", "not_validated"], ["Julius could be asking the question because he does not know the answer.", "n", "validated"], ["The context does not specify Julius’s knowledge state before asking.", "n", "validated"], ["Julius is asking for an answer, which suggests he does not already know it.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "91601n", "premise": "Even today, Yanomamo men raid villages, kill men, and abduct women for procreative purposes.", "hypothesis": "Yanomamo eats food.", "generated_explanations": [["The context discusses the violent actions and motivations of Yanomamo men but does not mention anything about their dietary habits or whether they eat food.", "n", "validated"], ["The context does not mention anything about eating or food consumption by the Yanomamo.", "c", "validated"], ["The actions described—raiding, killing, and abducting—do not imply or entail eating food.", "c", "validated"], ["The statement is unrelated to the information provided in the context.", "c", "validated"]], "label_count_round_1": {"n": 1, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 1, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "118415n", "premise": "John Panzar has characterized street delivery as a bottleneck function because a single firm can deliver to a recipient at a lower total cost than multiple firms delivering to the same customer.", "hypothesis": "John Panzar believes in nationalizing all postal delivery services and couriers into a single entity for cost-saving purposes.", "generated_explanations": [["The context only indicates John Panzar's view on the cost efficiency of a single firm performing street delivery, but does not provide any information regarding his views on nationalization or the merging of all postal and courier services.", "n", "validated"], ["The context does not clarify whether John Panzar favors government-run services, private monopolies, or some other structure for achieving the cost advantage identified.", "n", "validated"], ["The context does not state whether John Panzar believes the cost-saving argument should apply universally to all forms of delivery or only specific cases.", "n", "validated"], ["No information is provided about John Panzar's stance on the political, economic, or practical implications of creating a single entity, such as issues of regulation, competition, or service quality.", "n", "validated"], ["The context only states that John Panzar characterizes street delivery as a bottleneck due to cost advantages of single-firm delivery, but does not indicate any belief about nationalizing all postal services.", "c", "validated"], ["There is no mention in the context of nationalization or support for a government-run monopoly; the efficiency argument could apply to private firms as well.", "c", "validated"], ["Panzar's observation about costs does not necessarily imply support for merging all couriers and delivery services into a single entity.", "c", "validated"], ["The context refers specifically to delivery cost structure, not to policy recommendations or beliefs about how postal and courier services should be organized.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 4}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 4}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "113644n", "premise": "so do you have do you have the long i guess not not if there's see i was raised in New York but i guess up there you all don't have too long of a growing season do you", "hypothesis": "I am looking for a written guide to growing plants in different places in the country.", "generated_explanations": [["The context discusses growing seasons in New York but does not mention seeking or needing a written guide.", "n", "validated"], ["There is no indication in the context that the speaker is requesting information or resources about plant cultivation methods elsewhere.", "n", "validated"], ["The context centers on a spoken personal experience, not on the pursuit of written materials.", "n", "validated"], ["The context is a conversation about the length of the growing season in New York, not a request for a written guide.", "c", "validated"], ["The speaker is discussing personal experience and observations, not asking for or seeking a written guide.", "c", "validated"], ["There is no reference in the context to written materials or a desire to obtain such a guide.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "47260n", "premise": "The good news, however, can be found in reports like this one.", "hypothesis": "The good news is that the puppy's life was able to be saved.", "generated_explanations": [["The context does not specify what the \"good news\" refers to, so it is unclear if it involves a puppy’s life being saved.", "n", "validated"], ["There is no mention of a puppy or an incident involving a puppy in the context.", "n", "validated"], ["The context does not mention a puppy or any information about saving its life.", "c", "validated"], ["There is no indication in the context that the \"good news\" refers to anything related to a puppy.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "129081e", "premise": "right oh they've really done uh good job of keeping everybody informed of what's going on sometimes i've wondered if it wasn't almost more than we needed to know", "hypothesis": "After sharing all information with everyone, I think I may have shared too much.", "generated_explanations": [["The speaker acknowledges that everyone has been kept very well informed about what is going on.", "e", "validated"], ["The speaker questions whether the amount of information shared was excessive.", "e", "validated"], ["The context refers to a group or organization keeping \"everybody informed,\" but it is not clear that the speaker personally shared all the information.", "n", "validated"], ["The context does not indicate that the speaker was the one responsible for sharing information, only that they wondered if too much was being shared.", "n", "validated"], ["The statement uses first person singular (\"I\"), but the context could be about the actions of another party or a collective effort, not the individual speaker alone.", "n", "validated"], ["The context refers to \"they\" keeping people informed, not the speaker sharing information.", "c", "validated"], ["The speaker expresses that they have wondered if the information provided was more than needed, but does not state that they themselves shared the information.", "c", "validated"], ["The statement suggests personal responsibility for sharing, whereas the context attributes the information sharing to another party.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "18189e", "premise": "The important thing is to realize that it's way past time to move it.", "hypothesis": "It has not been moved yet in the past.", "generated_explanations": [["The phrase \"it's way past time to move it\" indicates that the action of moving it, which was supposed to happen earlier, has not yet occurred.", "e", "validated"], ["If it had already been moved in the past, there would be no need to emphasize that it's overdue to move it now.", "e", "validated"], ["The context states it is \"way past time\" to move it, implying it should have been moved already, but does not explicitly confirm whether it has or has not been moved in the past.", "n", "validated"], ["The phrase \"way past time\" could indicate that the action is overdue, but it leaves open the possibility that it may have been moved at some earlier, unspecified time.", "n", "validated"], ["The context focuses on the need for action in the present, not providing definite information about any prior movement.", "n", "validated"], ["The phrase \"way past time to move it\" implies that the action of moving it is overdue, but does not specify whether or not it has already been moved.", "c", "validated"], ["\"Way past time\" could be used even if the item had already been moved late, so the statement assumes a lack of action that is not confirmed by the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "91797c", "premise": "We know they will have to come from the south but that gives them a space as wide as the town in which to launch their attack.", "hypothesis": "The south is totally protected against an attack.", "generated_explanations": [["The context suggests the attackers can use any area \"as wide as the town\" to launch their attack from the south, but does not specify the level of protection in the south.", "n", "validated"], ["There is no information given about defenses or protection in the south, only about the attackers' possible approach.", "n", "validated"], ["The context indicates that attackers can come from the south and have a wide space to launch their attack, implying that the south is not completely defended.", "c", "validated"], ["If the south were totally protected, there would be no concern about an attack coming from that direction.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "917c", "premise": "eligible individuals and the rules that apply if a state does not substantially enforce the statutory requirements.", "hypothesis": "It does not matter whether or not a state enforces the statutory requirements.", "generated_explanations": [["The context directly mentions rules that apply when a state does not substantially enforce the statutory requirements, indicating that provisions are in place regardless of state enforcement, so enforcement does not affect the applicability of the rules.", "e", "not_validated"], ["The concept of \"eligible individuals\" and accompanying rules are defined independently of state enforcement, suggesting that eligibility and statutory requirements persist even without state action.", "e", "not_validated"], ["The context mentions rules that apply specifically if a state does not substantially enforce the statutory requirements, but does not clarify whether enforcement overall matters, leaving undetermined if enforcement is consequential.", "n", "validated"], ["The context does not specify whether the existence of these rules renders state enforcement irrelevant or still important, making it unclear whether enforcement is consequential or not.", "n", "validated"], ["The context provides no explicit statement about the overall significance or insignificance of enforcement by the state.", "n", "validated"], ["The context specifies rules that apply if a state does not substantially enforce the statutory requirements, implying that enforcement status is significant.", "c", "validated"], ["The existence of consequences or alternative rules for non-enforcement indicates that enforcement of statutory requirements matters.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "89995c", "premise": "yeah then you don't have you don't have that mess to clean up when you use an oil oil base painting and boy i'll tell you oh", "hypothesis": "Typically oil based paints are easy to work with and clean up.", "generated_explanations": [["The context mentions avoiding a mess by not using oil-based paint, but does not directly comment on the general ease or difficulty of working with or cleaning up oil-based paints.", "n", "validated"], ["The statement makes a general claim about oil-based paints being easy to work with and clean up, which is not explicitly supported or contradicted by the context.", "n", "validated"], ["Oil-based paints are not easy to clean up, which is implied by the mention of the \"mess to clean up\" when using them.", "c", "validated"], ["The context contrasts oil-based paints with something else (likely water-based paints), suggesting oil-based paints are messier and harder to clean.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "33822e", "premise": "Why shouldn't he be?", "hypothesis": "There is no reason he shouldn't be.", "generated_explanations": [["The question in the context suggests that there is no known objection or barrier to \"he\" being what is implied, so the statement asserts agreement by noting the absence of reasons against it.", "e", "validated"], ["The context raises a rhetorical question implying that being so is expected or unproblematic, which aligns with the statement’s claim that no contrary reason exists.", "e", "validated"], ["The context asks a rhetorical question but does not provide any information about the situation or reasons for or against \"him\" being or not being, so it is unclear whether there is a reason or not.", "n", "validated"], ["The context does not specify who \"he\" is or what the issue is regarding, so we cannot determine if any reasons exist.", "n", "validated"], ["The context is a rhetorical question implying skepticism or prompting justification, which suggests there might be reasons he shouldn't be.", "c", "validated"], ["The statement assumes with certainty that no reasons exist, which contradicts the possibility raised by the context that reasons could exist.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "42983e", "premise": "The town is also known for its sparkling wine and for the caves where about 70 per?­cent of France's cultivated mushrooms are grown.", "hypothesis": "The town has a lot of sparkling wine.", "generated_explanations": [["The context states that the town is known for its sparkling wine, indicating a significant presence or production of sparkling wine in the town.", "e", "validated"], ["The context says the town is \"known for its sparkling wine\" but does not specify the quantity of sparkling wine present or produced there.", "n", "validated"], ["Being \"known for\" something could refer to reputation rather than actual abundance.", "n", "validated"], ["The context states the town is \"known for its sparkling wine,\" which implies reputation or association, but does not directly confirm the quantity of sparkling wine present in the town.", "c", "validated"], ["The statement asserts that the town \"has a lot\" of sparkling wine, but the context provides no quantitative information or evidence about the actual amount of sparkling wine in the town.", "c", "validated"], ["The context could mean the wine is produced or originated there, but does not necessarily mean large quantities are presently held or stored in the town.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "6105e", "premise": "Asked about abortion the other day on CNN, Republican National Committee Chairman Jim Nicholson also invoked what is apparently the party-line  inclusive party.", "hypothesis": "The Republican National Committee Chairman gave the party's standard answer on the subject of abortion when he was asked about it on CNN.", "generated_explanations": [["The context states that Jim Nicholson \"invoked what is apparently the party-line\" when asked about abortion, indicating he gave the party's standard answer.", "e", "validated"], ["The statement specifies that the Republican National Committee Chairman was asked about abortion on CNN, matching the context.", "e", "validated"], ["The phrase \"party-line\" in the context directly supports the claim that he provided the party's standard response.", "e", "validated"], ["The context mentions that Jim Nicholson \"invoked what is apparently the party-line inclusive party\" but does not specify what he actually said about abortion, leaving the content of his answer unclear.", "n", "validated"], ["The context suggests he referenced party inclusivity rather than explicitly giving the standard answer on abortion, so it is undetermined whether his response matched the party's standard answer.", "n", "validated"], ["The phrase \"apparently the party-line\" introduces ambiguity about whether what he said truly reflects the standard party answer on abortion.", "n", "validated"], ["The context only states that Jim Nicholson \"invoked what is apparently the party-line inclusive party\" but does not specify what answer he gave on abortion or whether it aligns with the standard party answer.", "c", "validated"], ["The phrase \"party-line inclusive party\" does not directly confirm that the standard answer on abortion was given; it could refer to emphasizing inclusiveness rather than a specific stance on abortion.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "26143n", "premise": "However, the associated cost is primarily some of the costs of assessing and collecting duties on imported merchandise, such as the salaries of import specialists (who classify merchandise) and the costs of processing paperwork.", "hypothesis": "the associated cost is how much people spend relative to this amount", "generated_explanations": [["The context describes the associated cost as specific expenses related to assessing and collecting duties (e.g., salaries, paperwork processing), not as a measure of how much people spend relative to this amount.", "n", "validated"], ["The context does not provide information about how much people spend or any relative spending amounts, leaving the relationship between spending and associated cost unclear.", "n", "validated"], ["There is no information in the context equating \"associated cost\" with a ratio or comparison to spending, so it's undetermined whether this interpretation of associated cost is accurate.", "n", "validated"], ["The context defines the associated cost as expenses related to assessing and collecting duties (e.g., salaries and paperwork processing), not as a measure of how much people spend.", "c", "validated"], ["The statement describes associated cost in terms of people’s spending relative to an amount, which is unrelated to the administrative costs listed in the context.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "100768n", "premise": "well in a way you can travel light", "hypothesis": "You won't need to pack much.", "generated_explanations": [["Traveling light implies carrying minimal belongings.", "e", "validated"], ["If you travel light, the amount you need to pack is small.", "e", "validated"], ["The phrase \"in a way\" suggests that traveling light may not literally mean not packing much, but could have another interpretation.", "n", "validated"], ["\"Travel light\" can refer to emotional or psychological burdens rather than physical luggage, so it may not indicate packing fewer items.", "n", "validated"], ["The phrase \"in a way\" implies there are exceptions or limitations, so it may not be true that little needs to be packed in all situations.", "c", "not_validated"], ["\"Traveling light\" can be interpreted subjectively and might still require significant packing depending on personal or trip-specific requirements.", "c", "not_validated"], ["The context does not specify the purpose or duration of travel, which could necessitate packing more than expected.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 3}}
{"id": "82510e", "premise": "although the uh it's uh it we almost one day we painted the house to uh we painted we painted the whole inside and it had all this dark trim we thought uh you know we did the one wall but the other trim i'm trying to think i think i think we left most of it because it gets to be uh they don't do that in the newer houses now we don't the uh mold everything is white in a new house everything is white", "hypothesis": "We painted the house over the duration of one day.", "generated_explanations": [["The context mentions \"we almost one day we painted the house to uh we painted,\" suggesting that the act of painting the house was closely associated with a single day.", "e", "not_validated"], ["The use of \"almost one day\" implies that the painting was done within the span of one day or nearly completed in that time frame.", "e", "validated"], ["The speaker says \"we almost one day we painted the house\" which is incomplete and may suggest they did not actually complete painting the house in one day.", "n", "validated"], ["The use of \"almost\" implies that painting the house in a single day was not fully achieved.", "n", "validated"], ["Details about which parts were painted (e.g., \"we did the one wall,\" \"we left most of it\") indicate not all painting was completed in the time discussed, making the duration unclear.", "n", "validated"], ["The speaker says they \"almost one day we painted the house\" indicating they did not actually complete painting the house in one day.", "c", "validated"], ["The use of \"almost\" suggests that the task was not fully accomplished within a single day.", "c", "validated"], ["The speaker mentions only doing \"the one wall\" and implies other trim was left, indicating the whole house was not painted in one day.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "102563n", "premise": "The judge gave vent to a faint murmur of disapprobation, and the prisoner in the dock leant forward angrily.", "hypothesis": "The judge ordered the court to be silent.", "generated_explanations": [["The context mentions the judge expressing a faint murmur of disapprobation but does not indicate any verbal order regarding the court's silence.", "n", "validated"], ["There is no information in the context about the noise level or disturbances in the court that would prompt the judge to order silence.", "n", "validated"], ["The context describes the reactions of the judge and prisoner but does not mention any interaction between the judge and the rest of the court regarding silence.", "n", "validated"], ["The context states that the judge expressed a faint murmur of disapprobation, not that he ordered the court to be silent.", "c", "validated"], ["There is no mention in the context of the judge addressing the court or giving any instructions about silence.", "c", "validated"], ["The described actions do not indicate any attempt by the judge to control the courtroom’s noise or behavior.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "48553c", "premise": "Keep your eyes open for Renaissance details, grand doorways, and views into lovely courtyards.", "hypothesis": "All of the doorways and courtyards have been completely remodeled since the Renaissance.", "generated_explanations": [["The context does not specify whether the doorways and courtyards have been remodeled or preserved.", "n", "validated"], ["The context only mentions appreciating Renaissance details, which could mean original or restored features, but does not indicate complete remodeling.", "n", "validated"], ["There is no information about the history or renovation status of every doorway and courtyard referenced.", "n", "validated"], ["The context encourages visitors to look for Renaissance details, implying that some original features from the Renaissance are still present and have not been completely remodeled.", "c", "validated"], ["The context mentions views into courtyards, suggesting they may retain their historical character rather than having all been remodeled since the Renaissance.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "54458n", "premise": "This one ended up being surprisingly easy!", "hypothesis": "This question was very easy to answer.", "generated_explanations": [["The phrase \"surprisingly easy\" in the context implies the task's difficulty was low, aligning with the statement that the question was very easy to answer.", "e", "validated"], ["The context indicates the situation \"ended up\" being easy, which suggests the ease was determined in hindsight and may not directly reflect the initial perception of the question's difficulty.", "n", "validated"], ["The context does not specify whether \"this one\" refers explicitly to \"this question\"; it could refer to a task, a problem, or something else.", "n", "validated"], ["The context expresses an overall impression of ease but does not directly state how easy it was to answer the question, leaving room for subjective interpretation.", "n", "validated"], ["The context refers to \"this one,\" which could mean a specific part or item that was easy, not the overall question.", "c", "validated"], ["The context describes the task as \"surprisingly easy,\" implying an expectation of difficulty, but does not explicitly state that it was \"very easy\" as in the statement.", "c", "not_validated"], ["\"Surprisingly easy\" suggests a relative ease compared to expectations, not necessarily that it was objectively \"very easy.\"", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "17576n", "premise": "The percent of total cost for each function included in the model and cost elasticity (with respect to volume) are shown in Table 1.", "hypothesis": "Table 1 also shows a picture diagram for each function.", "generated_explanations": [["The context only mentions that Table 1 presents percent of total cost and cost elasticity, but does not mention any picture diagrams.", "n", "validated"], ["There is no information about graphical or pictorial elements being present in Table 1.", "n", "validated"], ["The context only mentions that Table 1 includes percent of total cost for each function and cost elasticity, but does not mention any picture diagrams.", "c", "validated"], ["There is no indication in the context that Table 1 contains diagrams of any kind.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "103431n", "premise": "In addition, the senior executives at these organizations demonstrated their sustained commitment to financerelated improvement initiatives by using key business/line managers to drive improvement efforts, attending key meetings, ensuring that the necessary resources are made available, and creating a system of rewards and incentives to recognize those who support improvement initiatives.", "hypothesis": "This system of rewards and incentives will hopefully improve company performance.", "generated_explanations": [["Rewards and incentives motivate employees to support and engage with improvement initiatives, potentially increasing their effectiveness and impact on company performance.", "e", "validated"], ["Recognition systems can lead to greater employee satisfaction and productivity, both of which contribute to improved company performance.", "e", "validated"], ["By aligning rewards with improvement initiatives, employees are encouraged to focus their efforts on activities that enhance company outcomes.", "e", "validated"], ["The context mentions the creation of a system of rewards and incentives but does not provide evidence or results indicating its actual effect on company performance.", "n", "validated"], ["The statement expresses hope (\"will hopefully\") rather than a factual outcome, making it undetermined based on the context provided.", "n", "validated"], ["The context does not specify whether similar initiatives in the past have led to improved company performance.", "n", "validated"], ["The context describes creating a system of rewards and incentives but does not claim or guarantee that it will improve company performance; the effect is only speculative in the statement.", "c", "validated"], ["There is no evidence or data in the context demonstrating that the rewards and incentives have led or will lead to improved company performance.", "c", "validated"], ["The context only states that the system recognizes those who support improvement initiatives, not that it improves company performance directly.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "64123c", "premise": "Per week?", "hypothesis": "Every day.", "generated_explanations": [["The statement \"Every day\" implies a frequency that is greater than or equal to \"per week,\" thus affirming or strengthening the frequency mentioned in the context.", "e", "not_validated"], ["The context \"Per week?\" asks about the frequency within a week, while the statement \"Every day\" gives a daily frequency, but it is not explicitly clear if \"Every day\" refers to every day of the week or something else.", "n", "validated"], ["There is insufficient information to determine if \"Every day\" is a direct answer to \"Per week?\" or if it refers to a different time frame or activity not specified in the context.", "n", "validated"], ["\"Every day\" indicates a frequency that is higher than \"per week,\" which typically refers to something happening once a week, not daily.", "c", "validated"], ["The statement \"Every day\" contradicts the implication of \"per week\" by suggesting a different time interval for occurrence.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "56163c", "premise": "She would be almost certainly sent to you under an assumed one.", "hypothesis": "The man told the other man that Bill would be sent to him.", "generated_explanations": [["The context does not specify the genders of the participants in the conversation, so it is unclear if any men are involved.", "n", "validated"], ["The individual being sent is referred to as \"she\" in the context, whereas the statement asserts \"Bill\" (typically a male name) would be sent.", "n", "validated"], ["The context mentions someone being sent \"under an assumed one\" (likely meaning a name), but it does not specify that the assumed name is \"Bill\".", "n", "validated"], ["There is no information in the context about any person named \"Bill\".", "n", "validated"], ["The context does not indicate that a man told another man about someone being sent; the speakers and their genders are unspecified.", "n", "validated"], ["The context refers to \"she,\" while the statement refers to \"Bill,\" implying different individuals.", "c", "validated"], ["The context suggests someone is being sent under an assumed name, but the statement directly names \"Bill,\" contradicting the assumed name aspect.", "c", "validated"], ["The context does not mention two men communicating, whereas the statement asserts a conversation between two men.", "c", "validated"]], "label_count_round_1": {"n": 5, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 5, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "11297c", "premise": "Transforming Control of Public Health Programs Raises Concerns (", "hypothesis": "Everyone is content with the change of public health programs.", "generated_explanations": [["The context mentions that the transformation of control raises concerns, but does not specify whether everyone is content or discontent, leaving open the possibility for both.", "n", "validated"], ["The term \"concerns\" implies that at least some people are not content, but it does not specifically address the sentiments of all individuals.", "n", "validated"], ["There is no information provided about the perspectives of every individual affected by the change, so it is undetermined if everyone is content.", "n", "validated"], ["The context indicates that concerns have been raised about the transformation of public health programs, implying that not everyone is content.", "c", "validated"], ["The presence of concerns suggests that at least some individuals or groups are dissatisfied or uneasy with the changes.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "32889n", "premise": "Extremely limited exceptions to the authority are established in 31 U.S.C.", "hypothesis": "They were trying to eliminate all exceptions.", "generated_explanations": [["The use of \"extremely limited exceptions\" suggests an intent to minimize or nearly eliminate exceptions to the authority, meaning efforts were likely made to restrict exceptions as much as possible.", "e", "not_validated"], ["The existence of only a few exceptions in 31 U.S.C. supports the idea that there was a deliberate attempt to avoid including many exceptions, aligning with the goal of eliminating all but the bare minimum.", "e", "validated"], ["The context only specifies that exceptions are extremely limited, not that there was an attempt to eliminate all exceptions.", "n", "validated"], ["The context does not provide information about motivations or intentions regarding the exceptions.", "n", "validated"], ["The current existence of limited exceptions does not imply that there was an active effort to reduce exceptions to zero.", "n", "validated"], ["The context states that exceptions, albeit extremely limited, are still established, meaning not all exceptions have been eliminated.", "c", "validated"], ["The presence of exceptions contradicts the claim that there was an effort to eliminate all exceptions.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "19c", "premise": "On the northern slopes of this rocky outcropping is the site of the ancient capital of the island, also called Thira, which dates from the third century b.c. (when the Aegean was under Ptolemaic rule).", "hypothesis": "Is the site of the ancient asteroid impact, also called Thira.", "generated_explanations": [["The context does not mention an asteroid impact, only the site of an ancient capital.", "n", "validated"], ["There is no information provided about an asteroid impact associated with Thira in the context.", "n", "validated"], ["The context describes the site as the ancient capital of the island, not as the site of an ancient asteroid impact.", "c", "validated"], ["There is no mention of an asteroid impact in the context.", "c", "validated"], ["The significance of Thira in the context is related to its historical and geopolitical attributes, not a geological event like an asteroid impact.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "32754e", "premise": "After shuttering the DOE, Clinton could depict himself as a crusader against waste and bureaucracy who succeeded where even Reagan failed.", "hypothesis": "Clinton shuttered the DOE to move against waste.", "generated_explanations": [["The context states that by shuttering the DOE, Clinton could present himself as someone fighting waste and bureaucracy, implying the action was motivated by a desire to reduce waste.", "e", "validated"], ["The context states what Clinton *could depict* (i.e., how he could present his actions), not necessarily his actual reasons or motivations.", "n", "validated"], ["The context does not provide direct evidence of Clinton's intent or rationale for shuttering the DOE; it only mentions the possible narrative he could use.", "n", "validated"], ["The context discusses what Clinton could do after shuttering the DOE, but does not state that he actually shuttered the DOE.", "c", "validated"], ["The statement assumes Clinton acted to move against waste, while the context only speculates on the possible depiction or narrative following the act, not the real motivation.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "12815n", "premise": "yeah well that's my uh i mean every time i've tried to go you know it's always there's there's always a league bowling", "hypothesis": "Every time I try to go bowling there are leagues only and I can't bowl.", "generated_explanations": [["The context mentions that every time the speaker tries to go, there is always league bowling happening.", "e", "validated"], ["League bowling implies the lanes are occupied by leagues, preventing casual play.", "e", "validated"], ["The context expresses frustration about the consistent presence of leagues when attempting to bowl.", "e", "validated"], ["The context mentions that there is always \"league bowling\" when the speaker tries to go, but it does not specify whether the speaker is actually prevented from bowling.", "n", "validated"], ["The context does not clarify if all lanes are occupied by leagues or if there is an opportunity for the speaker to bowl alongside or after the league play.", "n", "validated"], ["The context does not state that the speaker cannot bowl at a different time, only that league bowling is always present when they attempt to go.", "n", "validated"], ["The context does not indicate whether the speaker has ever tried to join a league or make other arrangements to bowl.", "n", "validated"], ["The context does not explicitly mention being denied access or being turned away from bowling; it only highlights the presence of leagues.", "n", "validated"], ["The context mentions \"there's always a league bowling\" but does not state that leagues are the only activity or that the speaker can't bowl; it just suggests leagues are present when the speaker tries to go.", "c", "validated"], ["The statement asserts the speaker cannot bowl, but the context does not confirm this inability, only that leagues are ongoing.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 5, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 5, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "135898c", "premise": "The end is near!  Then a shout went up, and Hanson jerked his eyes from the gears to focus on a group of rocs that were landing at the far end of the camp.", "hypothesis": "It's all over, Hanson whispered as he stared at the gears.", "generated_explanations": [["The phrase \"The end is near!\" suggests that something significant or catastrophic is about to happen, supporting Hanson's belief that \"it's all over.\"", "e", "validated"], ["The landing of a group of rocs, which may symbolize danger or a final event, gives Hanson reason to think the situation is hopeless or finished.", "e", "validated"], ["Hanson's focus on the gears might indicate he is witnessing the cessation of some crucial machinery or operation, reinforcing his sense that everything is ending.", "e", "not_validated"], ["The context mentions \"the end is near,\" suggesting something is approaching, but does not explicitly confirm that it is \"all over.\"", "n", "validated"], ["The context indicates Hanson is distracted by a shout and rocs landing, so it is unclear what he says or whispers in response.", "n", "validated"], ["There is no direct evidence in the context that Hanson whispers anything, let alone the statement in question.", "n", "validated"], ["Hanson was not whispering that it was all over; instead, he was focused on the gears when a shout drew his attention.", "c", "validated"], ["The narrative does not state or suggest that Hanson said \"It's all over\" while staring at the gears.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "82830n", "premise": "In the 19th century, when Kashmir was the most exotic hill-station of them all, the maharaja forbade the British to buy land there, so they then hit on the brilliant alternative of building luxuriously appointed houseboats moored on the lakes near Srinagar.", "hypothesis": "The maharaja allowed the British to build houseboats on the lakes.", "generated_explanations": [["The British built houseboats on the lakes near Srinagar after being forbidden from buying land, which implies that the maharaja allowed this alternative.", "e", "not_validated"], ["The context does not specify whether the maharaja explicitly allowed or forbade the building of houseboats; it only mentions that the British used houseboats as an alternative after being forbidden to buy land.", "n", "validated"], ["It is unclear from the context if building houseboats required the maharaja's permission or if it occurred without official approval or opposition.", "n", "validated"], ["The context only mentions that the maharaja forbade the British to buy land, but does not state that he specifically allowed them to build houseboats; building houseboats was an alternative they chose, not something explicitly permitted by the maharaja.", "c", "not_validated"], ["The statement asserts positive permission (\"allowed\"), whereas the context suggests the British acted due to a lack of prohibition, not due to explicit allowance.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1, "c": 1}}
{"id": "74509n", "premise": "Under the budget deal, by 2002, national defense will consume about $273 billion a year compared with $267 billion now.", "hypothesis": "The United States national defense budget will increase by 6 billion dollars.", "generated_explanations": [["The national defense budget is projected to rise from $267 billion to $273 billion, a difference of $6 billion.", "e", "validated"], ["The phrase \"about $273 billion\" is approximate and may not represent an exact $6 billion increase from $267 billion.", "n", "validated"], ["The figures given are for \"national defense,\" but it's possible that accounting methods or budget categorization could change, affecting the interpretation of the increase.", "n", "validated"], ["The context references projected future spending (\"by 2002\"), which may change due to unforeseen events or adjustments before that year.", "n", "validated"], ["The current figure (\"$267 billion now\") may not refer to the same fiscal period or precise baseline as used for the 2002 projection, making direct comparison uncertain.", "n", "validated"], ["The increase from $267 billion to $273 billion is $6 billion, but the statement does not specify whether this is a nominal or real (inflation-adjusted) increase, and the context does not clarify if inflation or other adjustments are accounted for.", "c", "validated"], ["The context says \"about $273 billion,\" which could mean the actual increase may be slightly more or less than exactly $6 billion.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "98944c", "premise": "evaluation questions.", "hypothesis": "Only statements of the evaluation are available.", "generated_explanations": [["The context \"evaluation questions\" suggests focus on content related to an evaluation process, making it plausible that only statements from this evaluation are accessible.", "e", "not_validated"], ["If only statements pertinent to evaluation questions are kept or shared, it follows that \"only statements of the evaluation are available.\"", "e", "validated"], ["The statement directly reflects a situation where access is restricted solely to the evaluation's statements, matching the information implied by the context.", "e", "validated"], ["The context \"evaluation questions\" does not specify whether statements of the evaluation are available or not.", "n", "validated"], ["The context does not clarify if anything other than questions, such as statements, exists or is provided.", "n", "validated"], ["It is unclear whether \"evaluation questions\" includes or excludes statements, making the availability of statements undetermined.", "n", "validated"], ["The context refers to evaluation questions, which are different from statements, indicating that more than just statements (i.e., questions) are available.", "c", "validated"], ["The mention of \"evaluation questions\" implies the presence of questions, not solely statements.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "19208c", "premise": "Hearty Sabbath meals.", "hypothesis": "Hearty meals will only be offered to Buddhists", "generated_explanations": [["The context mentions \"Sabbath,\" which is typically associated with Judaism or Christianity, not Buddhism, so it is unclear whether the meals are intended exclusively for Buddhists.", "n", "validated"], ["There is no information in the context specifying the recipients of the meals or any religious restrictions.", "n", "validated"], ["The context does not indicate whether non-Buddhists would be excluded from hearty Sabbath meals.", "n", "validated"], ["The context mentions \"Sabbath,\" which is traditionally associated with Judaism, not Buddhism.", "c", "validated"], ["There is no indication in the context that the meals are exclusive to Buddhists.", "c", "validated"], ["The word \"Sabbath\" suggests practices or meals related to Jewish customs, implying the meals are likely intended for Jews observing the Sabbath.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "117576e", "premise": "but i don't know you know  maybe you could do that for a certain period of time but i mean how long does that kind of a thing take you know to to um say to question the person or to get into their head", "hypothesis": "It might take a long time to do that because getting inside a person's head takes time.", "generated_explanations": [["The context questions how long it would take to \"get into their head,\" implying the process is not quick.", "e", "validated"], ["The speaker suggests that performing this task for only a certain period may not be enough, indicating it could require more time.", "e", "validated"], ["The act of questioning or understanding a person deeply is presented as something that involves an extended process.", "e", "validated"], ["The context expresses uncertainty about how long it takes to question someone or get into their head, but does not specify whether it takes a short or long time.", "n", "validated"], ["The context does not provide any information about the actual duration required to get inside a person's head.", "n", "validated"], ["The speaker's use of questions and hypotheticals indicates lack of knowledge rather than a definite stance on the length of time involved.", "n", "validated"], ["The context expresses uncertainty about how long it takes and does not assert that it will necessarily take a long time.", "c", "validated"], ["The speaker questions the process but does not claim that getting into someone's head inherently takes a long time; they are unsure about the duration.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "50484c", "premise": "All of our many earnest experiments produced results in line with random chance, they conclude.", "hypothesis": "The experiments proved it was a much better predictor.", "generated_explanations": [["The context states that the experiments produced results in line with random chance, but does not specify what was being predicted or what the predictor was, so it is unclear what the statement refers to.", "n", "validated"], ["The context does not provide evidence or data showing that anything was a \"much better predictor,\" leaving the claim unconfirmed.", "n", "validated"], ["The word \"they conclude\" suggests the authors reached a conclusion, but the specific content of their conclusion regarding predictors is not detailed in the context.", "n", "validated"], ["The experiments did not show the predictor was better; results matched random chance, indicating no predictive value.", "c", "validated"], ["The conclusion drawn was that the predictor performed no better than guessing, directly contradicting the statement.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "98445c", "premise": "It seeks genuine direct elections after a period that is sufficient to organize alternative parties and prepare a campaign based on freedom of speech and other civil rights, the right to have free trade unions, the release of more than 200 political prisoners, debt relief, stronger penalties for corruption and pollution, no amnesty for Suharto and his fellow thieves, and a respite for the poor from the hardest edges of economic reform.", "hypothesis": "The only thing that can our society is more power to the presidential electors.", "generated_explanations": [["The context lists multiple reforms and goals (e.g., civil rights, free trade unions, release of prisoners, anti-corruption) rather than focusing solely on increasing power to presidential electors, so it is unclear if empowering electors alone is sufficient or prioritized.", "n", "validated"], ["The statement claims that \"the only thing\" that can help society is empowering presidential electors, but the context suggests a multi-faceted approach, making it undetermined whether that is the single most important or only necessary change.", "n", "validated"], ["The context does not explicitly mention increasing power to presidential electors as a proposed solution, so it is unclear if this aligns with the intentions outlined.", "n", "validated"], ["The context lists multiple reforms sought by society, not just more power to presidential electors, refuting the idea that this is the only solution.", "c", "validated"], ["The desired changes include civil rights, political prisoner release, debt relief, anti-corruption measures, and economic protections, which are not addressed solely by empowering presidential electors.", "c", "validated"], ["The statement ignores the context's call for preparation and inclusion of alternative parties and freedom of expression, which go beyond simply increasing elector power.", "c", "validated"], ["The context opposes amnesty for corrupt leaders, a demand unrelated to presidential elector authority.", "c", "not_validated"], ["The statement overlooks economic reforms and social protections for the poor mentioned as goals in the context.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 5}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 4}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "7856c", "premise": "but how do you know  the good from the bad", "hypothesis": "Why care if it's good or bad?", "generated_explanations": [["If someone questions how to distinguish good from bad, it implies uncertainty or lack of concern about the distinction, which aligns with asking why one should care if something is good or bad.", "e", "not_validated"], ["The context discusses discerning between good and bad, but does not address or imply reasons for caring about the distinction.", "n", "validated"], ["The motivation or emotional investment in distinguishing good from bad is not mentioned or explored in the context.", "n", "validated"], ["The context implies that distinguishing between good and bad is important, while the statement suggests indifference, contradicting the context’s focus on discernment.", "c", "validated"], ["The context presupposes that value judgments (good vs. bad) matter, whereas the statement questions the very relevance of such judgments.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "8257n", "premise": "'But if White has any designs at all on living, he'll be as far from Little as he can possibly get by now.'", "hypothesis": "White should be afraid to come back to Little.", "generated_explanations": [["The context implies that White's survival depends on staying away from Little, suggesting there is danger associated with returning to Little, which would make White afraid to come back.", "e", "validated"], ["The phrase \"as far from Little as he can possibly get\" indicates that proximity to Little poses a threat to White, implying fear of returning.", "e", "validated"], ["The context mentions White avoiding Little to stay alive but does not explicitly state that fear is the motivation—self-preservation or tactical reasons are possible.", "n", "validated"], ["The context is ambiguous about White's emotional state; it only infers behavior, not feelings like fear.", "n", "validated"], ["The word \"should\" in the statement implies a judgment or recommendation not supported by the context, which is observational rather than prescriptive.", "n", "validated"], ["The context expresses what White would do if he wanted to stay alive, not what he should feel.", "c", "validated"], ["The statement attributes an emotion (\"afraid\") to White, while the context only describes a logical action (staying away from Little).", "c", "validated"], ["The context does not mention or imply fear as White's motivation—just a survival strategy.", "c", "validated"], ["\"Should be afraid\" is an evaluation or recommendation, which is not present in the context that only discusses likely behavior.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 4}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "141110n", "premise": "yes well yeah i am um actually actually i think that i at the higher level education i don't think there's so much of a problem there it's pretty much funded well there are small colleges that i'm sure are struggling", "hypothesis": "Small colleges usually have trouble with funding and resources.", "generated_explanations": [["The speaker mentions that small colleges are \"struggling,\" which implies they have difficulty with funding and resources.", "e", "validated"], ["The context contrasts higher level education being \"funded well\" with small colleges, suggesting small colleges do not receive as much funding and therefore struggle.", "e", "validated"], ["The context mentions uncertainty about small colleges struggling, using \"i'm sure\" rather than providing concrete evidence, making it unclear if trouble with funding and resources is typical.", "n", "validated"], ["The context only references \"small colleges\" in passing and does not specify \"usually,\" so the frequency or commonality of funding troubles is not established.", "n", "validated"], ["The speaker suggests that at the higher level of education, funding is generally sufficient, implying that most small colleges are not usually struggling with funding and resources.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "84055n", "premise": "Even if auditors do not follow such other standards and methodologies, they may still serve as a useful source of guidance to auditors in planning their work under GAGAS.", "hypothesis": "GAGAS requires strict compliance for auditors to follow.", "generated_explanations": [["The context indicates that other standards and methodologies can serve as guidance even if not followed, suggesting that GAGAS may not require strict compliance but may allow for flexibility.", "n", "validated"], ["The context does not explicitly state the requirements or compliance obligations under GAGAS, leaving the level of strictness undetermined.", "n", "validated"], ["The context suggests that auditors are not required to follow other standards and methodologies strictly, but can use them as guidance, implying that strict compliance is not mandated by GAGAS.", "c", "validated"], ["The statement claims that GAGAS requires strict compliance, whereas the context indicates flexibility in using other standards as helpful guidance rather than mandatory rules.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "143789n", "premise": "What a brilliantly innocuous metaphor, devised by a master manipulator to obscure his manipulations.", "hypothesis": "The metaphor was created by the manipulator to convince people of something.", "generated_explanations": [["The metaphor was devised by a manipulator with the intent to obscure his manipulations, which implies an attempt to influence or convince people of something other than the truth.", "e", "validated"], ["The context states that the metaphor was devised to obscure manipulations, but it does not specify that its purpose was to convince people of something.", "n", "validated"], ["Obscuring manipulations does not necessarily entail convincing people; it could simply be to hide intentions or actions.", "n", "validated"], ["There is no explicit mention in the context of the manipulator trying to make anyone believe a particular idea or fact.", "n", "validated"], ["The context states the metaphor was devised to obscure manipulations, not necessarily to convince people of something.", "c", "validated"], ["Obscuring manipulations implies hiding intent or actions rather than actively persuading or convincing others.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "13911n", "premise": "Changes in technology and its application to electronic commerce and expanding Internet applications will change the specific control activities that may be employed and how they are implemented, but the basic requirements of control will not have changed.", "hypothesis": "Technology will make it so we have less control of activities.", "generated_explanations": [["The context states that the basic requirements of control will not change, but does not specify whether the level of control—specifically, \"less control\"—will occur; thus, it is not clear whether technology will actually reduce control.", "n", "validated"], ["The context mentions changes in the specific control activities and their implementation, but does not indicate whether these changes result in more, the same, or less control.", "n", "validated"], ["The context states that the basic requirements of control will not have changed, indicating that technology does not reduce control over activities.", "c", "validated"], ["The context suggests that only the specific control activities and their implementation will change, not the overall level of control.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "122062n", "premise": "The order was founded by James VII (James II of England) and continues today.", "hypothesis": "Kings frequently founded orders that can still be found today.", "generated_explanations": [["The context provides an example of a king (James VII/James II) founding an order that still exists, which supports the generality of the statement.", "e", "validated"], ["The use of \"continues today\" in the context demonstrates that at least some orders founded by kings have persisted over time, contributing evidence to the frequency suggested by \"frequently.\"", "e", "not_validated"], ["The persistence of an order founded by a historical king implies that establishing lasting orders was within the capacity and practice of kings.", "e", "not_validated"], ["The context mentions only one specific instance of a king founding an order that continues today, not the frequency of such occurrences, so there is insufficient information to generalize about other kings and orders.", "n", "validated"], ["The context does not provide any data or examples about how common it is for kings to found enduring orders, leaving the statement undetermined.", "n", "validated"], ["The context only indicates that one king founded one order that still exists today, not that this is a frequent occurrence among kings generally.", "c", "validated"], ["There is no information in the context about the frequency with which kings founded lasting orders; it provides only a single example, which is insufficient to support a general claim.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 2}}
{"id": "49396e", "premise": "The road along the coastline to the south travels through busy agricultural towns and fishing villages untouched by tourism.", "hypothesis": "There are no tourists on the road through the agricultural towns and fishing villages.", "generated_explanations": [["The fishing villages are described as \"untouched by tourism,\" implying that tourists do not visit these areas, and therefore are not present on the road through them.", "e", "validated"], ["The context states that the towns and villages are \"untouched by tourism,\" which may refer to the lack of tourism infrastructure or commercial tourism impact rather than the complete absence of individual tourists.", "n", "validated"], ["The context does not specify the presence or absence of individual tourists; people not associated with tourism businesses could still travel through the area.", "n", "validated"], ["The statement refers specifically to the road itself, while the context discusses the characteristics of the towns and villages, not the exact population or presence of travelers on the road.", "n", "validated"], ["The context states that the towns and villages are \"untouched by tourism,\" which means they have not been affected by tourism but does not directly assert that there are absolutely no tourists present on the road.", "c", "validated"], ["The presence of the road itself implies possible travel, and while tourism may not have impacted the area, it does not exclude the isolated occurrence of tourists.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "73444n", "premise": "well they're so close to an undefeated undefeated season they can taste it and they wanna make history so i don't think they're gonna lack for motivation", "hypothesis": "Unless they suffer any losses, they'll remain motivated.", "generated_explanations": [["Their motivation is driven by being close to an undefeated season and the desire to make history, implying that as long as they stay undefeated (i.e., suffer no losses), their motivation will persist.", "e", "validated"], ["The context suggests motivation is sustained by the goal of making history, but it does not specify if motivation would decrease or persist in case of a loss.", "n", "validated"], ["The statement assumes losses would directly affect motivation, but the context does not address how losses would impact their drive.", "n", "validated"], ["The relationship between suffering losses and motivation is not explicitly discussed, so it is unclear whether motivation depends solely on remaining undefeated.", "n", "validated"], ["The context suggests their motivation is strong because they are close to an undefeated season and want to make history, not because of whether they suffer losses, so their motivation is not contingent on suffering losses.", "c", "validated"], ["The statement implies motivation depends on not suffering losses, but the context indicates their motivation comes from their desire for a perfect season and to make history.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "79106e", "premise": "The woman rolled and drew two spears before the horse had rolled and broken the rest.", "hypothesis": "They were in rotation on the ground grabbing their weapons.", "generated_explanations": [["The phrase \"rolled\" implies that individuals were moving or rotating on the ground.", "e", "validated"], ["The woman \"drew two spears,\" indicating she was grabbing weapons during the action.", "e", "not_validated"], ["The context mentions the woman rolling and drawing spears, but it is unclear if this involved being \"in rotation on the ground\" as stated.", "n", "validated"], ["The statement implies both individuals (\"they\") were grabbing their weapons while in rotation on the ground, but the context only describes the woman drawing spears and does not specify the horse or anyone else grabbing weapons.", "n", "validated"], ["The context does not clearly define who \"they\" refers to, leaving ambiguity about whether multiple people were involved in weapon-grabbing activities.", "n", "validated"], ["The context does not state that anyone was grabbing weapons while in rotation on the ground; it only mentions rolling and drawing spears.", "c", "validated"], ["The context refers to specific actions by the woman and the horse, not \"they\" as a group engaged in the described activity.", "c", "validated"], ["The phrase \"in rotation on the ground\" implies continuous spinning or turning, which is not supported by the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "82230e", "premise": "However, the other young lady was most kind.", "hypothesis": "I received a warm welcome from the other young lady who was present.", "generated_explanations": [["Referring to someone as \"most kind\" implies that the person behaved in a warm and welcoming manner.", "e", "validated"], ["The use of \"other young lady\" in both sentences makes it clear the same individual is being described.", "e", "validated"], ["The context states that the young lady was \"most kind,\" but it does not specify that her kindness was directed toward welcoming the speaker.", "n", "validated"], ["\"Most kind\" could refer to any kind action, not necessarily a warm welcome.", "n", "validated"], ["The context does not confirm that the speaker was actually present with the young lady or received any interaction from her.", "n", "validated"], ["The context indicates the other young lady was kind but does not mention a welcome or any interaction.", "c", "validated"], ["The statement assumes the speaker received a warm welcome, which is not specified in the context.", "c", "validated"], ["The context does not confirm that the speaker interacted with the young lady at all.", "c", "validated"], ["The presence of the speaker is not specified in the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 4}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "14280n", "premise": "The author began with a set of hunches or hypotheses about what can go wrong in agency management, and what would be evidence supporting-or contradicting-these hypotheses.", "hypothesis": "The hunches provided by the author weren't realistic as it pertains to agency management.", "generated_explanations": [["The context does not specify the content or realism of the author's hunches, only that they existed.", "n", "validated"], ["There is no information in the context regarding whether the hunches were later validated or invalidated.", "n", "validated"], ["The context does not indicate whether the hunches were realistic or not; it only states that the author had hunches or hypotheses about agency management.", "c", "validated"], ["The context mentions that the author sought evidence to support or contradict these hypotheses, which suggests an intention to test their realism rather than assuming they were unrealistic.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "19668c", "premise": "okay and and i think we just hang up i don't think we have to do anything else", "hypothesis": "We need to wait until they tell us what to do.", "generated_explanations": [["The context does not specify whether someone will provide further instructions after the call.", "n", "validated"], ["The context lacks information about any requirement to wait for additional guidance.", "n", "validated"], ["It is unclear in the context if someone else is responsible for telling the speakers what to do next.", "n", "validated"], ["The context states that \"we just hang up\" and \"don't have to do anything else,\" which contradicts the idea that further instructions or waiting are necessary.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "12562n", "premise": "David Cope, a professor of music at the University of California at Santa Cruz, claims to have created a 42 nd Mozart symphony.", "hypothesis": "Music Professor David Cope who specializes in Mozart's music claims to have created Mozart's 42nd symphony.", "generated_explanations": [["David Cope is identified as a professor of music at the University of California at Santa Cruz, matching the description of \"Music Professor David Cope.\"", "e", "not_validated"], ["The context states that David Cope claims to have created a 42nd Mozart symphony, directly supporting the claim in the statement.", "e", "validated"], ["Cope’s specialization is implied by his creation of a Mozart symphony, which aligns with the statement that he specializes in Mozart's music.", "e", "not_validated"], ["The context states David Cope is a professor of music, but does not specify that he specializes in Mozart's music.", "n", "validated"], ["The context mentions that David Cope is at UC Santa Cruz, but the statement does not specify any affiliation, leaving room for ambiguity about university connection.", "n", "not_validated"], ["The context says David Cope claims to have created \"a 42nd Mozart symphony,\" but the statement refers specifically to \"Mozart's 42nd symphony,\" implying authorship or direct composition by Mozart, which is not confirmed in the context.", "n", "validated"], ["The context states that David Cope is a professor of music, but does not specify that he specializes in Mozart's music.", "c", "not_validated"], ["The context says Cope claims to have created \"a 42nd Mozart symphony,\" not specifically \"Mozart's 42nd symphony,\" which could imply he composed a new work in the style of Mozart, not an authentic work by Mozart himself.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 2, "n": 1, "c": 1}}
{"id": "111693e", "premise": "The conspiracy-minded allege that the chains also leverage their influence to persuade the big publishers to produce more blockbusters at the expense of moderate-selling books.", "hypothesis": "Big publishers want to produce more high budget films, even if that means badly selling books.", "generated_explanations": [["The context discusses book publishing and sales, while the statement refers to publishers making high budget films, introducing uncertainty about whether \"publishers\" in the context and \"film producers\" in the statement are the same entities.", "n", "validated"], ["The context mentions an alleged shift towards blockbuster books, but does not provide information about publishers' intentions regarding film production or their willingness to risk book sales for film production.", "n", "validated"], ["The context addresses the influence of chains on publishers' book production, not on film production or budget allocation between films and books.", "n", "validated"], ["The statement refers to \"high budget films,\" while the context discusses \"blockbusters\" in the context of books, not films.", "c", "validated"], ["The statement implies that publishers prioritize film production over book sales, whereas the context is about publishers shifting focus from moderate-selling books to blockbuster books, not films.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "124839c", "premise": "(A bigger contribution may or may not mean, I really, really support Candidate X.) Freedom of association is an even bigger stretch--one that Justice Thomas would laugh out of court if some liberal proposed it.", "hypothesis": "A bigger contribution means to support candidate Y.", "generated_explanations": [["The context states that a bigger contribution \"may or may not\" mean strong support for Candidate X, which allows for the possibility that a bigger contribution does indicate support for a candidate, including Candidate Y.", "e", "not_validated"], ["The context directly links making a contribution with the concept of \"supporting\" a candidate, implying a relationship between financial contributions and support.", "e", "not_validated"], ["The context explicitly states that a bigger contribution may or may not indicate strong support for a candidate, which suggests uncertainty about the implication of a bigger contribution.", "n", "validated"], ["The context focuses on Candidate X, whereas the statement refers to Candidate Y, and there is insufficient information to assume the reasoning applies identically to both candidates.", "n", "validated"], ["The context states that a bigger contribution may or may not indicate strong support for a candidate, implying that such a contribution does not necessarily equate to support for candidate Y.", "c", "validated"], ["The statement assumes a direct relationship between contribution size and support level, but the context explicitly questions this assumption.", "c", "validated"], ["The context discusses Candidate X, while the statement refers to candidate Y, and there is no information linking contributions to candidate Y specifically.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "72870n", "premise": "Because marginal costs are very low, a newspaper price for preprints might be as low as 5 or 6 cents per piece.", "hypothesis": "Many people consider these prices to be unfair to new printers.", "generated_explanations": [["The context does not mention how people, including new printers, perceive the prices.", "n", "validated"], ["There is no information in the context about opinions regarding fairness or unfairness of the prices.", "n", "validated"], ["The context does not discuss the impact of these prices on new printers specifically.", "n", "validated"], ["The context does not mention any opinions or perceptions about the fairness of the prices.", "c", "validated"], ["There is no reference to new printers or how they are affected by the pricing.", "c", "validated"], ["The focus is solely on the low marginal cost and potential newspaper prices, not on fairness concerns.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "129601n", "premise": "Took forever.", "hypothesis": "Lasted two years", "generated_explanations": [["\"Took forever\" is a subjective expression that can refer to any long duration, and two years can be perceived as a long time depending on the situation.", "e", "not_validated"], ["The phrase \"Took forever\" is subjective and does not specify an exact duration, so it is unclear whether it refers to a span of two years.", "n", "validated"], ["Without additional temporal information, \"forever\" could refer to a period longer or shorter than two years, making it impossible to determine if \"Lasted two years\" is accurate.", "n", "validated"], ["\"Took forever\" is a subjective exaggeration and does not necessarily mean the duration was exactly two years; it could have been shorter or longer.", "c", "validated"], ["Two years is a specific, finite amount of time and may not universally be considered \"forever,\" which typically implies an indefinite or extremely long period.", "c", "validated"], ["The context does not specify any concrete time frame, so asserting \"lasted two years\" introduces information not present in the context.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "26372n", "premise": "Just like we have hairpins and powder-puffs.\" Tommy handed over a rather shabby green notebook, and Tuppence began writing busily.", "hypothesis": "Tommy handed Tuppence an empty shabby green notebook.", "generated_explanations": [["The context states that Tommy handed over a shabby green notebook to Tuppence.", "e", "validated"], ["The context does not specify whether the notebook Tommy handed over was empty or contained something written inside.", "n", "validated"], ["The context does not state that the notebook is empty; it only describes it as shabby and green.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 1, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 1, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "74534n", "premise": "And far, far away- lying still on the tracks- was the back of the train.", "hypothesis": "The train wasn't moving but then it started up.", "generated_explanations": [["The context describes the back of the train as \"lying still on the tracks,\" which indicates the train was not moving.", "e", "not_validated"], ["The statement suggests a sequence where the train was stationary and then began to move, which is possible given the context that initially only specifies the train’s lack of motion but does not contradict the possibility of it starting up afterward.", "e", "not_validated"], ["The context only describes the back of the train lying still and does not mention whether the train started moving afterward.", "n", "validated"], ["There is no information in the context about any change in the train's motion after being still.", "n", "validated"], ["The context only indicates that the back of the train was lying still on the tracks, with no mention of the train starting to move.", "c", "validated"], ["There is no information in the context about any change in the train's motion or that it started up after being still.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "63469c", "premise": "It lacked intelligence, introspection, and humor--it was crass, worthy of Cosmopolitan or Star . I do have a sense of humor, but can only appreciate a joke when it starts with a grain of truth.", "hypothesis": "The article won a Pulitzer Prize.", "generated_explanations": [["The context criticizes the article's quality but does not mention whether it won any awards.", "n", "validated"], ["An article described as lacking quality could conceivably still win a prize, but that information is not present in the context.", "n", "validated"], ["The context does not provide information about awards or recognition received by the article.", "n", "validated"], ["The context describes the article as crass and lacking intelligence, introspection, and humor, which are not qualities typically associated with Pulitzer Prize-winning work.", "c", "validated"], ["The comparison to Cosmopolitan or Star implies the article is of low journalistic or literary quality, making it unlikely to have received such a prestigious award.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "141321n", "premise": "It will be held in the Maryland woods, and the telecast will consist of jittery footage of the contestants' slow descent into madness as they are systematically stalked and disappeared/disqualified by Bob Barker.", "hypothesis": "The show will be set in the woods north of Boston.", "generated_explanations": [["The context specifies Maryland as the location, but does not clarify whether any part of the event is set in the woods north of Boston.", "n", "validated"], ["The context does not provide enough geographic detail to confirm or deny the involvement of woods north of Boston.", "n", "validated"], ["There is a possibility of multiple filming locations, which is not addressed in the context.", "n", "validated"], ["The context states the location is the Maryland woods, not the woods north of Boston.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "68946c", "premise": "It has served as a fortress for the Gallo-Romans, the Visigoths, Franks, and medieval French (you can see the layers of their masonry in the ramparts).", "hypothesis": "The fortress was built by the medieval French in 1173.", "generated_explanations": [["The context states that the fortress was used by multiple groups, including Gallo-Romans, Visigoths, and Franks, before the medieval French, but does not specify when each group built or modified the structure.", "n", "validated"], ["There is no information in the context about the exact construction date of the fortress.", "n", "validated"], ["The context mentions different layers of masonry, implying modifications or extensions by different groups, but does not clarify which group built the original structure or in which year.", "n", "validated"], ["The statement assigns a specific year (1173) and a specific group (medieval French) for the construction, which is not confirmed or contradicted by the context.", "n", "validated"], ["The fortress existed before the medieval French, as it had already served the Gallo-Romans, Visigoths, and Franks.", "c", "validated"], ["The context indicates multiple layers of occupation and construction, so the initial building of the fortress could not have occurred as late as 1173 by the medieval French.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "41975c", "premise": "Tommy realized perfectly that in his own wits lay the only chance of escape, and behind his casual manner he was racking his brains furiously.", "hypothesis": "He'd been stuck for hours, starting to feel doubt crawl into his mind.", "generated_explanations": [["Tommy is trying to escape and is under significant mental strain, which could lead to doubt creeping into his thoughts after a prolonged period without success.", "e", "not_validated"], ["The phrase \"racking his brains furiously\" suggests intense effort and possible frustration, which often accompany extended difficulty and doubt.", "e", "not_validated"], ["The context implies Tommy's situation depends solely on his own resources, increasing pressure and the likelihood of self-doubt over time.", "e", "validated"], ["The context does not specify how long Tommy has been trying to escape, so it is unclear if he has been stuck for hours.", "n", "validated"], ["The context does not mention Tommy feeling doubt; it only describes him racking his brains and maintaining a casual manner.", "n", "validated"], ["The context focuses on Tommy's awareness and mental effort but does not reveal any creeping feelings of despair or doubt.", "n", "validated"], ["The context does not mention Tommy being stuck for hours; it only describes his current mental state.", "c", "validated"], ["The context indicates Tommy is focused and actively using his wits, not experiencing creeping doubt.", "c", "validated"], ["There is no indication in the context that time has passed or that Tommy’s confidence is waning.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 2}}
{"id": "100349e", "premise": "He touched it and felt his skin swelling and growing hot.", "hypothesis": "His skin was burning.", "generated_explanations": [["Swelling and growing hot are symptoms that commonly accompany a burning sensation in the skin.", "e", "validated"], ["The description of his skin growing hot implies a sensation similar to burning.", "e", "validated"], ["The context mentions swelling and heat but does not specify burning, which could refer to an actual flame or more intense sensation than heat.", "n", "validated"], ["\"Burning\" can be interpreted as either a sensation or literal combustion, and the context does not clarify which, if any, is occurring.", "n", "validated"], ["Other causes for swelling and heat, such as an allergic reaction or irritation, are possible, so burning is not the only explanation.", "n", "validated"], ["The context mentions his skin growing hot but does not indicate actual burning, which involves tissue damage.", "c", "validated"], ["Swelling and heat can occur without burning; these symptoms could result from irritation or an allergic reaction rather than burning.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "107399c", "premise": "Bush the elder came of age when New England Republicans led the party, and patrician manners were boons to a Republican.", "hypothesis": "New England Republicans were weak.", "generated_explanations": [["The context does not provide information about the strength or weakness of New England Republicans.", "n", "validated"], ["The context suggests that New England Republicans led the party, but leadership does not necessarily indicate strength or weakness.", "n", "validated"], ["The context focuses on manners and cultural influence rather than political power or effectiveness.", "n", "validated"], ["The context states that New England Republicans \"led the party,\" indicating they held significant influence and power, which contradicts the assertion that they were weak.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "131623c", "premise": "In the depths of the Cold War, many Americans suspected Communists had infiltrated Washington and were about to subvert our democracy.", "hypothesis": "Communists assisted America's government during the Cold War.", "generated_explanations": [["The context only mentions suspicions of Communist infiltration, not evidence of actual assistance to the government.", "n", "validated"], ["The statement assumes Communists were actively helping the government, while the context discusses fears of subversion, which implies harm rather than assistance.", "n", "validated"], ["The context describes suspicion and fear of subversion by Communists, not assistance to the government.", "c", "validated"], ["The implication in the context is that Communists were perceived as hostile actors, not collaborators or supporters of government functions.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "58954c", "premise": "For an authentic feel of old Portugal, slip into the cool entrance hall of theimpressive Leal Senado ( Loyal Senate building), a fine example of colonial architecture.", "hypothesis": "All that remains of  Leal Senado is old ruins.", "generated_explanations": [["The context describes entering the Leal Senado building, implying it still exists and is functional, but does not explicitly state whether only ruins remain or if the building is fully intact.", "n", "validated"], ["The context refers to the Leal Senado as an impressive example of architecture, which could suggest preservation, but it does not clearly address the current physical condition (restored, partly ruined, or fully ruined).", "n", "validated"], ["The context does not specify if portions of the Leal Senado have been destroyed or remain as ruins, leaving open the possibility that only ruins exist or that the building is fully preserved.", "n", "validated"], ["The context describes the Leal Senado as an \"impressive\" and functional building, not as ruins.", "c", "validated"], ["The statement is contradicted by the suggestion to \"slip into\" the entrance hall, implying the building is intact and accessible.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "74377e", "premise": "no chemicals and plus then you can use it as a fertilizer and not have to worry about spreading those chemicals like on your lawn or your bushes or whatever", "hypothesis": "We don't want to use chemicals on our lawn", "generated_explanations": [["Using fertilizers without chemicals avoids spreading chemicals on the lawn.", "e", "validated"], ["The concern mentioned is about not wanting to worry about chemicals on the lawn.", "e", "validated"], ["The context discusses not having to worry about spreading chemicals, but does not explicitly state a desire or intent regarding their use.", "n", "validated"], ["The context mentions the potential benefit of a product or method not involving chemicals, without specifying the preferences or desires of the speaker.", "n", "validated"], ["The context discusses avoiding chemicals to allow the resulting product to be safely used as fertilizer, but does not state an explicit preference or desire about not wanting to use chemicals on the lawn.", "c", "validated"], ["The context only mentions not spreading chemicals as a benefit, rather than expressing opposition or desire concerning their use.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "130680e", "premise": "We also have found that leading organizations strive to ensure that their core processes efficiently and effectively support mission-related outcomes.", "hypothesis": "Leading organizations want to be sure their processes are successful.", "generated_explanations": [["Leading organizations aim for their core processes to efficiently and effectively support mission-related outcomes, which implies a desire for successful processes.", "e", "validated"], ["Ensuring that processes support mission-related outcomes suggests that organizations want their processes to achieve intended results, indicating a concern for process success.", "e", "validated"], ["The context mentions \"efficiently and effectively support mission-related outcomes,\" but it does not specify whether \"successful\" is defined in the same way as \"efficient and effective\" or \"supporting outcomes.\"", "n", "validated"], ["The context does not state the desires or intentions (\"want to be sure\") of leading organizations, only their actions or efforts.", "n", "validated"], ["The context refers to \"core processes\" while the statement broadly says \"their processes,\" leaving ambiguity as to whether this applies to all processes or only some.", "n", "validated"], ["The context specifies that leading organizations focus on supporting mission-related outcomes, not just general process success.", "c", "not_validated"], ["The context emphasizes efficiency and effectiveness in support of mission-related outcomes rather than the broader or vaguer goal of \"processes being successful.\"", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "49227n", "premise": "well that's uh i agree with you there i mean he didn't have the surrounding cast that Montana had there's no doubt about that", "hypothesis": "I agree that he didn't have the same support as Montana, but he did well.", "generated_explanations": [["The context explicitly states agreement that \"he didn't have the surrounding cast that Montana had,\" matching the statement's acknowledgment of this lack of support.", "e", "validated"], ["The context implies that, despite lacking support, the person under discussion is being evaluated, which is consistent with the statement's implication that he nevertheless performed well.", "e", "validated"], ["The context confirms agreement on the lack of a surrounding cast but does not mention or imply how \"he\" performed, so it is unknown whether the speaker thinks \"he did well.\"", "n", "validated"], ["The phrase \"he did well\" is not discussed in the context, so there is insufficient information to determine if the speaker believes this part of the statement.", "n", "validated"], ["The context does not mention or imply that \"he did well\"; it only expresses agreement that he lacked the supporting cast.", "c", "validated"], ["The statement introduces the idea of \"doing well,\" which is not addressed or supported by the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "124853e", "premise": "H-2A agricultural workers are required to maintain a foreign residence which they have no intention of abandoning.", "hypothesis": "Permanent foreign residence is required for some types of agricultural work visas.", "generated_explanations": [["H-2A agricultural workers must maintain a foreign residence they do not intend to abandon, which means holding a permanent foreign residence is a requirement for the H-2A visa.", "e", "validated"], ["The context specifies the requirement for H-2A workers, but does not provide information about other types of agricultural work visas, so it is unclear if the statement applies universally.", "n", "validated"], ["The phrase \"permanent foreign residence\" in the statement may have a different legal meaning than \"foreign residence which they have no intention of abandoning\" in the context, so equivalency cannot be assumed.", "n", "validated"], ["\"Permanent\" foreign residence implies an intention to reside indefinitely in the foreign country, whereas H-2A workers are only required to maintain a foreign residence with no intention of abandoning it, not necessarily in a permanent or indefinite sense.", "c", "validated"], ["The requirement to maintain a foreign residence is tied to visa status (non-immigrant intent), not the nature of the agricultural work itself.", "c", "validated"], ["Not all types of agricultural work visas require maintenance of a foreign residence; the statement generalizes beyond H-2A visas.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "117892n", "premise": "No, Dave Hanson, you were too important to us for that.", "hypothesis": "No, Dave Hanson, we couldn't risk your life becaus you are too important to us.", "generated_explanations": [["Saying \"you were too important to us for that\" implies that Dave's importance prevented them from taking a certain action, which aligns with not wanting to risk his life.", "e", "validated"], ["Both the context and statement express the idea that Dave's value or importance was the reason for a protective decision.", "e", "validated"], ["The context's phrase \"for that\" is clarified in the statement as \"risk your life,\" which is a possible action that would not be taken due to his importance.", "e", "validated"], ["The context does not specify what action \"that\" refers to, so it is unclear whether it involved risking Dave Hanson's life.", "n", "validated"], ["The context does not mention risk to Dave Hanson's life, only his importance.", "n", "validated"], ["The context does not mention risking Dave Hanson's life; it only states his importance, not any specific action or risk.", "c", "validated"], ["The statement introduces the idea of not risking Dave Hanson's life, which is not present in the context.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "111243n", "premise": "The pope, suggesting that Gen.", "hypothesis": "Gen is being suggested by the Pope.", "generated_explanations": [["The phrase \"The pope, suggesting that Gen.\" implies that the Pope is making a suggestion about Gen, which can be interpreted as the Pope suggesting Gen.", "e", "not_validated"], ["The context does not specify what the Pope is suggesting about Gen, only that a suggestion is being made involving Gen.", "n", "validated"], ["It is unclear from the context whether Gen is being recommended, mentioned, or discussed in another capacity by the Pope.", "n", "validated"], ["The directionality of the suggestion (whether Gen is the subject or object of the suggestion) is ambiguous in the context.", "n", "validated"], ["The statement implies direct suggestion of Gen as a person (\"Gen\"), but the context may be using \"suggesting that Gen...\" as the start of a longer sentence or idea, leaving the intent incomplete.", "n", "validated"], ["The context states that the pope is suggesting something about Gen, not suggesting Gen as a person.", "c", "validated"], ["The statement misinterprets the context by implying that Gen is the subject of the suggestion, rather than the topic or object about which the suggestion is made.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "77654e", "premise": "but there's no uh inscriptions or or dates or anything else", "hypothesis": "There aren't any dates on it?", "generated_explanations": [["The context explicitly mentions there are no inscriptions or dates.", "e", "validated"], ["The phrase \"no uh inscriptions or or dates\" directly implies the absence of dates.", "e", "validated"], ["The context mentions there are no inscriptions, dates, or anything else, but the speaker says \"uh,\" indicating some uncertainty, so it is not absolutely clear.", "n", "validated"], ["The context does not specify what \"it\" refers to, so it’s not certain if the lack of dates applies to the same object as in the statement.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "110061n", "premise": "If you have the energy to climb the 387 steps to the top of the south tower, you will be rewarded with a stunning view over the city.", "hypothesis": "The south tower has the best view in the city.", "generated_explanations": [["The context describes the view from the top of the south tower as \"stunning,\" which implies it is exceptionally good, possibly the best in the city.", "e", "not_validated"], ["The context mentions a \"stunning view\" but does not compare the south tower's view to other locations in the city.", "n", "validated"], ["The context lacks information about views from other towers or viewpoints in the city, so it is unclear if the south tower's view is the best.", "n", "validated"], ["The context only mentions a \"stunning view\" from the south tower, not that it is the best view in the city.", "c", "validated"], ["There may be other locations in the city that offer an equal or better view, which the context does not address.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "29844c", "premise": "I am glad she wasn't, said Jon.", "hypothesis": "Jon was sad that she wasn't happy.", "generated_explanations": [["The context does not specify Jon’s emotional state regarding her happiness, only that he was glad about an unspecified outcome.", "n", "validated"], ["The context does not indicate whether \"she\" was or wasn't happy, nor Jon's feelings about her happiness.", "n", "validated"], ["The reason for Jon's gladness is not clarified; it may be unrelated to her happiness.", "n", "validated"], ["Jon expressed gladness, not sadness, about the situation.", "c", "validated"], ["The context does not mention anything about the woman's happiness.", "c", "validated"], ["Jon's statement refers only to whether \"she wasn't\" (unspecified), not specifically to her being happy.", "c", "not_validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "27335e", "premise": "is there still that type of music available", "hypothesis": "Is that genre of music still a thing?", "generated_explanations": [["\"Type of music\" and \"genre of music\" refer to the same concept.", "e", "validated"], ["Asking if something is \"available\" and if it is \"still a thing\" are both inquiries about whether it continues to exist or be accessible.", "e", "validated"], ["Both the context and the statement are expressing uncertainty about the continued existence or presence of the same category of music.", "e", "validated"], ["\"That type of music\" in the context may not refer to the exact same meaning as \"that genre of music\" in the statement.", "n", "validated"], ["The context questions the availability of the music, while the statement questions its continued existence or relevance, which are not necessarily equivalent.", "n", "validated"], ["The context does not specify whether \"available\" means being produced, being popular, or simply accessible, leading to ambiguity in matching the intent of the statement.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 3}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "87332c", "premise": "Strange as it may seem to the typical household, capital gains on its existing assets do not contribute to saving as measured in NIPA.", "hypothesis": "NIPA considers cat fur when it defines savings.", "generated_explanations": [["The context only discusses how capital gains on existing assets are treated in savings measurement according to NIPA, but does not mention or imply anything about cat fur.", "n", "validated"], ["There is no information about whether NIPA includes or excludes cat fur in its definition of savings.", "n", "validated"], ["The context specifies that NIPA (National Income and Product Accounts) does not count capital gains on assets as savings, showing its focus is on financial measures, not physical items such as cat fur.", "c", "validated"], ["There is no mention or implication that cat fur is considered by NIPA in the definition of savings; the context discusses assets and capital gains, not animal products.", "c", "validated"], ["NIPA is an economic accounting framework focused on macroeconomic indicators and would not include unrelated items like cat fur in its calculation of savings.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "53499c", "premise": "my goodness it's hard to believe i didn't think there was anybody in the country who hadn't seen that one", "hypothesis": "I thought I was the only one in this country who had seen it.", "generated_explanations": [["The context mentions someone expressing surprise that anyone in the country had not seen \"that one,\" but does not specify the speaker's prior beliefs about being the only one who had seen it.", "n", "validated"], ["The context does not clarify whether the speaker believed they were unique in having seen it or simply assumed nearly everyone had.", "n", "validated"], ["The context implies the speaker believed everyone in the country had seen it, not just themselves.", "c", "validated"], ["The context expresses surprise that anyone had not seen it, which contradicts the idea of thinking only they had seen it.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "65199n", "premise": "and i look back on that and i bought shoes i went shopping i did not need that money i did not need it i didn't need it i shouldn't have even qualified to get it i didn't need it and it would have been a little rough i might have eaten some bologna instead of roast beef out of the deli but i did not need it and as i look back now now we're paying that back i told my son if you have to live in the ghetto to go to college do it but don't take out ten thousand dollars in loans don't do it and i don't i hope don't think he'll have to do that but i just so like we might if we didn't have those loans we could have saved in the last five years the money for that and i believe we would have because God's really put it in our heart not to get in debt you know but we have friends at church that do this on a constant basis that are totally debt free and they pay cash for everything they buy", "hypothesis": "I am envious of all my debt-free churchgoing friends.", "generated_explanations": [["The speaker expresses admiration for friends at church who are totally debt free and pay cash for everything they buy.", "e", "not_validated"], ["The speaker reflects regret about taking out loans and wishes they had not gotten into debt.", "e", "not_validated"], ["The speaker contrasts their own financial struggles with the stability and freedom of their debt-free friends.", "e", "not_validated"], ["The speaker describes wishing they could have saved money instead of paying back loans, implying a preference for the situation their debt-free friends are in.", "e", "not_validated"], ["The speaker does not explicitly express feelings of envy toward their debt-free friends; they only mention their behavior as an example.", "n", "validated"], ["The speaker references admiration or observation rather than any personal longing or comparative dissatisfaction.", "n", "validated"], ["The emotions the speaker expresses are mainly regret over their own financial decisions, not jealousy of others.", "n", "validated"], ["The context focuses on personal responsibility and lessons learned rather than on the speaker’s feelings toward others’ situations.", "n", "validated"], ["The speaker does not express envy but rather uses their debt-free friends as examples to illustrate a point about financial management.", "c", "validated"], ["The speaker describes admiration for their friends' financial choices, not envy.", "c", "validated"], ["The focus is on regret about personal financial decisions, not on comparing themselves with or desiring what their friends have.", "c", "validated"], ["The statement \"I am envious\" is not supported by any expression of jealousy or longing for their friends' situations; instead, the speaker offers advice and self-reflection.", "c", "validated"]], "label_count_round_1": {"e": 4, "n": 4, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 4, "c": 4}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 4}}
{"id": "88050c", "premise": "If you have any questions about this report, please contact Henry R. Wray, Senior Associate General Counsel, at (202) 512-8581.", "hypothesis": "Henry R. Wray can be reached at (555) 512-8581.", "generated_explanations": [["The context provides Henry R. Wray's contact number as (202) 512-8581, but the statement gives a different area code (555), and it is not specified whether both numbers reach him.", "n", "validated"], ["The context does not mention Henry R. Wray having a number with the area code (555), so it is undetermined if that number is assigned to him.", "n", "validated"], ["The possibility that (555) 512-8581 is an alternative contact for Henry R. Wray is not confirmed or denied in the context.", "n", "validated"], ["The phone number provided in the context for reaching Henry R. Wray is (202) 512-8581, not (555) 512-8581.", "c", "validated"], ["The area code in the statement, (555), does not match the area code in the context, which is (202).", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "34094e", "premise": "No, monsieur.", "hypothesis": "The speaker is answering no to a question.", "generated_explanations": [["The phrase \"No, monsieur\" directly communicates a negative response to someone, which is characteristic of answering \"no\" to a question.", "e", "validated"], ["The context does not clarify whether \"No, monsieur.\" is in response to a question, a statement, or another type of prompting.", "n", "validated"], ["The phrase \"No, monsieur.\" could be used as an interjection or exclamation, not necessarily as an answer to a question.", "n", "validated"]], "label_count_round_1": {"e": 1, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 1, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "72875e", "premise": "The policy succeeded, and I was fortunate to have had the opportunity to make that contribution to my people.", "hypothesis": "Because the policy was a success, I was able to make a contribution to my people.", "generated_explanations": [["The speaker indicates that the policy's success and their involvement in it enabled them to contribute positively to their people.", "e", "validated"], ["The statement logically follows since the speaker links the policy’s success and their personal opportunity to contribute.", "e", "validated"], ["The context does not specify that the policy's success was the reason the speaker was able to make a contribution; it only states both events occurred.", "n", "validated"], ["It is not clear from the context whether the speaker's opportunity to contribute was contingent upon the policy's success or if it was independent of the outcome.", "n", "validated"], ["The context does not state that the success of the policy was the reason the speaker was able to make a contribution; the causality is not established.", "c", "validated"], ["It is possible the speaker made a contribution independently of whether the policy succeeded or not.", "c", "validated"], ["The opportunity to contribute may have existed regardless of the policy’s outcome; the statement inaccurately assumes the success enabled the contribution.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "19921n", "premise": "3) The gap between the productivity of women and the productivity of men.", "hypothesis": "The gap of genders.", "generated_explanations": [["The term \"gap of genders\" refers to differences or disparities between genders, which aligns with the described productivity gap between women and men.", "e", "validated"], ["The context explicitly discusses a productivity gap that exists between genders (women and men), directly supporting the statement.", "e", "validated"], ["The phrase \"gap of genders\" is vague and does not specify which particular difference or aspect between genders is being referred to.", "n", "validated"], ["The statement does not clarify whether it is about productivity specifically or any other gap between genders, making its relationship to the context unclear.", "n", "validated"], ["The statement could refer to any kind of gender gap (such as wage, education, opportunities), not necessarily productivity.", "n", "validated"], ["The statement refers to a general gender gap, while the context specifies a gap in productivity between women and men.", "c", "validated"], ["The statement lacks detail about the specific area (productivity) where the gap exists.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "23583e", "premise": "While obviously constrained by their bondage, blacks nonetheless forged a culture rich with religious observances, folk tales, family traditions, song, and so on.", "hypothesis": "Clearly are constrained by their folk tales and traditions.", "generated_explanations": [["The context specifies that the constraint is due to bondage, not folk tales and traditions, so it is undetermined whether folk tales and traditions are constraining.", "n", "validated"], ["The context describes folk tales and traditions as aspects of a rich culture, not as sources of constraint, leaving it unclear if they are constraining.", "n", "validated"], ["The statement asserts a present-tense universal claim (\"clearly are constrained\"), but the context does not provide evidence for or against this claim regarding folk tales and traditions specifically.", "n", "validated"], ["The context states that blacks were constrained by their bondage (slavery), not by their folk tales and traditions.", "c", "validated"], ["The context portrays folk tales and traditions as elements of a rich culture, not as constraints.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "91106n", "premise": "SSA is also seeking statutory authority for additional tools to recover current overpayments.", "hypothesis": "SSA wants the authority to recover overpayments made to insurers.", "generated_explanations": [["The context states that SSA is seeking statutory authority for additional tools to recover current overpayments, which could include overpayments made to insurers, depending on to whom the overpayments were made.", "e", "not_validated"], ["The context only mentions \"current overpayments\" without specifying to whom these overpayments were made.", "n", "validated"], ["The statement refers specifically to overpayments made to \"insurers,\" but the context does not identify insurers as the recipients of overpayments.", "n", "validated"], ["The context specifies that SSA seeks authority to recover current overpayments, but does not indicate that these overpayments are made to insurers.", "c", "validated"], ["There is no mention in the context that insurers are involved with the overpayments being discussed.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "9557e", "premise": "Tommy Thompson of Wisconsin and Mayor Rudolph Giuliani of New York, the conservative vanguard on the issue, show no inclination to exploit research that says, in effect, Why care about day-care quality?", "hypothesis": "Thompson and Giuliani don't want to care about day cares.", "generated_explanations": [["The context only mentions that Thompson and Giuliani show no inclination to exploit certain research, not that they don't want to care about day cares themselves.", "n", "validated"], ["The context does not specify Thompson and Giuliani's personal views or intentions regarding caring about day cares, only their stance toward certain research.", "n", "validated"], ["The context refers to their position on the issue in general terms, without detailing whether they care or do not care about day cares.", "n", "validated"], ["The context indicates that Thompson and Giuliani do not wish to exploit research that suggests not caring about day-care quality, implying they actually do care about day cares.", "c", "validated"], ["The statement misrepresents their position by suggesting a lack of care, while the context shows they are not using dismissive research as a basis for their actions.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "15537n", "premise": "So unlike people who are fortunate enough to be able to afford attorneys and can go to another lawyer, our clients are simply lost in the legal system if they cannot get access to it from us.", "hypothesis": "Our clients can barely afford our legal assistance.", "generated_explanations": [["The context indicates that the clients are not able to afford attorneys in general, implying financial hardship regarding legal services, including those provided by \"us.\"", "e", "validated"], ["The clients' inability to seek another lawyer suggests financial constraints that make even the current legal assistance difficult to afford.", "e", "validated"], ["The context mentions clients being \"lost in the legal system\" if they cannot get access to assistance but does not specify whether this is due to financial inability or other barriers.", "n", "validated"], ["The context contrasts clients who \"can afford attorneys\" with \"our clients\" who must rely on this specific legal aid, but does not state explicitly whether their issue is affordability of the specific legal assistance or just private attorneys.", "n", "validated"], ["The context does not provide direct information about whether clients can afford legal assistance from this provider; only that their access is critical.", "n", "validated"], ["The context does not state that clients can barely afford assistance; it states they cannot get access to legal aid unless it is provided, implying they cannot afford it at all.", "c", "validated"], ["The statement implies some level of affordability, while the context suggests clients are entirely dependent on free or provided legal services, not on affordability.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "3476n", "premise": "apparently apparently the appraisers likes it because our taxes sure is high  isn't it it really is", "hypothesis": "We wished the taxes were lower.", "generated_explanations": [["The statement \"our taxes sure is high\" implies dissatisfaction with the current high tax level, indicating a preference for lower taxes.", "e", "validated"], ["Expressing that the appraisers like the property because taxes are high suggests the speaker would rather taxes were not so high, revealing a wish for lower taxes.", "e", "validated"], ["The phrase \"it really is\" reinforces the frustration or disapproval of high taxes, supporting the idea that the speaker desires lower taxes.", "e", "validated"], ["The context states that taxes are high but does not mention or imply the speakers' wishes or preferences regarding the tax amount.", "n", "validated"], ["The context expresses a fact or observation about taxes being high, not any emotional attitude or desire about tax levels.", "n", "validated"], ["The context does not mention any wishes or desires about tax levels, only an observation about high taxes.", "c", "validated"], ["There is no indication in the context that the speaker wishes for lower taxes; they simply comment on the current state.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "56124n", "premise": "Of how, when tea was done, and everyone had stood,He reached for my head, put his hands over it,And gently pulled me to his chest, which smelledOf dung smoke and cinnamon and mutton grease.I could hear his wheezy breathing now, like the prophet's Last whispered word repeated by the faithful.Then he prayed for what no one had time to translate--His son interrupted the old man to tell him a groupOf snake charmers sought his blessing, and a blind thief.The saint pushed me away, took one long look,Then straightened my collar and nodded me toward the door.", "hypothesis": "When tea was done, he put his hands on me romantically.", "generated_explanations": [["The described gesture of reaching for the speaker's head, pulling them gently to his chest, and holding them, could be interpreted as an intimate or affectionate act, which some might perceive as romantic depending on cultural or situational context.", "e", "not_validated"], ["The context describes the gesture as gentle and affectionate, but not explicitly romantic, leaving the possibility of a romantic interpretation undetermined.", "n", "validated"], ["The context does not provide information about the intent or emotional context behind the gesture, so motivation (romantic or otherwise) cannot be definitively determined.", "n", "validated"], ["The described environment (reference to praying, blessing, and the presence of others) introduces ambiguity about the nature of the touch, making it unclear whether the gesture was romantic or platonic.", "n", "validated"], ["He put his hands over the narrator's head gently and pulled the narrator to his chest, but there is no indication of romantic intent; the gesture appears caring or paternal.", "c", "validated"], ["The context describes a saint praying and interacting in a respectful, spiritual manner.", "c", "validated"], ["The setting involves a blessing and prayer, which are not typically romantic situations.", "c", "validated"], ["The phrase \"pushed me away\" and \"nodded me toward the door\" suggest dismissal rather than romance.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 4}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "5193n", "premise": "EPA estimates that 5.6 million acres of lakes, estuaries and wetlands and 43,500 miles of streams, rivers and coasts are impaired by mercury emissions.", "hypothesis": "The release of mercury has an impact on rivers, streams and lakes", "generated_explanations": [["EPA data shows that a large number of acres of lakes, estuaries, and wetlands are impaired by mercury emissions, directly indicating an impact on lakes.", "e", "validated"], ["The context mentions that a specific area and length of water bodies are \"impaired\" by mercury emissions, but it does not define what \"impaired\" means or specify the type or extent of impact mercury has.", "n", "validated"], ["The context does not explicitly state that the impairment is due to the direct release of mercury rather than other emission processes or sources.", "n", "not_validated"], ["The statement is general (\"has an impact\"), while the context quantifies impairment but does not describe whether all types of mercury release have impacts or what those impacts are.", "n", "validated"]], "label_count_round_1": {"e": 1, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 1, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "106390n", "premise": "Mykonos has had a head start as far as diving is concerned because it was never banned here (after all, there are no ancient sites to protect).", "hypothesis": "Protection of ancient sites is the reason for diving bans in other places.", "generated_explanations": [["The context states that diving was never banned in Mykonos because there are no ancient sites to protect, implying that the protection of ancient sites is the reason diving is banned elsewhere.", "e", "validated"], ["The context only implies that the absence of ancient sites to protect is a reason diving was not banned in Mykonos, but does not explicitly state that protection of ancient sites is the reason for diving bans elsewhere.", "n", "validated"], ["There may be other reasons for diving bans in other places that are not mentioned or addressed in the context.", "n", "validated"], ["The context does not explicitly state that protection of ancient sites is the reason for diving bans elsewhere; it only suggests Mykonos did not have a ban because it lacks such sites.", "c", "validated"], ["There may be other reasons for diving bans in other places unrelated to the protection of ancient sites.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "54327n", "premise": "substitute my my yeah my kid'll do uh four or five hours this week for me no problem", "hypothesis": "I just can't make the time because of my job.", "generated_explanations": [["The speaker is delegating work to their child because their own job prevents them from having the necessary time.", "e", "not_validated"], ["The mention of the child doing hours \"for me\" implies the speaker lacks the availability due to occupational commitments.", "e", "validated"], ["The context describes the speaker arranging for their child to cover time for them, but does not specify the reason why the speaker needs this arrangement.", "n", "validated"], ["There is no indication in the context as to whether the speaker’s job is the reason for their unavailability.", "n", "validated"], ["The context does not clarify whether the speaker could make time if not for their job, or if there are other constraints.", "n", "validated"], ["The context indicates that the speaker's kid will cover four or five hours for them, suggesting they are able to make time.", "c", "validated"], ["There is no mention in the context of the speaker being unable to make time due to their job; instead, it implies a solution exists.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "2870n", "premise": "Most menu prices include taxes and a service charge, but it's customary to leave a tip if you were served satisfactorily.", "hypothesis": "Most customers will tip in addition to the tax on the menus.", "generated_explanations": [["Tipping is customary when service is satisfactory, indicating that most customers do leave a tip.", "e", "not_validated"], ["Menu prices already include taxes, so any tip given by customers is in addition to the tax.", "e", "validated"], ["The context states it is \"customary to leave a tip if you were served satisfactorily,\" but does not indicate what proportion of customers actually do so.", "n", "validated"], ["The statement equates custom with action by \"most customers,\" but the context only notes what is customary, not what is common practice.", "n", "validated"], ["There is no evidence in the context quantifying actual tipping behavior relative to taxes included on menus.", "n", "validated"], ["The context states that most menu prices already include both taxes and a service charge, so tipping is not mandatory but only customary if the service is satisfactory, meaning not all customers will tip.", "c", "validated"], ["The statement suggests tipping is in addition to just the tax, whereas the context indicates that a service charge (often covering what a tip would) is also included in the price.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "63218n", "premise": "Recently, however, I have settled down and become decidedly less experimental.", "hypothesis": "I have lost my experimental nature due to old age.", "generated_explanations": [["The context suggests a transition from being experimental to being settled and less experimental, which can be interpreted as losing an experimental nature.", "e", "validated"], ["The phrase \"due to old age\" could be associated with \"settling down,\" as aging is commonly linked to adopting less experimental and more stable behaviors.", "e", "not_validated"], ["The context mentions becoming less experimental but does not specify old age as the cause.", "n", "validated"], ["The context does not provide any information about the speaker's age.", "n", "validated"], ["Other factors besides old age could explain the change in behavior.", "n", "validated"], ["The context does not mention old age as the reason for settling down or becoming less experimental.", "c", "validated"], ["The change in behavior is described as recent, which does not necessarily correlate with old age.", "c", "validated"], ["It is possible to settle down and become less experimental for reasons other than old age, such as changes in personal interests, life circumstances, or priorities.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "144753c", "premise": "When he's ready for a major strike, how many innocents do you suppose are going to suffer? To quote one of your contemporaries; 'The needs of the many outweigh the needs of the few.' '", "hypothesis": "He won't do a big strike because of the innocent people.", "generated_explanations": [["The context questions how many innocents will suffer in a major strike, implying the person is willing to risk innocent lives, but does not definitively state his intent or motivation.", "n", "validated"], ["The reference to \"the needs of the many outweigh the needs of the few\" suggests a rationale that could justify sacrificing innocents, but does not confirm whether he will or will not act on it.", "n", "validated"], ["The context does not specify the individual's moral boundaries or decision process regarding innocent casualties, leaving his actual choice unclear.", "n", "validated"], ["The context suggests that he is willing to proceed with a major strike despite the suffering of innocents, as it references the idea that the needs of the many outweigh the needs of the few.", "c", "validated"], ["The rhetorical question in the context implies that innocent people will suffer as a consequence of his major strike, contradicting the idea that he would refrain from striking because of them.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "73191n", "premise": "To get a wonderful view of the whole stretch of river, and to stretch your legs in a beautiful parklike setting, climb up to the Ceteau de Marqueyssac and its jardins suspendus (hanging gardens).", "hypothesis": "You will enjoy stretching your legs as you climb the Ceteau de Marqueyssac.", "generated_explanations": [["The context describes the location as a \"beautiful parklike setting,\" which is typically enjoyable for walking or stretching your legs.", "e", "validated"], ["The activity suggested involves climbing and walking through gardens, which can be pleasurable for people who like physical activity.", "e", "validated"], ["The presence of jardins suspendus (hanging gardens) implies attractive scenery, enhancing the enjoyment of the walk.", "e", "validated"], ["The context mentions stretching your legs as a physical activity but does not specify whether the person will enjoy it.", "n", "validated"], ["The statement introduces an affective component (\"enjoy\") that is not addressed in the context, which only describes the action and the setting.", "n", "validated"], ["Individual enjoyment is subjective and cannot be inferred solely from the description provided in the context.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 3}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "62273n", "premise": "The book is a parody of Bartlett's , serving up quotes from Lincoln, Jefferson, and Roger Rosenblatt with equal pomposity.", "hypothesis": "Bill Reilly's book has quotes from various presidents ranging from Lincoln to Jefferson.", "generated_explanations": [["The context mentions that the book includes quotes from Lincoln and Jefferson, who are both presidents.", "e", "validated"], ["The phrase \"ranging from Lincoln to Jefferson\" accurately reflects the inclusion of quotes from both Lincoln and Jefferson, suggesting a range of presidents as quoted in the book.", "e", "validated"], ["The context does not specify who authored the parody book; it does not mention Bill Reilly.", "n", "validated"], ["The context only mentions Lincoln and Jefferson as examples but does not state that quotes from a range of presidents are included.", "n", "validated"], ["The context does not confirm that the book contains quotes specifically from various presidents; it mentions Lincoln and Jefferson but also references Roger Rosenblatt, who is not a president.", "n", "validated"], ["The context does not mention Bill Reilly as the author of the book.", "c", "validated"], ["There is no indication in the context that the book is authored by Bill Reilly or associated with him in any way.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "58016c", "premise": "(As the old saying goes, If you can't figure out who the fool is at the poker table, it's probably you.", "hypothesis": "Dealers say everyone is smart that is playing.", "generated_explanations": [["The context does not include any information about the opinions or statements of dealers.", "n", "validated"], ["The context presents an old saying, not an assertion about dealer perceptions or statements.", "n", "validated"], ["The context implies that not everyone at the table is smart, as it suggests there is at least one \"fool,\" contradicting the statement that everyone playing is smart.", "c", "validated"], ["The statement attributes the opinion to dealers, but the context does not mention or reference dealer opinions or statements.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "45605n", "premise": "They have prominent red protuberances and may have been named after the British redcoats.", "hypothesis": "They were named after the redcoats because they are the same bright red color on their bodies.", "generated_explanations": [["The context states that they have prominent red protuberances, which aligns with the statement that their bodies are a bright red color.", "e", "validated"], ["The context mentions that they may have been named after British redcoats, implying a connection between their appearance and the redcoats' bright red uniforms.", "e", "validated"], ["The context states they \"may have been named after the British redcoats\" but does not confirm this as the definitive reason.", "n", "validated"], ["The context does not specify that the naming was explicitly due to \"the same bright red color on their bodies,\" only referencing \"prominent red protuberances.\"", "n", "validated"], ["The degree of color similarity between them and redcoats is not established in the context.", "n", "validated"], ["The context only states they \"may have been named after the British redcoats,\" indicating uncertainty, not that this is the definite reason.", "c", "validated"], ["The context mentions \"prominent red protuberances\" but does not confirm that their overall body color is the same bright red as the redcoats.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "82174e", "premise": "NEH-supported exhibitions were distinguished by their elaborate wall panels--educational maps, photomurals, stenciled treatises--which competed with the objects themselves for space and attention.", "hypothesis": "The exhibitions seem well-funded due to the elaborate detail of the gallery.", "generated_explanations": [["The use of elaborate wall panels, including educational maps, photomurals, and stenciled treatises, suggests significant resources were allocated for exhibition design.", "e", "validated"], ["The level of detail and the variety of display elements indicate the exhibitions were supported with sufficient funds to allow for such enhancements.", "e", "validated"], ["NEH support implies external financial backing, making elaborate features in the gallery feasible.", "e", "validated"], ["The presence of elaborate wall panels does not necessarily indicate a high level of funding, as elaborate details could result from creative use of limited resources or volunteer efforts.", "n", "validated"], ["No explicit information is provided about the exhibitions’ actual budgets or sources of funding.", "n", "validated"], ["The \"elaborate detail\" could describe design priorities or curatorial choices rather than being a reflection of funding levels.", "n", "validated"], ["The statement assumes a direct correlation between elaborate detail and financial support, which is not established in the context.", "n", "validated"], ["The context attributes the elaborate details to NEH support, not necessarily to overall exhibition funding, so the apparent elaborateness could result from targeted grants rather than general wealth.", "c", "validated"], ["Elaborate wall panels and details may reflect prioritization of educational materials over funding level; sophisticated design elements do not always indicate ample funding.", "c", "validated"], ["The focus on elaborate wall panels that compete for space might suggest an emphasis on presentation rather than resource abundance, so the detail does not inherently imply well-funded exhibitions.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 4, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "123703e", "premise": "Specifically, by defining mission improvement objectives, senior executives determine whether their organization needs a CIO who is a networking/marketing specialist, business change agent, operations specialist, policy/oversight manager, or any combination thereof.", "hypothesis": "A CIO must be an operations specialist.", "generated_explanations": [["The context lists multiple possible types of CIOs and suggests that the required type depends on the organization's objectives, implying that being an operations specialist is only one of several possibilities, not a necessity in all cases.", "n", "validated"], ["The context allows for any combination of roles, so a CIO might fulfill other roles or combinations that do not include operations specialist.", "n", "validated"], ["The context states that a CIO can be a networking/marketing specialist, business change agent, operations specialist, policy/oversight manager, or any combination, indicating that being an operations specialist is not a requirement but one of several possible roles.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "127410n", "premise": "In this case, shareholders can pay twice for the sins of others.", "hypothesis": "shareholders can pay once for the sins of others.", "generated_explanations": [["If shareholders can pay twice for the sins of others, it logically follows that they can pay at least once for the sins of others, as paying twice includes the possibility of paying once.", "e", "validated"], ["The context specifies \"pay twice,\" but does not state whether paying once is possible, impossible, or also occurs.", "n", "validated"], ["It is unclear if \"paying twice\" necessarily excludes the possibility of \"paying once\" occurring in other situations.", "n", "validated"], ["The context does not indicate if \"paying once\" might happen in different cases or under different circumstances.", "n", "validated"], ["The context specifies that shareholders can pay twice, not just once, for the sins of others.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "55572n", "premise": "But they also don't seem to mind when the tranquillity of a Zen temple rock garden is shattered by recorded announcements blaring from loudspeakers parroting the information already contained in the leaflets provided at the ticket office; when heavy-metal pop music loudly emanates from the radio of the middle-aged owner of a corner grocery store; and when parks, gardens, and hallowed temples are ringed by garish souvenir shops whose shelves display both the tastefully understated and the hideously kitsch.", "hypothesis": "A Zen temple rock garden is a a place for lots of people to gather and celebrate.", "generated_explanations": [["The context does not specify the intended or actual use of the Zen temple rock garden as a gathering or celebration space.", "n", "validated"], ["The context focuses on disturbances to tranquillity, not on whether large gatherings or celebrations occur there.", "n", "validated"], ["There is no information about the number of people typically present in the rock garden.", "n", "validated"], ["There is no mention of celebratory events or social gatherings taking place in the rock garden.", "n", "validated"], ["The context describes the tranquillity of a Zen temple rock garden, implying it is intended as a peaceful and quiet place, not a venue for gatherings and celebrations.", "c", "validated"], ["There is no mention of celebration or large gatherings; the context instead highlights disturbances to the garden's intended quiet atmosphere.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "45774c", "premise": "According to a 1995 Financial Executives Research Foundation report,5 transaction processing and other routine accounting activities, such as accounts payable, payroll, and external reporting, consume about 69 percent of costs within finance.", "hypothesis": "The financial world would be ok it there wasn't any 5 percent processing.", "generated_explanations": [["The context does not specify what \"5 percent processing\" refers to, so it is unclear how its absence would impact the financial world.", "n", "validated"], ["There is no information in the context about whether \"5 percent processing\" is critical or expendable within finance.", "n", "validated"], ["The context only discusses the proportion of costs consumed by certain activities but does not address the necessity or consequences of removing any portion of those activities.", "n", "validated"], ["The context discusses 69 percent of costs being consumed by transaction processing and routine accounting activities, not 5 percent, so the statement incorrectly references \"5 percent processing,\" which does not relate to the information provided.", "c", "validated"], ["The statement is unclear and unfounded as it suggests the financial world would be fine without \"5 percent processing\" when the context specifies the bulk of costs (69 percent) is dedicated to transaction processing, implying its critical importance rather than dispensability.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "130869n", "premise": "Castlerigg near Keswick is the best example.", "hypothesis": "A good example would be Castlerigg near Keswick, in Scotland.", "generated_explanations": [["Castlerigg near Keswick is described as the best example in the context, so it qualifies as a good example.", "e", "validated"], ["The statement aligns with the context in identifying Castlerigg near Keswick as an example, supporting its truthfulness.", "e", "validated"], ["The context confirms Castlerigg near Keswick as the best example but does not explicitly state it is located in Scotland.", "n", "validated"], ["The context does not specify the geographical location of Keswick, so the statement's identification of it as being in Scotland cannot be confirmed.", "n", "validated"], ["Castlerigg near Keswick is located in England, not Scotland.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "93955n", "premise": "The large scale production of entertainment films is a phenomenon well worth seeing several times.", "hypothesis": "The production of entertainment films is elaborate and large scaled.", "generated_explanations": [["The context describes the production of entertainment films as a \"large scale\" phenomenon, which directly supports the claim that the production is \"large scaled.\"", "e", "validated"], ["The context suggests that this phenomenon is \"well worth seeing several times,\" implying that the production involves elaborate processes or impressive features that merit repeated viewing, supporting the idea that it is \"elaborate.\"", "e", "not_validated"], ["The context only states that large scale production is worth seeing, but does not specify whether all entertainment films are produced on a large and elaborate scale.", "n", "validated"], ["The statement introduces the idea of \"elaborate\" production, which is not mentioned or implied in the context.", "n", "validated"], ["The context refers specifically to \"large scale production,\" not to all production of entertainment films, so it is unclear if this applies universally.", "n", "validated"], ["The context only states that large scale production of entertainment films exists and is noteworthy, but it does not claim that all entertainment film production is elaborate or large scale.", "c", "validated"], ["The context does not describe the production process as \"elaborate;\" it only comments on the scale and the experience of seeing such productions.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "72870c", "premise": "Because marginal costs are very low, a newspaper price for preprints might be as low as 5 or 6 cents per piece.", "hypothesis": "Newspaper preprints can cost as much as $5.", "generated_explanations": [["The context only discusses preprint prices being as low as 5 or 6 cents, but does not specify an upper limit, so higher prices are not ruled out.", "n", "validated"], ["The statement refers to \"can cost as much as $5,\" which could imply rare or exceptional cases not addressed by the context.", "n", "validated"], ["The context states that the price for newspaper preprints might be as low as 5 or 6 cents per piece due to very low marginal costs, making a $5 price far higher than what is indicated.", "c", "validated"], ["There is no indication in the context that preprint prices could reach $5; the amounts mentioned are in cents, not dollars.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "77025c", "premise": "You are sure that you did not in any way disclose your identity?\" Tommy shook his head.", "hypothesis": "I wish you hadn't revealed your identity, that was a mistake.", "generated_explanations": [["The context indicates that Tommy did not disclose his identity, but the statement assumes or expresses regret that he did, leaving it unclear whether the regret is based on fact or misunderstanding.", "n", "validated"], ["The statement could be expressing a hypothetical or a mistaken belief rather than referencing an actual event, and the context does not clarify which is the case.", "n", "validated"], ["The context asserts that Tommy did not disclose his identity, while the statement assumes that he did.", "c", "validated"], ["The statement accuses Tommy of revealing his identity, which contradicts Tommy shaking his head to confirm he did not.", "c", "validated"], ["The statement treats identity disclosure as a past event, but the context denies any such event occurred.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "69975n", "premise": "I'm not interested in tactics, Al.", "hypothesis": "Al is very interested in tactics.", "generated_explanations": [["The context only specifies the speaker's lack of interest and does not mention Al's feelings or opinions about tactics.", "n", "validated"], ["There is no information provided about Al's interests at all.", "n", "validated"], ["The context only indicates the speaker's own lack of interest in tactics and does not provide any information about Al's interest, so there is no basis for claiming Al is very interested in tactics.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "125238c", "premise": "If the collecting entity transfers the nonexchange revenue to the General Fund or another entity, the amount is accounted for as a custodial activity by the collecting entity.", "hypothesis": "Nonexchange revenue to the General Mills.", "generated_explanations": [["The context refers to government accounting practices, but the statement mentions \"General Mills,\" which is a private company, making it unclear if the context applies.", "n", "validated"], ["It is not specified whether General Mills is the collecting entity or the recipient of the nonexchange revenue, leading to ambiguity.", "n", "validated"], ["The source and nature of the \"nonexchange revenue\" in relation to General Mills are not described, so the relationship is undetermined.", "n", "validated"], ["The context discusses a \"General Fund\" in a government accounting context, not \"General Mills,\" which is a private company; thus, nonexchange revenue is not related to General Mills.", "c", "validated"], ["General Mills, as a for-profit corporation, does not have nonexchange revenues in the governmental accounting sense referenced in the context.", "c", "validated"], ["The context involves governmental entities and their funds, not private sector businesses like General Mills.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "27022c", "premise": "For fiscal year 1996, Congress determined that the Commission should recover $126,400,000 in costs, an amount 8.6 percent higher than required in fiscal year 1995.", "hypothesis": "Congress determined that Commission should recover over $126 in costs.", "generated_explanations": [["The amount Congress determined for the Commission to recover in costs for fiscal year 1996 is $126,400,000, which is over $126.", "e", "validated"], ["The statement refers to \"$126\" without specifying the units or scale, making it unclear whether it means $126, $126 thousand, $126 million, etc., so it cannot be definitively determined if it matches \"$126,400,000\".", "n", "validated"], ["The context states exactly \"$126,400,000\", so whether \"over $126\" includes or excludes this specific amount is ambiguous due to the lack of specificity in the statement.", "n", "not_validated"], ["The statement says \"over $126,\" which is an extremely small amount and does not accurately reflect the actual amount of $126,400,000 determined by Congress.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 1, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "66689c", "premise": "OMB issued the guidance in Memorandum M0010, dated April 25, 2000.", "hypothesis": "Memorandum M0010 was issued by INS.", "generated_explanations": [["The context specifies that OMB issued Memorandum M0010, but does not mention whether INS is involved in its issuance, so it is unknown if INS also issued the memorandum.", "n", "validated"], ["The statement claims INS issued the memorandum, but the context only references OMB, leaving the possibility of dual authorship or misattribution undetermined.", "n", "validated"], ["The context states that OMB issued the guidance, not INS.", "c", "validated"], ["OMB and INS are separate organizations; attribution to INS is incorrect based on the context.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "112547n", "premise": "Credibility is a vital factor, and Jim Lehrer does, indeed, have it.", "hypothesis": "Everyone would believe whatever Jim Lehrer said.", "generated_explanations": [["Having credibility does not guarantee that everyone would believe whatever a person says; there could be individuals who remain skeptical for various reasons.", "n", "validated"], ["The context only establishes that Jim Lehrer has credibility, not that he has perfect or universal credibility.", "n", "validated"], ["Other factors beyond credibility, such as prior beliefs, biases, or the content of specific statements, can influence whether someone chooses to believe Jim Lehrer.", "n", "validated"], ["The statement assumes unanimous belief, which is a much stronger claim than the context supports.", "n", "validated"], ["Having credibility does not guarantee that every person will believe everything Jim Lehrer says, as individuals may have personal biases, alternative information, or skepticism.", "c", "validated"], ["Some people may not know who Jim Lehrer is and therefore would not automatically believe his statements.", "c", "validated"], ["Credibility can be context-dependent; people might trust him in some topics but not in others.", "c", "validated"], ["Even credible individuals can make mistakes, leading some to doubt particular claims.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 4}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 4}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "129081n", "premise": "right oh they've really done uh good job of keeping everybody informed of what's going on sometimes i've wondered if it wasn't almost more than we needed to know", "hypothesis": "I think I have shared too much information with everyone, so next year I will share less.", "generated_explanations": [["The speaker expresses that the amount of information shared might have been excessive, implying a desire to reduce information sharing in the future.", "e", "not_validated"], ["The statement suggests the speaker is considering sharing less information next year based on their experience of possibly sharing too much this time.", "e", "not_validated"], ["The context discusses receiving information from others, not the speaker themselves sharing information.", "n", "validated"], ["There is no indication in the context that the speaker has control over how much information is shared with everyone.", "n", "validated"], ["The context expresses a reaction to being informed, not an intention or plan to change future behavior.", "n", "validated"], ["The context uses \"I've wondered\" to express uncertainty, not a definitive decision to alter information sharing next year.", "n", "validated"], ["The statement’s use of \"I think I have shared too much\" is not supported by any evidence in the context.", "n", "validated"], ["The context refers to \"they\" keeping everyone informed, not the speaker sharing information.", "c", "validated"], ["The context expresses wondering about receiving too much information, not about personally sharing it.", "c", "validated"], ["The context does not mention any plans or intentions for next year.", "c", "validated"], ["The context does not indicate the speaker regrets their own actions—only remarks on information received.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 5, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 5, "c": 4}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "45306n", "premise": "Each caters to a specific crowd, so hunt around until you find the one right for you.", "hypothesis": "There are marketers who have argued that there needs to be more effort to broaden appeal.", "generated_explanations": [["The context suggests that current establishments focus on niche audiences rather than broad appeal, implying that there is room for broader marketing efforts.", "e", "not_validated"], ["The existence of targeted venues implies that not all businesses aim for or achieve broad appeal, which could motivate marketers to advocate for strategies that attract a wider customer base.", "e", "validated"], ["The phrase \"hunt around until you find the one right for you\" indicates that options are specialized rather than universally appealing, supporting the notion that some believe greater effort should be directed toward inclusivity or mass appeal.", "e", "not_validated"], ["The context mentions that each caters to a specific crowd but does not provide any information about marketers or their arguments.", "n", "validated"], ["The context does not indicate whether there is a discussion or debate about broadening appeal.", "n", "validated"], ["The context does not mention or imply anything about marketers or their arguments regarding broadening appeal.", "c", "validated"], ["The context suggests satisfaction with serving specific crowds rather than advocating for broader appeal.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 2}}
{"id": "76957c", "premise": "Both initial and supplemental proposed rule publications invited comments on the information collection requirements imposed by the rule.", "hypothesis": "There's no point in following politics or voting because your vote won't actually make a difference.", "generated_explanations": [["The context discusses rule publication and public comments, while the statement is about political participation and voting, resulting in no direct informational connection between the two.", "n", "validated"], ["The context references procedural aspects of rulemaking, not the efficacy of individual votes or political engagement, so it does not provide evidence for or against the statement.", "n", "validated"], ["The context describes the process of inviting public comments on proposed rules, demonstrating that individual participation (such as providing comments or voting) is recognized and can influence outcomes in rulemaking, contradicting the statement that individual actions do not make a difference.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "2262n", "premise": "She buried his remains to spare her mother the gruesome sight.", "hypothesis": "The remains would have caused grief to her mother.", "generated_explanations": [["She buried the remains specifically to spare her mother, implying that seeing them would have been emotionally distressing.", "e", "validated"], ["The term \"gruesome sight\" suggests that the remains were disturbing, which would likely elicit grief in her mother.", "e", "validated"], ["The context only indicates that the remains would have been a \"gruesome sight,\" but does not specify whether this would cause grief, fear, disgust, or another emotional response in her mother.", "n", "validated"], ["The connection between seeing something gruesome and experiencing grief is not explicitly made in the context; the mother could already be grieving or have a different reaction altogether.", "n", "validated"], ["The context does not clarify the nature of the relationship between the remains and the mother, so her emotional response to seeing them cannot be certain.", "n", "validated"], ["The context indicates the motivation was to spare her mother from a gruesome sight, not necessarily from grief.", "c", "not_validated"], ["The remains might have been shocking or visually disturbing without directly causing emotional grief.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "40710n", "premise": "Write, write, and write.", "hypothesis": "You should keep practicing writing.", "generated_explanations": [["The context emphasizes the repeated act of writing, suggesting the importance of continual practice.", "e", "validated"], ["The repetition in the context implies that improvement in writing comes from persistent effort.", "e", "validated"], ["The context serves as an encouragement to engage in the activity of writing consistently.", "e", "validated"], ["The context emphasizes the action of writing but does not explicitly state whether it recommends persistence or practice.", "n", "validated"], ["The context does not specify if the repeated writing is meant as advice or simply a description of an activity.", "n", "validated"], ["The intent behind the phrase \"Write, write, and write\"—whether motivational, instructional, or descriptive—is unclear.", "n", "validated"], ["The context already implies continuous practice of writing, making the advice redundant rather than introducing a new or false idea.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 1}}
{"id": "21957n", "premise": "But those that are manufactured for sale in in Europe and so forth are quite the other way around", "hypothesis": "Products are made with differently designed machines in Europe.", "generated_explanations": [["The phrase \"quite the other way around\" implies that the manufacturing process for products in Europe is different from elsewhere, suggesting a difference in design or method, which could include the machines used.", "e", "not_validated"], ["The context distinguishes products \"manufactured for sale in Europe,\" implying adaptation or change in production, which may involve differently designed machines suitable for European standards or preferences.", "e", "not_validated"], ["The context states that products made for sale in Europe are \"quite the other way around\" compared to something not specified, but it does not mention machine design or differences in manufacturing equipment.", "n", "validated"], ["The context does not clarify whether the difference pertains to design, process, materials, standards, or machines, leaving the specific reason for the difference in products undetermined.", "n", "validated"], ["The context only specifies a difference in the characteristics of products made for sale in Europe, not that they are made with different machines.", "c", "validated"], ["There is no mention in the context of the design or type of machines used in Europe.", "c", "validated"], ["The context contrasts the products themselves, not the manufacturing equipment or methods.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "14126e", "premise": "and so i have really enjoyed that but but there are i do have friends that watch programs like they want to see a particular program and they are either home watching it or definitely recording it they have some programs that they won't miss", "hypothesis": "What programs do your friends like to watch?", "generated_explanations": [["The context mentions that the speaker has friends who watch specific programs that they don't want to miss, implying that the friends have particular programs they like to watch.", "e", "validated"], ["The statement seeks to know which programs these friends prefer, which is directly related to the context where it is stated that the friends have favorite or unmissable programs.", "e", "validated"], ["The context mentions that the friends have programs they won't miss, but does not specify the names or types of programs they like to watch.", "n", "validated"], ["The context only indicates the friends' viewing habits, not the content or genre of the programs they watch.", "n", "validated"], ["The context does not specify which programs the friends like to watch.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "79013n", "premise": "But it just might be because he's afraid he'll lose his No.", "hypothesis": "He's definitely afraid of losing he's No.", "generated_explanations": [["The context suggests as a possibility that he is afraid he will lose his No., which means it is possible or implied that he is indeed afraid of losing his No.", "e", "not_validated"], ["The statement is a direct assertion of the possibility raised in the context, so if the context's speculation is accurate, the statement would be true.", "e", "not_validated"], ["The context says \"it just might be\" indicating possibility, not certainty, while the statement asserts definite fear.", "n", "validated"], ["The context expresses speculation about his feelings, but does not confirm them.", "n", "validated"], ["The context uses the phrase \"it just might be,\" which expresses uncertainty, while the statement claims it as a definite fact.", "c", "validated"], ["The context suggests the possibility among other explanations, not a certainty, so the statement overstates what is implied.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "38156n", "premise": "BUDGETARY RESOURCES - The forms of authority given to an agency allowing it to incur obligations.", "hypothesis": "Administrations generally feel that some agencies should have more budgetary resources than others.", "generated_explanations": [["Different agencies have varying responsibilities and priorities, leading administrations to allocate more budgetary resources to those deemed more important.", "e", "not_validated"], ["Administrations make funding decisions based on perceived effectiveness or impact, resulting in some agencies receiving more budgetary resources than others.", "e", "not_validated"], ["National strategies or political agendas influence administrations to favor certain agencies, granting them greater budgetary resources.", "e", "not_validated"], ["Changes in external circumstances, such as emergencies or policy shifts, can lead administrations to believe that specific agencies require increased budgetary resources.", "e", "not_validated"], ["The context defines \"budgetary resources\" but does not mention administrative opinions or preferences regarding their distribution among agencies.", "n", "validated"], ["There is no information about comparative levels of budgetary resources between agencies in the context.", "n", "validated"], ["The context does not reference the views or attitudes of administrations or any specific actors.", "n", "validated"], ["The context defines \"budgetary resources\" but does not mention or imply anything about administrations’ opinions or preferences regarding resource allocation among agencies.", "c", "validated"], ["There is no information provided about comparative levels of budgetary resources between agencies or any administrative stance on such differences.", "c", "validated"]], "label_count_round_1": {"e": 4, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 4}}
{"id": "25304n", "premise": "well we bought this with credit too  well we found it with a clearance uh down in Memphis i guess and uh", "hypothesis": "We bought non-sale items in Memphis on credit.", "generated_explanations": [["The context indicates that the item was bought on clearance, which suggests it was on sale, not a non-sale item.", "n", "validated"], ["The context does not specify whether any non-sale items were purchased in Memphis; it only mentions buying \"this\" particular item on clearance.", "n", "validated"], ["The item was found on clearance, indicating it was a sale item, not a non-sale item.", "c", "validated"], ["The context does not specify that multiple items were bought; it refers to a single item.", "c", "not_validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "111338e", "premise": "He threw one of them and shot the other.", "hypothesis": "He shot his gun.", "generated_explanations": [["The verb \"shot\" typically implies the use of a gun as the means of shooting.", "e", "validated"], ["The common interpretation of \"shot\" in most contexts refers to firing a gun unless specified otherwise.", "e", "validated"], ["The context does not specify what object or weapon was used to shoot; \"shot\" could refer to something other than a gun (e.g., shooting a camera, slingshot, bow, etc.).", "n", "validated"], ["It is unclear whether \"shot\" refers to shooting an object, person, or animal, which may not involve a gun.", "n", "validated"], ["The verb \"shot\" can have multiple meanings and the context does not clarify which meaning applies.", "n", "validated"], ["\"Shot\" could refer to using something other than a gun, such as a camera or a slingshot.", "c", "not_validated"], ["The context does not specify that \"shot\" was done with a gun; it could involve any object capable of shooting.", "c", "validated"], ["There is no mention of him possessing a gun in the context.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 2}}
{"id": "75259c", "premise": "Buffet and a  la carte available.", "hypothesis": "It has table service.", "generated_explanations": [["\"A la carte\" service typically involves ordering individual items from a menu, which usually requires table service.", "e", "validated"], ["The context states \"buffet and a la carte available\" but does not specify the style of service for either; buffets typically do not involve table service, while a la carte may or may not.", "n", "validated"], ["Some restaurants offer both buffet (self-service) and a la carte (possible table service), but the context does not clarify whether table service is provided with one, both, or neither option.", "n", "validated"], ["The statement implies table service, but the context only mentions buffet and a la carte options, neither of which necessarily require table service (buffets typically do not involve it).", "c", "validated"], ["The context does not specify that servers bring food to the table, which is essential for table service.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "53211n", "premise": "No, I exclaimed, astonished.", "hypothesis": "I said no to him several time, utterly surprised by the change of events.", "generated_explanations": [["The speaker exclaimed \"No,\" indicating they expressed refusal.", "e", "validated"], ["The speaker was astonished, which aligns with being utterly surprised by the change of events.", "e", "not_validated"], ["The context only shows a single instance of exclaiming \"No,\" not multiple refusals.", "n", "validated"], ["The context does not specify \"him\" as the recipient of the statement.", "n", "validated"], ["The context mentions astonishment but does not explicitly refer to surprise at \"the change of events.\"", "n", "validated"], ["The context only indicates a single exclamation of \"No\" and does not mention saying \"no\" multiple times.", "c", "validated"], ["The context expresses astonishment but does not refer to being surprised specifically by a \"change of events.\"", "c", "validated"], ["The statement mentions \"him,\" but the context does not specify to whom \"no\" is being exclaimed.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1, "c": 1}}
{"id": "123267e", "premise": "He's a bad lot.", "hypothesis": "He's a dishonest person", "generated_explanations": [["The phrase \"a bad lot\" is commonly used to describe someone with a poor moral character, which includes being dishonest.", "e", "validated"], ["Being \"a bad lot\" implies engaging in unethical or untrustworthy behavior, of which dishonesty is a key example.", "e", "validated"], ["The phrase \"a bad lot\" might refer to negative qualities that are not limited to dishonesty, such as being lazy, rude, or irresponsible, so it does not necessarily entail dishonesty.", "n", "validated"], ["The context does not provide specific examples or evidence of dishonesty, leaving it unclear whether dishonesty is among his negative traits.", "n", "validated"], ["Being \"a bad lot\" can refer to poor character or bad behavior generally, which might include rudeness, irresponsibility, or unreliability, but does not specifically imply dishonesty.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "80808n", "premise": "A button on the Chatterbox page will make this easy, so please do join in.", "hypothesis": "They wanted to make the site very user friendly.", "generated_explanations": [["Providing a button to make participation easy suggests an intention to simplify the user experience.", "e", "validated"], ["Encouraging users to join in easily reflects a desire to make the site accessible and welcoming.", "e", "validated"], ["The context mentions a button that will make something easy, but does not specify the overall intention behind the site design.", "n", "validated"], ["There is no direct reference to the creators' motivations or goals for user friendliness in the context.", "n", "validated"], ["The presence of a single easy-to-use button does not imply that the entire site is intended to be user friendly.", "n", "validated"], ["The context only mentions that a button will make joining easy, not that there was an intention to make the entire site user friendly.", "c", "validated"], ["No evidence in the context that there was a broader goal of user friendliness beyond the specific action of joining via the Chatterbox page.", "c", "validated"], ["The context does not mention the motivations, desires, or intentions of the creators or maintainers of the site.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "72740c", "premise": "So it wasn't Missenhardt's singing--marvelous though that was--that made Osmin's rantings so thrilling.", "hypothesis": "Osmin was always calm and collected.", "generated_explanations": [["The context mentions Osmin's \"rantings,\" which suggests he was not always calm and collected, but it does not directly state his general temperament outside of this instance.", "n", "validated"], ["The statement refers to Osmin’s overall demeanor (\"always\"), but the context only provides information about a specific situation.", "n", "validated"], ["Osmin is described as having \"rantings,\" indicating he was not calm and collected.", "c", "validated"], ["The context suggests that Osmin's behavior was thrilling due to his rantings, which contradicts calmness and collectedness.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "71251n", "premise": "Deborah Pryce said Ohio Legal Services in Columbus will receive a $200,000 federal grant toward an online legal self-help center.", "hypothesis": "A $200,000 federal grant will be received by Ohio Legal Services, said Deborah Pryce, who could finally say it to the public.", "generated_explanations": [["Deborah Pryce publicly announced that Ohio Legal Services will receive a $200,000 federal grant.", "e", "validated"], ["The grant amount and recipient mentioned in the statement matches the information given in the context.", "e", "validated"], ["The information source in both the context and statement is Deborah Pryce.", "e", "not_validated"], ["The context does not specify whether Deborah Pryce was previously unable to announce the grant publicly, so it is undetermined if she could \"finally\" say it to the public.", "n", "validated"], ["The context indicates the grant will be received, but does not explicitly state the announcement's timing or Deborah Pryce's prior restrictions regarding making the information public.", "n", "validated"], ["The context does not mention that Deborah Pryce had previously been unable to share the information with the public or that she was \"finally\" able to say it.", "c", "validated"], ["The statement attributes an emotional or temporal milestone (“finally say it to the public”) to Deborah Pryce that is not supported by the context.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "117680c", "premise": "Since the rules were issued as interim rules and not as general notices of proposed rulemaking, they are not subject to the Unfunded Mandates Reform Act of 1995.", "hypothesis": "The rules were  not issued as interim rules but rather general notices of proposed rulemaking.", "generated_explanations": [["The context does not specify what the rules could have been; it only states what they were, leaving open the possibility that they might have been issued as something else.", "n", "validated"], ["The context assumes but does not prove the exclusive nature of rule types, so it's undetermined if the rules might fall under both categories or if the definitions overlap.", "n", "validated"], ["The context explicitly states that the rules were issued as interim rules, not as general notices of proposed rulemaking.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "80930n", "premise": "so you um-hum so you think it comes down to education or or something like that", "hypothesis": "IT all boils down to how much education you have.", "generated_explanations": [["The context suggests that the underlying factor being discussed is education, aligning with the statement that everything depends on the amount of education a person has.", "e", "validated"], ["The speaker in the context explicitly considers education as the core issue, which supports the statement’s claim that education is the fundamental determinant.", "e", "validated"], ["The context suggests uncertainty or multiple possible factors (\"education or or something like that\"), while the statement asserts education as the sole decisive factor, so it is unclear whether the speaker agrees education is exclusively what matters.", "n", "validated"], ["The context does not specify if \"you think\" reflects the speaker’s own belief or is merely a prompt for further discussion, so the connection to the statement is ambiguous.", "n", "validated"], ["The context includes uncertainty (\"or something like that\"), suggesting that factors other than education may be involved, so the statement's claim that everything boils down to education is too absolute.", "c", "validated"], ["The context shows the speaker is speculating or unsure, while the statement asserts education as the sole determining factor, which overstates the certainty present in the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "98844n", "premise": "The m??tro (subway) is the fastest way to move around the city, but the buses, both in the capital and the other big towns, are best for taking in the sights.", "hypothesis": "Taking the subway is a good way to experience big city life.", "generated_explanations": [["The subway is described as the fastest way to move around the city, which is a characteristic feature of big city life, where efficiency and speed are valued.", "e", "validated"], ["Using the subway is a typical part of the daily routine for many residents in large cities, making it representative of big city life.", "e", "validated"], ["The context discusses the subway's speed and the buses being better for sightseeing but does not address whether taking the subway provides an experience of big city life.", "n", "validated"], ["The concept of \"experiencing big city life\" is subjective and not defined in the context, so it is unclear if speed or sightseeing is more relevant to such an experience.", "n", "validated"], ["There is no information in the context about the qualitative aspects of subway travel (such as ambiance, crowd interactions, etc.) that might constitute \"experiencing big city life.\"", "n", "validated"], ["The context suggests the subway is valued for speed, not for experiencing city life or sights.", "c", "validated"], ["Buses are described as best for taking in the sights, implying the subway is not suited for that purpose.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "127073c", "premise": "maybe adult literacy maybe you know composition writing maybe you know uh volunteering you know on a tutor line or though the even through the elementary schools for help with homework or the other part of me says is God i've had enough kids  do i really", "hypothesis": "maybe I could volunteer to help coach sports since I've helped all my children be successful in sports", "generated_explanations": [["The context mentions volunteering in various forms, which aligns with the idea of volunteering to coach sports.", "e", "validated"], ["The speaker notes having had enough experience with kids, implying experience that could be useful in a coaching role.", "e", "not_validated"], ["The statement about helping their own children be successful in sports suggests relevant practical experience for coaching.", "e", "not_validated"], ["The context mentions volunteering for literacy, composition writing, tutoring, or homework help, but does not mention coaching sports, so it is unclear if coaching sports is a relevant or considered option.", "n", "validated"], ["The speaker expresses reluctance about working with more children, which may contradict the idea of volunteering to coach sports, but does not definitively rule it out.", "n", "validated"], ["The statement references past experience helping children succeed in sports, but the context does not provide information on the speaker’s sports background or willingness to use it for volunteering.", "n", "validated"], ["The context discusses volunteering related to adult literacy, composition writing, tutoring, and helping with homework, not coaching sports.", "c", "validated"], ["There is mention of being tired of working with kids, which suggests reluctance rather than willingness to volunteer in a new capacity like coaching sports.", "c", "validated"], ["There is no indication in the context that the speaker has experience helping their children be successful in sports.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 2}}
{"id": "61216c", "premise": "By seeding packs with a few high-value cards, the manufacturer is encouraging kids to buy Pokemon cards like lottery tickets.", "hypothesis": "Each Pokemon card pack is filled with every rare card a kid could want.", "generated_explanations": [["The context mentions only that packs are seeded with a few high-value cards, not that every pack contains all rare cards a kid could want.", "n", "validated"], ["\"Every rare card a kid could want\" is a subjective and undefined set, and the context does not specify the contents beyond a few high-value cards.", "n", "validated"], ["The context suggests rarity and an incentive structure similar to a lottery, implying not all packs contain rare cards, but does not clarify the exact contents of each pack.", "n", "validated"], ["Packs are only seeded with a few high-value cards, not every rare card.", "c", "validated"], ["Not every pack contains rare cards; the inclusion is limited and random.", "c", "validated"], ["It is unlikely that any single pack contains all the rare cards kids might want.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "102857n", "premise": "Expenses included in calculating net cost for education and training programs that are intended to increase or maintain national economic productive capacity shall be reported as investments in human capital as required supplementary stewardship information accompanying the financial statements of the Federal Government and its component units.", "hypothesis": "Net cost for college programs can be calculated as a way to increase productivity.", "generated_explanations": [["Calculating the net cost for education and training programs (such as college programs) is necessary to assess investments aimed at increasing national economic productive capacity (productivity).", "e", "validated"], ["The context specifies that expenses for education and training programs are reported as investments in human capital if they aim to increase or maintain national economic productive capacity, but it does not clarify whether the calculation of net cost itself serves as a way to increase productivity.", "n", "validated"], ["The context discusses reporting requirements and classification of expenses, not the methods or purposes of calculating net cost for programs like college programs.", "n", "validated"], ["It is unclear from the context whether \"calculating net cost\" is directly linked to increasing productivity, or if it is merely an accounting or reporting necessity.", "n", "validated"], ["Net cost for college programs is a financial calculation, not a method for increasing productivity; it is a measure of expenses minus revenues, not an intervention or strategy.", "c", "validated"], ["Calculating net cost itself does not increase productivity; it is used for reporting and assessment purposes, not as a means to affect economic output.", "c", "validated"], ["The context requires net cost for education and training programs to be reported as investments in human capital due to their intent to increase or maintain productivity, but the act of calculating net cost does not directly serve to increase productivity.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "133243e", "premise": "He watched the river flow.", "hypothesis": "The river roared by.", "generated_explanations": [["Rivers that flow can make a roaring sound, especially if the water is moving quickly or turbulently.", "e", "not_validated"], ["The act of watching a river flow could involve observing and hearing loud water movement, which can be described as \"roaring by.\"", "e", "not_validated"], ["The context only mentions the river flowing, without describing any sound, so it is unclear whether the river was loud enough to \"roar.\"", "n", "validated"], ["\"Flowed\" does not specify the speed or turbulence of the river, so it is not certain if the river's movement would produce a roaring sound.", "n", "validated"], ["The context does not mention any sound, so there is no evidence that the river was roaring.", "c", "validated"], ["\"Flow\" implies gentle movement, which contrasts with \"roared,\" a word suggesting loud, turbulent water.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "144408n", "premise": "Today it is possible to buy cheap papyrus printed with gaudy Egyptian scenes in almost every souvenir shop in the country, but some of the most authentic are sold at The Pharaonic Village in Cairo where the papyrus is grown, processed, and hand-painted on site.", "hypothesis": "The Pharaonic Village in Cairo is the only place where one can buy authentic papyrus.", "generated_explanations": [["The context states that authentic papyrus is sold at The Pharaonic Village in Cairo but does not claim that it is the only place where authentic papyrus can be bought.", "n", "validated"], ["The context mentions that cheap papyrus is available in almost every souvenir shop, suggesting the existence of other sources, but does not clarify if those are ever authentic.", "n", "validated"], ["The word \"some\" in \"some of the most authentic are sold at The Pharaonic Village\" implies that authentic papyrus might also be available elsewhere.", "n", "validated"], ["The context does not claim that The Pharaonic Village is the only place selling authentic papyrus, only that it is one place where some of the most authentic papyrus is sold.", "c", "validated"], ["The use of the phrase \"some of the most authentic\" implies that authentic papyrus can be found in other locations as well.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "104412e", "premise": "After being diagnosed with cancer, Carrey's Kaufman decides to do a show at Carnegie Hall.", "hypothesis": "Carrey's Kaufman was diagnosed with cancer before deciding to do a show at Carnegie Hall.", "generated_explanations": [["The context states that Kaufman decides to do a show at Carnegie Hall after being diagnosed with cancer, indicating the cancer diagnosis occurred first.", "e", "validated"], ["The statement matches the order of events presented in the context, with the cancer diagnosis preceding the decision to do a show at Carnegie Hall.", "e", "validated"], ["The context does not specify the exact timing of the diagnosis relative to the decision, only that the decision to do a show at Carnegie Hall follows the diagnosis, not necessarily as a result of or strictly after it.", "n", "validated"], ["The statement assumes a direct chronological order (diagnosis first, then decision), but the context could be consistent with simultaneous events or the events being closely related without a clear order.", "n", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 1}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "129601e", "premise": "Took forever.", "hypothesis": "Lasted too long", "generated_explanations": [["\"Took forever\" implies an event or situation continued for an excessively long period, which aligns with \"lasted too long.\"", "e", "validated"], ["Both phrases express the idea of something continuing beyond what is considered reasonable or expected.", "e", "validated"], ["\"Took forever\" is a subjective expression and may refer to something feeling like a long time, not necessarily meaning it objectively \"lasted too long.\"", "n", "validated"], ["Without information about an expected or appropriate duration, it's unclear whether it actually exceeded a relevant threshold to be considered \"too long.\"", "n", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 1}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "62238e", "premise": "Clearly, GAO needs assistance to meet its looming human capital challenges.", "hypothesis": "GAO will soon be suffering from a shortage of qualified personnel.", "generated_explanations": [["The mention of \"looming human capital challenges\" implies that GAO is facing upcoming difficulties related to its workforce.", "e", "validated"], ["The need for \"assistance\" suggests that GAO does not currently have enough qualified personnel to handle these challenges on its own.", "e", "validated"], ["The context mentions \"looming human capital challenges\" but does not specify that these challenges will result in a shortage of qualified personnel.", "n", "validated"], ["The need for assistance could stem from factors other than a shortage, such as skill gaps, succession planning, or increased workload.", "n", "validated"], ["The context does not clarify whether the challenge is related to quantity, quality, or management of personnel.", "n", "validated"], ["The timeframe for \"soon\" is unspecified and not addressed by the context.", "n", "validated"], ["The context states that GAO \"needs assistance to meet its looming human capital challenges,\" which implies the challenges are anticipated but does not confirm that a shortage of qualified personnel will definitely occur.", "c", "validated"], ["\"Human capital challenges\" could refer to issues other than a shortage, such as the need for new skills, succession planning, or adapting to organizational changes, not necessarily a shortage of qualified personnel specifically.", "c", "validated"], ["The phrase \"needs assistance\" suggests that action is being taken to prevent or address the challenges, so a shortage may be avoided entirely.", "c", "validated"], ["The context does not specify the nature, timing, or severity of the challenges—meaning a shortage is only one of several possible outcomes.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 4}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "51353e", "premise": "It is not a surprise, either, that Al Pacino chews the scenery in Devil's Advocate . And the idea that if the devil showed up on Earth he'd be running a New York corporate-law firm is also, to say the least, pre-chewed.", "hypothesis": "The fact that the devil would work in law is extremely cliche.", "generated_explanations": [["The context describes the idea of the devil running a corporate law firm as \"pre-chewed,\" which means it is overused or unoriginal.", "e", "validated"], ["Referring to something as \"pre-chewed\" implies that it is clichéd or a trope, supporting the statement that the devil working in law is extremely cliche.", "e", "validated"], ["The context describes the idea of the devil running a New York corporate-law firm as \"pre-chewed,\" which suggests familiarity or lack of originality but does not explicitly state it is \"extremely cliche.\"", "n", "validated"], ["The statement's use of \"extremely cliche\" intensifies the level of unoriginality, which may not be fully supported by the context's wording.", "n", "validated"], ["The context refers specifically to a corporate-law firm in New York, whereas the statement generalizes to the devil working in law broadly, possibly extending beyond the context.", "n", "validated"], ["The context implies that the idea of the devil running a corporate-law firm is \"pre-chewed,\" suggesting it is somewhat expected or unoriginal, but it does not directly state that it is \"extremely cliche,\" which is a much stronger assertion.", "c", "validated"], ["The context only comments specifically on the scenario of the devil heading a New York corporate-law firm, not on the broader statement that the devil working in law in general is extremely cliche.", "c", "validated"], ["The review uses phrases like \"to say the least, pre-chewed,\" which suggest unoriginality, but it does not necessarily equate this with being \"extremely cliche,\" as there is a difference in intensity and meaning between \"pre-chewed\" and \"extremely cliche.\"", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "108027n", "premise": "The door opened and Severn stepped out.", "hypothesis": "They were waiting for someone to open the door for them.", "generated_explanations": [["The context does not specify whether there was anyone besides Severn present, so it is unclear if \"they\" refers to any individuals who might have been waiting.", "n", "validated"], ["The context does not indicate whether Severn opened the door themselves or if someone else opened it for them.", "n", "validated"], ["The context does not mention anyone waiting or expecting the door to be opened.", "n", "validated"], ["The context does not indicate that Severn was waiting; it only states that Severn stepped out after the door opened.", "c", "validated"], ["The context does not specify whether someone else opened the door or if Severn opened it themselves.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "95883e", "premise": "Charles Geveden has introduced legislation that will increase the Access to Justice supplement on court filing fees.", "hypothesis": "Charles Geveden initiated a law that will essentially lower court filing fees.", "generated_explanations": [["The context only mentions an increase in the Access to Justice supplement on court filing fees, not a decrease.", "n", "validated"], ["It is unclear how increasing the supplement would translate to the overall court filing fees being lowered.", "n", "validated"], ["The context does not provide information about other potential changes to court filing fees that might offset the increase.", "n", "validated"], ["The legislation introduced by Charles Geveden will increase, not lower, the Access to Justice supplement on court filing fees.", "c", "validated"], ["Increasing the supplement will result in higher, not lower, overall court filing fees.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "26495e", "premise": "Standard screens may not perform as well in these patient subgroups that may represent a considerable part of the ED population.", "hypothesis": "The subgroups may not perform well in standard screens.", "generated_explanations": [["The context states that standard screens may not perform as well in these subgroups, which implies that the subgroups may not yield good results when subjected to standard screens.", "e", "validated"], ["The context states that standard screens may not perform as well in these subgroups, which refers to the performance of the tests, not the subgroups' ability or performance in the screens.", "n", "validated"], ["The phrasing of the statement implies the subgroups are being assessed, whereas the context describes the standard as being less effective, creating ambiguity about agency.", "n", "validated"], ["The context does not provide information on how the subgroups \"perform,\" only how the standard screens' performance is affected in those subgroups.", "n", "validated"], ["The statement implies that the subgroups themselves are performing, whereas the context states that the standard screens may not perform well when used with these subgroups; the subject of performance is reversed.", "c", "validated"], ["The context discusses the effectiveness of screens, not the capability or performance of the subgroups.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "67836n", "premise": "Who are these sons of eggs?", "hypothesis": "I wish they were daughters of eggs.", "generated_explanations": [["The speaker is responding to the identification of the group as \"sons of eggs\" by expressing a preference for them to be \"daughters of eggs\" instead.", "e", "not_validated"], ["The statement assumes the context's mention of \"sons of eggs\" is true, and builds on it by expressing a wish for an alternative (daughters instead of sons), implying acceptance of the \"eggs\" part.", "e", "not_validated"], ["The statement expresses a wish or preference rather than providing information about the reality of whether the \"sons of eggs\" are daughters instead, so the truth cannot be determined.", "n", "validated"], ["The context is a clarifying question about identity, while the statement introduces a hypothetical scenario unrelated to the factual answer to the question.", "n", "validated"], ["The statement expresses a wish or desire rather than a factual claim, so it cannot be evaluated as true or false based on the context provided.", "c", "validated"], ["The statement refers to \"daughters of eggs,\" but the context mentions \"sons of eggs,\" indicating a mismatch between what is stated and what is present in the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "21340n", "premise": "uh somewhat they're not my favorite team i am uh somewhat familiar with them", "hypothesis": "They are the best team in the league, by they are not my favorite.", "generated_explanations": [["The context does not provide any information about the team's standing or performance in the league.", "n", "validated"], ["The speaker only mentions familiarity and not favoritism, but does not address whether the team is the best.", "n", "validated"], ["The context does not express any opinion about the team's skill or ranking, only a lack of strong favoritism and some familiarity.", "c", "validated"], ["The context does not indicate that the team is the best in the league.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "114971e", "premise": "They won't be killing off George Clooney's character at ER like they did to Jimmy Smits at NYPD . Instead, Dr. Doug Ross is being forced out over the next two episodes because the maverick heartthrob gives an unauthorized painkiller to a terminally ill boy (Thursday, 10 p.m.).", "hypothesis": "George Clooney will not be getting fired from his TV show.", "generated_explanations": [["The context states that Dr. Doug Ross (George Clooney's character) is being forced out, but it does not explicitly say whether this means that George Clooney (the actor) is being fired from the TV show or if his character is simply being written off for other reasons.", "n", "validated"], ["Being \"forced out\" can refer to the character within the show's narrative rather than the actor's employment status; the actor might be leaving voluntarily or for plot reasons, not necessarily being fired.", "n", "validated"], ["The context discusses the fate of the character, not the terms of George Clooney's employment, so there is insufficient information to determine if Clooney is being fired.", "n", "validated"], ["The context states that Dr. Doug Ross (George Clooney's character) is being forced out, which implies he is being fired or removed from the show.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "103354n", "premise": "The Varanasi Hindu University has an Art Museum with a superb collection of 16th-century Mughal miniatures, considered superior to the national collection in Delhi.", "hypothesis": "The Varanasi Hindu University has an art museum on its campus which may be superior objectively to the national collection in Delhi.", "generated_explanations": [["The Art Museum at Varanasi Hindu University possesses a superb collection of 16th-century Mughal miniatures.", "e", "not_validated"], ["The museum's collection is considered superior to the national collection in Delhi.", "e", "validated"], ["The context states that the museum's collection is \"considered superior,\" which reflects an opinion or consensus rather than objective measurement.", "n", "validated"], ["There is no information in the context about objective criteria or evaluations used to compare the two collections.", "n", "validated"], ["The context does not explicitly confirm that the superiority is in all aspects or only specific to 16th-century Mughal miniatures.", "n", "validated"], ["The context does not specify whether the museum is located on the university's campus.", "n", "validated"], ["The context states that the collection is \"considered superior\" to the national collection in Delhi, which reflects an opinion or subjective assessment, while the statement claims the possibility of objective superiority, which is not supported by the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 4, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "11971n", "premise": "In a six-year study, scientists fed dogs and other animals irradiated chicken and found no evidence of increased cancer or other toxic effects.", "hypothesis": "Scientists gave animals irradiated chicken and they all lived as long as the rest of them.", "generated_explanations": [["The study found no evidence of increased toxic effects, which implies the animals' lifespans were not shortened.", "e", "not_validated"], ["No increased cancer or toxic effects suggests the irradiated chicken did not negatively impact the animals' health or longevity.", "e", "not_validated"], ["The context mentions no evidence of increased cancer or other toxic effects but does not provide information about the lifespan of the animals.", "n", "validated"], ["The statement asserts that all animals lived as long as the rest, but the context does not specify survival rates or longevity data.", "n", "validated"], ["The context reports no evidence of increased cancer or toxic effects, but it does not state that all animals lived as long as others, so lifespan data is not provided.", "c", "validated"], ["The context does not specify the survival rates or longevity of the animals, only the absence of certain health effects.", "c", "validated"], ["The statement generalizes that *all* animals lived as long, which is not supported or claimed in the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "83722e", "premise": "Whether a government postal service can engage in these kinds of negotiations deserves serious study.", "hypothesis": "There is serious study needed to check.", "generated_explanations": [["The context explicitly states that the issue \"deserves serious study\", indicating the need for serious study.", "e", "validated"], ["The phrase \"deserves serious study\" implies that serious study is required to determine whether a government postal service can engage in those negotiations.", "e", "validated"], ["The context mentions that the issue \"deserves serious study,\" but does not state that such study is actually needed or will occur.", "n", "validated"], ["The statement asserts that \"serious study is needed,\" but the context only raises the question of whether this is true, without confirming it.", "n", "validated"], ["The context suggests that the topic deserves serious study, implying it has not yet been undertaken, while the statement asserts that serious study is needed specifically \"to check,\" which changes the nuance from deserving study to an obligation or requirement for verification.", "c", "not_validated"], ["The statement generalizes the need for study, whereas the context focuses specifically on the question of a government postal service engaging in negotiations.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "38527n", "premise": "will never be doused (Brit Hume, Fox News Sunday ; Tony Blankley, Late Edition ; Robert Novak, Capital Gang ; Tucker Carlson, The McLaughlin Group ). The middle way is best expressed by Howard Kurtz (NBC's Meet the Press )--he scolds Brill for undisclosed campaign contributions and for overstretching his legal case against Kenneth Starr but applauds him for casting light on the media.", "hypothesis": "They wanted the public to know where the funds came from.", "generated_explanations": [["Howard Kurtz scolded Brill for undisclosed campaign contributions, implying an expectation that such contributions should be disclosed so the public knows their sources.", "e", "validated"], ["The context does not specify the intentions of Brit Hume, Tony Blankley, Robert Novak, Tucker Carlson, or Howard Kurtz regarding public knowledge of funding sources.", "n", "validated"], ["The context mentions undisclosed campaign contributions but does not indicate whether anyone wanted these to be disclosed to the public.", "n", "validated"], ["There is no direct reference in the context to any of the individuals expressing a desire for transparency about the origins of funds.", "n", "validated"], ["The context does not mention anyone expressing a desire for the public to know the source of funds.", "c", "validated"], ["The people referenced are being discussed for their media roles and opinions, not for advocating transparency about funding sources.", "c", "validated"], ["The discussion centers around media accountability and critique, not financial disclosure or origins of funds.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "59934n", "premise": "Likewise, at their production decision reviews, these programs did not capture manufacturing and product reliability knowledge consistent with best practices.", "hypothesis": "Their production decision reviews located an anomaly in the data.", "generated_explanations": [["The context states that reliability knowledge was not captured, but does not mention whether or not an anomaly in the data was located.", "n", "validated"], ["The statement asserts the location of an anomaly, which is not addressed or implied by the context.", "n", "validated"], ["The context focuses on process shortcomings, not on the identification of specific data issues such as anomalies.", "n", "validated"], ["The context states that production decision reviews did not capture specific knowledge, but does not mention locating any anomaly in the data.", "c", "validated"], ["There is no evidence in the context that any anomaly in the data was found during the reviews.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "10916n", "premise": "He'd gone a long way on what he'd found in one elementary book.", "hypothesis": "He learned a lot from that elementary book.", "generated_explanations": [["He made significant progress based on the content of the elementary book.", "e", "validated"], ["The phrase \"gone a long way\" suggests he gained substantial knowledge or skill from the book.", "e", "validated"], ["His achievements were attributed to what he found in the elementary book.", "e", "validated"], ["The phrase \"gone a long way\" could refer to achievements or progress made after using the elementary book, not necessarily indicating the amount learned directly from it.", "n", "validated"], ["The context does not quantify or describe the extent of his learning, only the distance or progress resulting from using the book.", "n", "validated"], ["It is possible that what he achieved involved significant independent effort or other resources beyond the elementary book.", "n", "validated"], ["Going a long way on what he found in the book does not necessarily mean he learned a lot; it could mean he made good use of a small amount of knowledge.", "c", "validated"], ["The phrase \"what he'd found\" suggests he might have only learned a specific piece of information or insight, rather than a lot.", "c", "not_validated"], ["The context does not explicitly state the quantity or depth of his learning, only the practical outcome.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "34043c", "premise": "The Gaiety Theatre in South King Street is worth visiting for its ornate d??cor.", "hypothesis": "The Trump Tower is a terrible place to visit for ornate decor.", "generated_explanations": [["The context only discusses the Gaiety Theatre and does not mention Trump Tower or its decor.", "n", "validated"], ["There is no information in the context about whether Trump Tower has ornate decor or about its quality as a place to visit.", "n", "validated"], ["The evaluation of the Gaiety Theatre does not logically implicate anything about the decor or desirability of visiting Trump Tower.", "n", "validated"], ["The context only discusses the Gaiety Theatre and makes no mention of Trump Tower, so there is no basis to infer anything about Trump Tower's decor.", "c", "validated"], ["The context praises the Gaiety Theatre for its ornate decor, but does not offer any negative or comparative information about Trump Tower.", "c", "not_validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "117089n", "premise": "appropriate agency representatives, help resolve", "hypothesis": "the right agency workers, help fix my security system", "generated_explanations": [["\"Appropriate agency representatives\" refers to the correct or relevant workers from an agency, which aligns with \"the right agency workers.\"", "e", "validated"], ["\"Help resolve\" encompasses the idea of \"help fix,\" as both imply assistance in addressing a problem.", "e", "validated"], ["If the agency in question deals with security systems, their representatives or workers would logically help with fixing a security system.", "e", "not_validated"], ["It is unclear whether \"appropriate agency representatives\" and \"the right agency workers\" refer to the same individuals or roles.", "n", "validated"], ["The context does not specify what issue needs to be resolved, while the statement refers specifically to fixing a security system.", "n", "validated"], ["The type of help provided (\"resolve\" in the context vs. \"fix\" in the statement) may differ depending on the situation.", "n", "validated"], ["\"Agency representatives\" does not necessarily mean \"agency workers,\" as representatives could be managers or spokespeople, not the workers who perform technical tasks.", "c", "validated"], ["The context mentions \"help resolve,\" which is a general term, while the statement specifies \"help fix my security system,\" which is more specific and may not be implied.", "c", "validated"], ["There is no mention in the context that the issue involves a security system, so it is not clear that the help provided would address this specific problem.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "121910c", "premise": "If ancient writings give only a romanticized view, they do offer a more precise picture of Indo-Aryan society.", "hypothesis": "Ancient writings  show an accurate picture of Indo-Anryan society.", "generated_explanations": [["The context states that ancient writings \"offer a more precise picture of Indo-Aryan society,\" which implies they provide accurate information.", "e", "not_validated"], ["The context mentions \"a more precise picture\" but does not state that the picture is accurate, so it is unclear whether \"more precise\" equates to \"accurate.\"", "n", "validated"], ["The context notes that ancient writings give \"only a romanticized view,\" which may conflict with accuracy, but it is not specified whether this means the overall depiction is inaccurate.", "n", "validated"], ["The context does not define what is meant by \"accurate,\" and therefore the extent to which the writings are accurate or inaccurate is not established.", "n", "validated"], ["Ancient writings are said to give only a romanticized view, not an accurate one.", "c", "validated"], ["The passage states ancient writings offer a \"more precise\" picture compared to something else, but not necessarily an \"accurate\" picture.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "113668n", "premise": "If necessary to meeting the restrictions imposed in the preceding sentence, the Administrator shall reduce, pro rata, the basic Phase II allowance allocations for each unit subject to the requirements of section 414.", "hypothesis": "Section 414 helps balance allowance allocations for units.", "generated_explanations": [["Section 414 imposes requirements that, if necessary, lead to pro rata reductions in basic Phase II allowance allocations, ensuring that allocations are adjusted fairly among all units subject to its requirements.", "e", "validated"], ["By mandating pro rata reductions based on the need to meet restrictions, Section 414 provides a mechanism that prevents any one unit from disproportionately benefiting or being disadvantaged, thereby promoting balance in allocations.", "e", "validated"], ["The context only indicates that the Administrator may reduce allocations pro rata for compliance with certain restrictions but does not specify whether section 414 contributes to balancing allocations.", "n", "validated"], ["The context references section 414 as establishing requirements triggering a reduction mechanism but does not clarify the purpose or effect of section 414 itself on allowance distribution balance.", "n", "validated"], ["The statement assumes a positive balancing effect by section 414, but the context does not provide enough detail about the content or objectives of section 414 to determine if this is accurate.", "n", "validated"], ["The context only mentions that the Administrator may reduce allocations to meet restrictions related to section 414, not that section 414 itself balances allocations.", "c", "validated"], ["There is no information in the context suggesting section 414's purpose or function is to balance allowance allocations.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "128176e", "premise": "The chart to which Reich refers was actually presented during Saxton's opening statement, hours before Reich testified, and did not look as Reich claims it did.", "hypothesis": "Reich refers to a chart that he misunderstood.", "generated_explanations": [["Reich described the chart in a way that does not match its actual appearance.", "e", "validated"], ["Reich claimed the chart was presented during his testimony, but it was actually shown earlier.", "e", "validated"], ["The timing and description in Reich's reference indicate he did not accurately comprehend the chart's context or content.", "e", "validated"], ["The context does not specify whether Reich misunderstood the chart, only that he described its appearance inaccurately and that he referred to it.", "n", "validated"], ["The context does not provide information about Reich’s understanding or interpretation of the chart’s content, only the timing and visual accuracy.", "n", "validated"], ["The statement is false because the issue is not that Reich misunderstood the chart, but that he misrepresented the time and appearance of the chart.", "c", "validated"], ["The statement incorrectly claims a misunderstanding, when the actual problem was a factual inaccuracy about when and how the chart was presented, not a comprehension error.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "122322e", "premise": "well uh normally i like to to go out fishing in a boat and uh rather than like bank fishing and just like you try and catch anything that's swimming because i've had such problems of trying to catch any type of fish that uh i just really enjoy doing the boat type fishing", "hypothesis": "I fish in the boat and try catching any fish because I have trouble catching certain types.", "generated_explanations": [["The context explains a preference for boat fishing over bank fishing.", "e", "validated"], ["The speaker mentions trying to catch \"anything that's swimming,\" indicating a willingness to catch any type of fish.", "e", "validated"], ["The speaker states having trouble catching any type of fish, suggesting difficulty with specific types may be a factor.", "e", "validated"], ["The enjoyment of boat fishing is linked to previous problems catching certain fish, supporting the motivation described in the statement.", "e", "validated"], ["The context mentions having problems catching \"any type of fish,\" but does not specify that the difficulty is limited to \"certain types\" as in the statement.", "n", "validated"], ["The statement implies that trouble catching certain types is the reason for fishing from the boat and trying to catch any fish, but the context does not explicitly establish this causal relationship.", "n", "validated"], ["The context states enjoyment of boat fishing, which may be a separate motivation not directly linked to the difficulty of catching certain types of fish.", "n", "validated"], ["The speaker says they have trouble catching any type of fish, not just certain types, so the statement misrepresents the scope of their difficulty.", "c", "validated"]], "label_count_round_1": {"e": 4, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 4, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "53619c", "premise": "True devotees talk shop at even more specialized groups, such as one on Northeastern weather (ne.weather), whose recent conversation topics included the great blizzard of 1978 and the freak snowstorm of May 1977.", "hypothesis": "Ne.weather is a general discussion group, not only about weather.", "generated_explanations": [["The context specifies that ne.weather is a specialized group focused on Northeastern weather, but does not explicitly state whether other general topics are allowed or discussed.", "n", "validated"], ["The context lists weather-related conversations but does not clarify the exclusion or inclusion of non-weather topics.", "n", "validated"], ["The context specifies that ne.weather is a specialized group focused on Northeastern weather, indicating that it is not a general discussion group.", "c", "validated"], ["The recent conversation topics mentioned are specifically about weather events, showing the group's focus is limited to weather, not general topics.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "27287c", "premise": "we were talking . Try to behave", "hypothesis": "We are having an argument, come at me if you dare!", "generated_explanations": [["The context indicates a conversation but does not specify if it is an argument or a friendly exchange.", "n", "validated"], ["There is no evidence in the context about any challenge or confrontation taking place.", "n", "validated"], ["The tone or intent behind \"Try to behave\" is unclear and does not confirm hostility or provocation.", "n", "validated"], ["The context lacks any explicit mention of daring or argumentative language.", "n", "validated"], ["The context only mentions that \"we were talking\" without any indication of hostility or disagreement, so there is no evidence of an argument.", "c", "validated"], ["The statement introduces a challenge or confrontation (\"come at me if you dare!\") that is not supported by the neutral context provided.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "125700e", "premise": "Don't forget to take a change of clothing and a towel.", "hypothesis": "Remember to replace your towel and clothing.", "generated_explanations": [["The context instructs to bring a towel and clothing, but does not mention replacing them.", "n", "validated"], ["It is unclear whether \"replace\" in the statement means to bring new items or to substitute existing ones, which is not specified in the context.", "n", "validated"], ["The context advises bringing extra items, not replacing existing ones.", "c", "validated"], ["There is no suggestion in the context that the current towel or clothing needs to be exchanged for new or different ones.", "c", "validated"], ["\"Take a change of clothing and a towel\" implies packing or carrying additional items, while \"replace\" implies substituting or discarding existing ones, which is not mentioned in the context.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "96946n", "premise": "Once or twice, but they seem more show than battle, said Adrin.", "hypothesis": "Adrin said they liked to perform more than they did fight.", "generated_explanations": [["Adrin described the events as being more like shows than actual battles, implying that performance was emphasized over real fighting.", "e", "validated"], ["The context indicates that the events were \"more show than battle,\" but it does not specify whether Adrin liked this aspect or was merely observing it.", "n", "validated"], ["There is no direct information about Adrin's personal preference or feelings towards performing versus fighting.", "n", "validated"], ["The context indicates that the events were more show than battle, not that Adrin liked performing more than fighting.", "c", "validated"], ["The context does not mention Adrin’s personal preferences, only their observations about the events.", "c", "validated"], ["The statement attributes a personal opinion or preference to Adrin that is not supported by anything Adrin says in the context.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "17660e", "premise": "and not only that it it opens you to phone solicitations", "hypothesis": "It also opens the door to move marketing calls.", "generated_explanations": [["\"Phone solicitations\" and \"marketing calls\" both refer to unsolicited promotional calls.", "e", "validated"], ["If something opens you to phone solicitations, it consequently allows marketing calls to reach you.", "e", "validated"], ["The context explicitly states exposure to phone solicitations, which are a form of marketing calls.", "e", "validated"], ["The context mentions \"phone solicitations\" but does not specify the type, so it is unclear if \"move marketing calls\" are included.", "n", "validated"], ["\"Phone solicitations\" and \"marketing calls\" are referring to the same concept, so the statement is essentially repeating the information already given in the context, not providing a distinct or additional fact to be false.", "c", "not_validated"], ["The statement introduces \"move marketing calls,\" which is not mentioned or implied in the context; \"move marketing calls\" could be a different category, and the context only specifies general phone solicitations.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 1, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 1}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "107252c", "premise": "On the northwestern Alpine frontier, a new state had appeared on the scene, destined to lead the movement to a united Italy.", "hypothesis": "The alpine frontier was separated from Italy by glaciers.", "generated_explanations": [["The context does not mention any physical features such as glaciers separating the Alpine frontier from Italy.", "n", "validated"], ["There is no information provided about the geography or natural barriers of the Alpine frontier in the context.", "n", "validated"], ["The context indicates that a state had appeared on the northwestern Alpine frontier and was involved in the movement towards a united Italy, implying there was significant political and social interaction across this region, which would have been unlikely if the area were completely separated from Italy by glaciers.", "c", "validated"], ["The mention of a new state appearing and leading a movement suggests that the Alpine frontier was accessible and not entirely blocked by natural barriers like glaciers.", "c", "validated"], ["Historical evidence shows that regions on the northwestern Alpine frontier (such as Piedmont-Sardinia) were integral parts of Italian unification processes and not cut off by impassable glaciers.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "113967e", "premise": "'I don't know what happened, exactly.' I said.", "hypothesis": "You aren't making sense.", "generated_explanations": [["Saying \"I don't know what happened, exactly\" suggests a lack of clarity or detail, which could cause confusion for the listener.", "e", "not_validated"], ["Admitting uncertainty about the events could make the explanation seem incoherent or incomplete, prompting the listener to feel the speaker isn't making sense.", "e", "not_validated"], ["The context only states uncertainty about events, not about the speaker's coherence or sense-making.", "n", "validated"], ["There is no information in the context about whether the speaker's statement was logical or made sense to others.", "n", "validated"], ["The context does not indicate how the listener perceived or interpreted the speaker's words.", "n", "validated"], ["The statement \"I don't know what happened, exactly.\" is a clear and coherent expression of uncertainty, so it does make sense.", "c", "validated"], ["Not knowing what happened does not imply incoherence or a lack of sense in communication.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "129464c", "premise": "It can entail prospective and retrospective designs and it permits synthesis of many individual case studies undertaken at different times and in different sites.", "hypothesis": "It can entail prospective and retrospective designs for system redesigns.", "generated_explanations": [["The context states that it can entail prospective and retrospective designs, which is directly mentioned in the statement.", "e", "validated"], ["Prospective and retrospective designs are common approaches for system redesigns, so the statement is plausible within the scope of what is described in the context.", "e", "not_validated"], ["The context mentions \"prospective and retrospective designs\" in general, without specifying that these designs are exclusively for \"system redesigns.\"", "n", "validated"], ["The context does not clarify what \"it\" refers to regarding its intended purpose or application, leaving it undetermined whether \"system redesigns\" are involved.", "n", "validated"], ["The context discusses the synthesis of \"individual case studies\" but does not connect these directly to \"system redesigns.\"", "n", "validated"], ["The context states that prospective and retrospective designs are entailed for synthesizing individual case studies, not specifically for system redesigns.", "c", "validated"], ["There is no mention of \"system redesigns\" in the context, so the statement introduces information not supported by the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "82528c", "premise": "you know maybe it just wasn't possible at all in the first place you know like the no new taxes thing you know that's uh with the economy going the way it is and everything that was nearly ridiculous thing to", "hypothesis": "it's possible to have no new taxes with the way the economy is right now.", "generated_explanations": [["The speaker expresses doubt about the possibility, suggesting uncertainty rather than outright denial.", "n", "validated"], ["The phrase \"maybe it just wasn't possible at all in the first place\" indicates a lack of definitive knowledge about the feasibility.", "n", "validated"], ["Describing the idea as \"nearly ridiculous\" implies skepticism, but does not categorically rule out the possibility.", "n", "validated"], ["The speaker suggests that having no new taxes is nearly ridiculous given the current state of the economy, implying it is not possible.", "c", "validated"], ["The phrase \"wasn't possible at all in the first place\" directly contradicts the statement's claim of possibility.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "134356n", "premise": "You will remember my saying that it was wise to beware of people who were not telling you the truth.\"", "hypothesis": "There might be dishonest people around here.", "generated_explanations": [["Being advised to beware of people who are not telling the truth suggests the presence or possibility of dishonest people nearby.", "e", "validated"], ["The warning implies a concern about dishonesty in the environment, making it plausible that dishonest people might be present.", "e", "validated"], ["The context references a general warning about people who are not truthful, but does not specify whether there are currently dishonest people present.", "n", "validated"], ["The statement speculates about the possibility of dishonest people being present, which is not confirmed or denied by the context.", "n", "validated"], ["The context only recalls advice about being cautious of dishonest people, but does not imply their presence in the current setting or that there actually are dishonest people around.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "102075c", "premise": "um-hum with the ice yeah", "hypothesis": "With the sunshine and heat wave yes.", "generated_explanations": [["The presence of ice suggests efforts to stay cool, which aligns with conditions of sunshine and a heat wave.", "e", "validated"], ["A heat wave and sunshine would cause people to use ice, supporting the implication in the context.", "e", "not_validated"], ["The context mentions \"ice,\" while the statement refers to \"sunshine and heat wave,\" and there is no information connecting the presence of ice to sunshine and a heat wave.", "n", "validated"], ["The context affirms something related to \"ice,\" but does not indicate any weather conditions, making it unclear if sunshine and a heat wave are present.", "n", "validated"], ["The connection between the events (ice and sunshine/heat wave) is not explicitly established, so it is undetermined if the ice situation is happening during sunshine and a heat wave.", "n", "validated"], ["The context only mentions ice, not sunshine or a heat wave.", "c", "validated"], ["There is no indication in the context of any heat or sunny weather conditions.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "96956c", "premise": "You wonder whether he could win a general election coming out of the right lane of the Democratic Party.", "hypothesis": "He will not run in a general election while he is a conservative Democrat.", "generated_explanations": [["The context describes doubt about his electability as a conservative Democrat, implying that his ideological position (right lane of the Democratic Party) might prevent him from running in a general election.", "e", "not_validated"], ["The statement suggests a causal link: as long as he remains a conservative Democrat, he will refrain from running in a general election, which is consistent with the context's skepticism about his chances.", "e", "not_validated"], ["The context raises a question about his electability as a right-leaning Democrat but does not state whether he will or will not run in a general election.", "n", "validated"], ["The context does not specify his future intentions or actions regarding participation in a general election.", "n", "validated"], ["The context does not clarify if being a \"right lane\" Democrat precludes him from running; it only mentions speculation about his chances.", "n", "validated"], ["The context discusses the possibility of him winning a general election as a right-leaning Democrat, which implies he could run in a general election as a conservative Democrat, contradicting the statement.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "24163e", "premise": "We have done that spectacularly.", "hypothesis": "Spectacular results was the only way to describe the impact of our past work.", "generated_explanations": [["The use of \"spectacularly\" to describe how the work was done implies that the results or impact of the work were also spectacular.", "e", "not_validated"], ["If the work was accomplished in a spectacular manner, it is reasonable to infer that the impact or outcomes were also spectacular, making that the only fitting description.", "e", "not_validated"], ["The context indicates that the action was performed \"spectacularly\" but does not specify the actual results or impact of the past work.", "n", "validated"], ["The context does not state that \"spectacular results\" were the only possible way to describe the impact, leaving open the possibility that there are other descriptions.", "n", "validated"], ["There is no explicit information in the context about the nature or extent of the impact of the past work.", "n", "validated"], ["The context indicates that the manner of performing the action was spectacular, but does not confirm that the results or impact were spectacular.", "c", "validated"], ["The context does not specify that \"spectacular\" was the only possible way to describe the impact—other descriptions may also be valid.", "c", "validated"], ["The context refers to something recently accomplished (\"we have done\"), while the statement generalizes about all past work.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "31775c", "premise": "well what station plays uh that type of music", "hypothesis": "What TV station has documentaries about space travel?", "generated_explanations": [["The context refers to music, while the statement refers to TV documentaries about space travel, so the type of station being discussed is not specified.", "n", "validated"], ["It is not clear whether the \"station\" in the context is a TV station or a radio station.", "n", "validated"], ["The context is asking about a music radio station, not a TV station.", "c", "validated"], ["The statement refers to documentaries about space travel, which is unrelated to music.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "8487n", "premise": "We always knew it was an outside chance.", "hypothesis": "We were never assured of it happening in time and we knew this full well.", "generated_explanations": [["The phrase \"outside chance\" indicates a low probability, implying there was never certainty about it happening.", "e", "validated"], ["Saying \"we always knew\" shows an awareness and acceptance of the unlikely outcome, consistent with \"we knew this full well.\"", "e", "validated"], ["Recognizing an \"outside chance\" inherently means a lack of assurance regarding the event happening in any specific timeframe.", "e", "validated"], ["The context states that it was \"an outside chance,\" but does not specify if the timing was a factor in their doubts or if their awareness included the timing aspect.", "n", "validated"], ["The context does not mention whether \"we\" explicitly never felt assured, only that there was a recognition of low probability.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "46576e", "premise": "Perhaps a further password would be required, or, at any rate, some proof of identity.", "hypothesis": "Identity should be a minimum requirement.", "generated_explanations": [["The context suggests that proof of identity may be required, which aligns with the statement that identity should be a minimum requirement.", "e", "validated"], ["The mention of \"some proof of identity\" indicates that verifying identity is seen as a baseline necessity in the situation described.", "e", "validated"], ["The context discusses possible requirements such as a password or proof of identity, but does not specify what the minimum requirement should be.", "n", "validated"], ["The context suggests possibilities rather than rules, leaving it unclear whether identity is considered the minimum or an optional proof.", "n", "validated"], ["The use of \"perhaps\" and \"at any rate\" in the context implies uncertainty about what is definitively required.", "n", "validated"], ["The context suggests that proof of identity is one possible requirement but does not state it should be the minimum requirement.", "c", "validated"], ["The context implies that either a password or proof of identity could be required, not that identity alone is necessary at a minimum.", "c", "validated"], ["The phrase \"at any rate, some proof of identity\" indicates it as an option rather than as a baseline necessity.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "83247e", "premise": "It's come back? cried Julius excitedly.", "hypothesis": "They were excited to hear it will come back.", "generated_explanations": [["Julius expressed excitement upon hearing the news of its return.", "e", "validated"], ["The statement \"It's come back?\" indicates an expectation or confirmation that something will return, causing excitement.", "e", "validated"], ["The word \"excitedly\" directly describes the reaction to the news, matching the emotion in the statement.", "e", "validated"], ["The context only indicates that Julius is excited and asks, \"It's come back?\" but does not confirm that others were excited or that they heard definitive news about it coming back.", "n", "validated"], ["The statement refers to \"they,\" implying multiple people, but the context only references Julius’s reaction.", "n", "validated"], ["Only Julius is described as being excited, not \"they,\" which would imply multiple people.", "c", "validated"], ["The context only shows someone asking a question, not confirming that \"it will come back.\"", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "80109n", "premise": "if it had rained any more in the last two weeks instead of planting Saint Augustine grass in the front yard i think i would have plowed everything under and had a rice field", "hypothesis": "It has rained enough to flood everything here and make rice pattys.", "generated_explanations": [["The context expresses a hypothetical situation about increased rainfall, not a statement that flooding or sufficient rain for rice paddies actually occurred.", "n", "validated"], ["There is no direct information given about the actual amount of rain or the presence of flooding, only a suggestion of what might have happened with more rain.", "n", "validated"], ["The context suggests that it has not rained enough to actually require creating a rice field; it implies a hypothetical situation rather than an actual one.", "c", "validated"], ["The grass planting occurred, indicating conditions were not so wet or flooded as to prevent normal yard work.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "52854n", "premise": "This was used for ceremonial purposes, allowing statues of the gods to be carried to the river for journeys to the west bank, or to the Luxor sanctuary.", "hypothesis": "Statues were moved to Luxor for funerals and other ceremonies.", "generated_explanations": [["The context states that statues of the gods were carried to the Luxor sanctuary, which implies movement to Luxor for ceremonial purposes.", "e", "validated"], ["The mention of \"journeys to the west bank\" can be associated with funerary rites in ancient Egyptian culture, supporting the idea of statues being moved for funerals.", "e", "not_validated"], ["The phrase \"ceremonial purposes\" encompasses both funerals and other types of ceremonies, aligning with the statement.", "e", "validated"], ["The context mentions ceremonial purposes for moving statues but does not specify funerals as one of those ceremonies.", "n", "validated"], ["The context suggests movement to Luxor sanctuary and the west bank but does not clarify which specific ceremonies, besides general ceremonial purposes, were involved.", "n", "validated"], ["The context specifies ceremonial purposes related to journeys to the west bank and the Luxor sanctuary, but does not mention funerals as the reason for moving the statues.", "c", "validated"], ["The context only refers to carrying statues to the river for journeys, not explicitly stating their movement was for funerals.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1, "c": 1}}
{"id": "133274n", "premise": "(Imagine the difference between smoking a cigarette and injecting pure nicotine directly into a vein.)", "hypothesis": "Smoking a cigarette is a lot like injecting pure nicotine.", "generated_explanations": [["Both smoking a cigarette and injecting pure nicotine deliver nicotine into the body, resulting in its physiological effects.", "e", "not_validated"], ["Both methods can quickly introduce nicotine into the bloodstream, leading to rapid onset of effects.", "e", "not_validated"], ["Both involve the use of a substance primarily for its psychoactive, stimulant properties.", "e", "not_validated"], ["The context prompts a comparison but does not specify how similar or different the experiences are, leaving the degree of similarity between smoking a cigarette and injecting nicotine unclear.", "n", "validated"], ["The context only asks the reader to imagine the difference, not explicitly stating if the two actions are alike or not.", "n", "validated"], ["The physiological and psychological effects of each method are not described in the context, making it impossible to assess the claimed similarity.", "n", "validated"], ["No information about the processes, risks, or experiences associated with either action is provided in the context.", "n", "validated"], ["Smoking a cigarette delivers nicotine much more slowly and at lower concentrations than injecting pure nicotine directly into a vein.", "c", "validated"], ["Smoking introduces many other chemicals and toxins besides nicotine, while injection involves only pure nicotine.", "c", "validated"], ["The physiological effects and risks of injecting pure nicotine are much more severe and immediate compared to smoking a cigarette.", "c", "validated"], ["The method of administration (inhalation vs. intravenous injection) leads to significant differences in how the body processes nicotine.", "c", "validated"], ["Smoking a cigarette involves a ritual and sensory experience that injecting pure nicotine does not replicate.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 5}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 4, "c": 5}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 3}}
{"id": "120070n", "premise": "well do you know you have a ten limit a ten minute time limit well that's okay and then they come on and tell you and they tell you got five seconds to say good-bye", "hypothesis": "You get a ten minute time limit, but sometimes you'll be told to end early.", "generated_explanations": [["The context mentions a ten minute time limit.", "e", "not_validated"], ["The context describes being told you have five seconds to say goodbye, indicating you may be asked to end before the full ten minutes.", "e", "validated"], ["The context mentions a ten minute time limit and being told you have five seconds to say good-bye, but does not explicitly state that being told to end early sometimes happens.", "n", "validated"], ["The context only mentions being notified about a ten minute time limit and then being told when there are five seconds left, but does not indicate that anyone is ever told to end early before the time limit is up.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 1, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 1, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "129185n", "premise": "Lincoln glared.", "hypothesis": "The man was angry.", "generated_explanations": [["Glaring is often a facial expression associated with anger, suggesting that Lincoln was angry.", "e", "validated"], ["The context does not specify Lincoln's emotional state; glaring can result from emotions other than anger (e.g., concentration, confusion, or surprise).", "n", "validated"], ["It is not clear from the context whether \"Lincoln\" refers to \"the man\" mentioned in the statement; there is ambiguity regarding the identity of \"the man.\"", "n", "not_validated"], ["The context does not specify that Lincoln is a man.", "c", "validated"], ["Glaring does not necessarily indicate anger; it could imply other emotions or intentions such as concentration, suspicion, or annoyance.", "c", "validated"], ["The statement generalizes \"the man,\" but the context specifically refers to \"Lincoln,\" so it is not established that \"the man\" and \"Lincoln\" are the same individual.", "c", "not_validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 1, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"n": 1, "c": 1}}
{"id": "49172n", "premise": "These alone could have valuable uses.", "hypothesis": "They may be valuable.", "generated_explanations": [["The context asserts that \"these alone could have valuable uses,\" which suggests that they possess qualities or features making them valuable.", "e", "validated"], ["The potential for \"valuable uses\" implies that the items themselves may have value associated with those uses.", "e", "validated"], ["If something can be used in a valuable way, it follows that it may be valuable itself.", "e", "validated"], ["The context says the items \"could have valuable uses,\" which suggests potential but does not confirm actual value, leaving uncertainty about their value.", "n", "validated"], ["The context refers to the value of their uses, not directly to the value of \"them,\" so it's unclear if the items themselves are inherently valuable.", "n", "validated"], ["The context suggests \"could have valuable uses,\" which implies only a possibility, not certainty; the statement asserts value as more likely or definite.", "c", "not_validated"], ["The valuable aspect in the context refers to \"uses,\" not necessarily to the items themselves, whereas the statement claims inherent value to \"they.\"", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "140782c", "premise": "Generally, FGD systems tend to be constructed closer to the ground compared to SCR technology retrofits.", "hypothesis": "FGD systems tend to replicate SCR systems.", "generated_explanations": [["The context discusses the relative positioning (height) of FGD systems versus SCR systems but provides no information about functional, structural, or operational replication.", "n", "validated"], ["The statement involves replication, which implies similarity beyond physical placement, but the context only addresses installation height, leaving replication undetermined.", "n", "validated"], ["FGD systems and SCR systems serve different functions; FGD systems remove sulfur dioxide from flue gas, while SCR systems reduce nitrogen oxides.", "c", "validated"], ["The context discusses physical placement of equipment, not functional replication or technological mimicry.", "c", "validated"], ["Constructing FGD systems closer to the ground does not imply they replicate the design or operation of SCR systems.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "45443c", "premise": "This confluence of a bad tax, a $1 billion reserve, a botched opposition campaign, and voters willing to call a bluff resulted in the I-695 victory.", "hypothesis": "The I-695 failed in its campaign to help the people.", "generated_explanations": [["The context states that I-695 achieved victory, but does not specify whether its intended goal was to help the people or whether it was perceived as helpful or harmful by its supporters or the public.", "n", "validated"], ["There is no information about the actual effects or aftermath of I-695's passage on the people, so it is unclear if it succeeded or failed in helping them.", "n", "validated"], ["The statement assumes that I-695's campaign was explicitly to \"help the people,\" but the context does not clarify the purpose or message of the campaign.", "n", "validated"], ["The context states that I-695 was victorious, indicating it succeeded rather than failed.", "c", "validated"], ["The context implies that the outcome aligned with the will of the voters, suggesting it did help the people as intended.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "22938e", "premise": "Despite a recent renovation, the Meadows Mall is the least appealing of the three suburban malls.", "hypothesis": "The Meadows Mall is not appealing.", "generated_explanations": [["Being described as the least appealing among the three suburban malls indicates that the Meadows Mall lacks appeal compared to the others.", "e", "validated"], ["The use of \"least appealing\" implies a relative lack of appeal, which includes being not appealing.", "e", "validated"], ["The context specifies \"least appealing\" among three malls, which does not necessarily mean \"not appealing\" at all; it could still be somewhat appealing compared to an absolute standard.", "n", "validated"], ["\"Least appealing\" is a comparative assessment, so without knowing the general appeal of all three malls, one cannot determine if Meadows Mall is actually \"not appealing\" in an absolute sense.", "n", "validated"], ["The statement \"The Meadows Mall is not appealing\" is false because being the least appealing of three options does not mean it is not appealing; it could still be somewhat appealing, just less so than the other two malls.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "67571c", "premise": "Everybody has this quote from NBA commissioner David  You cannot strike your boss and still hold your job--unless you play in the NBA.", "hypothesis": "NBA commissioner said he hates NBA players.", "generated_explanations": [["The context does not mention the NBA commissioner expressing hatred toward NBA players.", "n", "validated"], ["The context only references a quote about player conduct, not personal feelings of the commissioner.", "n", "validated"], ["The quote from the NBA commissioner does not mention hatred toward NBA players; it only addresses the consequences of striking a boss in the NBA as compared to other professions.", "c", "validated"], ["The commissioner’s quote is about employment consequences, not about expressing personal feelings or emotions toward NBA players.", "c", "validated"], ["There is no direct statement in the context indicating that the commissioner said he hates NBA players.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "5087e", "premise": "approaches to achieving missions vary considerably between agencies.", "hypothesis": "Approaches to achieving missions might change a lot.", "generated_explanations": [["The context states that different agencies use considerably varied approaches, which implies that approaches are not fixed and can differ greatly, aligning with the statement that approaches might change a lot.", "e", "validated"], ["The significant variation mentioned in the context suggests that there is no single, stable method, supporting the idea that approaches to achieving missions might undergo substantial changes.", "e", "validated"], ["The context specifies variation between agencies, but does not clarify if individual agency approaches change over time, so the temporal aspect of \"might change a lot\" is undetermined.", "n", "validated"], ["The term \"vary considerably between agencies\" addresses differences across agencies at a given time, not the possibility or frequency of changes occurring.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "23769n", "premise": "Kom Ombo is an unusual temple in that it is dedicated to two gods.", "hypothesis": "Rarely visited, Kom Ombo is a strange temple devoted to two gods.", "generated_explanations": [["The context describes Kom Ombo as \"unusual\" because it is dedicated to two gods, aligning with the statement that it is a \"strange temple devoted to two gods.\"", "e", "validated"], ["Both the context and statement mention that the temple is dedicated/devoted to two gods, confirming this aspect of the statement.", "e", "not_validated"], ["The context does not provide information about how frequently Kom Ombo is visited, so it is unclear whether it is rarely visited.", "n", "validated"], ["The context describes Kom Ombo as \"unusual,\" but does not specifically state it is \"strange,\" so the connotation of \"strange\" is not confirmed.", "n", "validated"], ["The context does not indicate that Kom Ombo is rarely visited; it only describes its unusual dedication to two gods.", "c", "validated"], ["The statement implies that its strangeness is due to it being \"rarely visited,\" but the context states the temple is \"unusual\" because it is dedicated to two gods, not because of visitation frequency.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "13760n", "premise": "If they have overestimated how far the CPI is off, Boskin and his commission may institutionalize an underestimated CPI--guaranteeing a yearly, stealth tax increase.", "hypothesis": "If they've overestimated how far the CPI is off, it will have horrific consequences.", "generated_explanations": [["Overestimating how far the CPI is off could lead to officially adopting a lower, underestimated CPI, which would not accurately track inflation.", "e", "not_validated"], ["An institutionalized underestimated CPI would result in a hidden or \"stealth\" tax increase every year, negatively impacting taxpayers.", "e", "not_validated"], ["The context specifies a \"yearly, stealth tax increase\" as a consequence but does not clarify whether this is considered \"horrific,\" so the severity implied by the statement is not established.", "n", "validated"], ["The context does not mention or quantify any consequences beyond the stealth tax increase, so potential additional negative effects alluded to in the statement are not confirmed.", "n", "validated"], ["The judgment of what counts as \"horrific\" is subjective and not defined in the context.", "n", "validated"], ["The context specifically mentions a \"yearly, stealth tax increase\" as a consequence, but does not describe the consequences as \"horrific\" or suggest effects of a comparable severity.", "c", "validated"], ["The context does not elaborate on broader or more severe ramifications beyond the specified tax impact, so labeling the consequences as \"horrific\" is not supported.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "2133n", "premise": "The tomb guardian will unlock the gate to the tunnel and give you a candle to explore the small circular catacomb, but for what little you can see, it is hardly worth the effort.", "hypothesis": "The tomb garden can give you a thorough tour of the catacombs.", "generated_explanations": [["The context only mentions the tomb guardian unlocking the gate and giving a candle, not providing a thorough tour.", "n", "validated"], ["The catacomb appears small and not thoroughly accessible based on what is visible, so a thorough tour is not guaranteed.", "n", "validated"], ["The usefulness or completeness of exploring the catacomb is called into question by the comment that it is \"hardly worth the effort,\" leaving it undetermined whether a thorough tour is even possible or offered.", "n", "validated"], ["The tomb guardian only gives you access to a small circular catacomb, not a thorough tour of the entire catacombs.", "c", "validated"], ["The statement refers to a \"tomb garden,\" which appears to be a mischaracterization or misspelling of \"tomb guardian,\" who is the actual figure in the context.", "c", "not_validated"], ["The context suggests that the catacomb is barely worth exploring due to its limited visibility and extent, implying a thorough tour is not possible or provided.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "117093n", "premise": "Hong Kong has long been China's handiest window on the West, and the city is unrivaled in its commercial know-how and managerial expertise.", "hypothesis": "Hong Kong is a great place to find commercial know-how if you are hiring someone new.", "generated_explanations": [["Hong Kong is described as being unrivaled in its commercial know-how, implying a high concentration of such expertise in the city.", "e", "validated"], ["Being China's window on the West suggests that Hong Kong attracts and develops talent with international commercial skills.", "e", "validated"], ["The city's reputation for managerial expertise supports the likelihood of finding candidates with strong commercial know-how when hiring.", "e", "validated"], ["The context highlights Hong Kong's collective strength in commercial know-how and managerial expertise but does not specifically address the availability of individuals with these skills for hiring.", "n", "validated"], ["The statement assumes that commercial know-how is accessible specifically in the context of recruiting talent, which is not directly discussed in the context.", "n", "validated"], ["There is no information provided about the job market, hiring pool, or ease of recruitment in Hong Kong.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 3}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "112402c", "premise": "Although the accounting and reporting model needs to be updated, in my view, the current attest and assurance model is also out of date.", "hypothesis": "The accounting model needs to be updated in addition to the acquisition model.", "generated_explanations": [["The context mentions the need to update the accounting and reporting model, but does not mention anything about the acquisition model.", "n", "validated"], ["There is no information in the context about whether the acquisition model needs to be updated.", "n", "validated"], ["The statement refers to the \"acquisition model,\" which is not discussed in the context; thus, its status is unknown.", "n", "validated"], ["The context does not mention the acquisition model; it refers to the attest and assurance model as being out of date, not the acquisition model.", "c", "validated"], ["The statement incorrectly substitutes \"acquisition model\" for \"attest and assurance model,\" which misrepresents the context.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "32754n", "premise": "After shuttering the DOE, Clinton could depict himself as a crusader against waste and bureaucracy who succeeded where even Reagan failed.", "hypothesis": "Reagan had tried to shutter the DOE but was unable to.", "generated_explanations": [["The phrase \"succeeded where even Reagan failed\" implies that Reagan attempted to shutter the DOE but did not succeed.", "e", "validated"], ["Clinton's achievement is contrasted with Reagan's failure, indicating Reagan made an effort but was unable to accomplish it.", "e", "validated"], ["The context uses Reagan as a benchmark for a difficult task, which suggests Reagan previously attempted and did not complete it.", "e", "validated"], ["The context states that Clinton \"succeeded where even Reagan failed,\" which implies but does not explicitly confirm that Reagan attempted to shutter the DOE.", "n", "validated"], ["The context does not provide any direct information about Reagan's actions or intentions regarding the DOE, only referencing his failure in a comparative sense.", "n", "validated"], ["The phrase \"where even Reagan failed\" could refer to a general goal of reducing waste and bureaucracy, not necessarily the specific act of shuttering the DOE.", "n", "validated"], ["The context says that Clinton could claim to have \"succeeded where even Reagan failed,\" but it does not explicitly state that Reagan tried to shutter the DOE, only that Reagan failed to do so.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "120896n", "premise": "Tell me, how did those scribbled words on the envelope help you to discover that a will was made yesterday afternoon?\" Poirot smiled.", "hypothesis": "How did you work out from that text that there was a new will?", "generated_explanations": [["\"Scribbled words on the envelope\" refers to the \"text,\" which establishes that Poirot used the content of what was written to deduce the existence of a new will.", "e", "validated"], ["Both the context and statement ask about deducing the creation of a will from written clues, indicating the reasoning process is the same in both.", "e", "validated"], ["The context only mentions \"scribbled words on the envelope\" and does not reveal the content of the text, making it unclear whether the words refer specifically to a new will.", "n", "validated"], ["The context discusses the discovery of a will having been made, but does not specify that the discovery was made solely from the text on the envelope, so it is undetermined if the text alone revealed a new will.", "n", "validated"], ["The statement assumes the existence of a \"new will,\" but the context does not make it explicit whether the will discovered was new or simply newly found evidence of an existing will.", "n", "validated"], ["The statement refers to \"that text,\" but the context specifies \"scribbled words on the envelope,\" which may not be the same as a formal text.", "c", "not_validated"], ["The statement asserts the will is \"new,\" whereas the context only specifies a will was made \"yesterday afternoon,\" not qualifying its novelty.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "25437n", "premise": "Well, we will come in and interview the brave Dorcas.\" Dorcas was standing in the boudoir, her hands folded in front of her, and her grey hair rose in stiff waves under her white cap.", "hypothesis": "Dorcas is well known for her bravery.", "generated_explanations": [["The context only mentions an interview with Dorcas described as \"brave,\" but does not provide any evidence that she is well known for her bravery.", "n", "validated"], ["The term \"brave\" may be an isolated descriptor or a rhetorical flourish rather than an indication of her reputation.", "n", "validated"], ["There is no information in the context about other people's awareness or opinions regarding Dorcas's bravery.", "n", "validated"], ["The context mentions Dorcas being called \"brave\" in a likely ironic or procedural manner during an interview and provides no supporting evidence that she is well known for bravery.", "c", "validated"], ["There is no indication in the context that others know Dorcas for her bravery; her reputation is not described at all.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "56895c", "premise": "The entire economy received a massive jump-start with the outbreak of the Korean War, with Japan ironically becoming the chief local supplier for an army it had battled so furiously just a few years earlier.", "hypothesis": "Korea and Japan were not at war.", "generated_explanations": [["The context describes Japan supplying an army involved in the Korean War, indicating cooperation or at least lack of hostility between Japan and the parties involved in the war, rather than Japan itself being at war with Korea.", "e", "validated"], ["Japan is described as a supplier, not a combatant in the Korean War, implying it was not engaged in war with Korea at that time.", "e", "validated"], ["The context mentions Japan had battled \"an army\" fiercely a few years prior, but does not clearly specify whether that army was Korean, American, or another force, leaving the state of war between Korea and Japan undetermined.", "n", "validated"], ["The context focuses on Japan’s economic relationship during the Korean War, not directly detailing the diplomatic or military relationship between Korea and Japan at that time.", "n", "validated"], ["There is no explicit information about whether Korea and Japan were in a state of war or peace during the events described.", "n", "validated"], ["The context states that Japan had battled the army it was now supplying, implying that Japan and Korea (or Korea's army) had been at war.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "43094c", "premise": "Time 's cover package considers what makes a good school.", "hypothesis": "Time's cover package is about how most college students have to deal with insane student loans.", "generated_explanations": [["The context mentions the cover package is about \"what makes a good school,\" but does not specify a focus on student loans or college students.", "n", "validated"], ["It is unclear from the context whether the discussion about \"what makes a good school\" includes or excludes financial aspects like student loans.", "n", "validated"], ["The context could refer to any type of school, not necessarily colleges, leaving uncertain whether the statement about college student loans is relevant.", "n", "validated"], ["The context specifies that Time's cover package is about what makes a good school, not about college students dealing with student loans.", "c", "validated"], ["The statement incorrectly describes the subject of the cover package as focusing on student loans, which is not mentioned in the context.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "21834e", "premise": "But the world is not run for the edification of tourists.", "hypothesis": "The world does not try and morally subject to tourists.", "generated_explanations": [["The phrase \"not run for the edification of tourists\" indicates that the world does not exist to educate, improve, or benefit tourists specifically, implying there is no intent to cater to their moral interests.", "e", "validated"], ["\"Edification\" inherently involves moral or intellectual improvement, so a lack of focus on tourists' edification means there is no attempt to morally serve or be subject to tourists.", "e", "validated"], ["The statement follows logically from the context, as not seeking tourists' edification encompasses not morally subjecting the world to their interests.", "e", "validated"], ["The term \"edification\" generally refers to intellectual or moral improvement but does not specify \"morally subject.\"", "n", "validated"], ["\"Morally subject\" is an unclear phrase and could have various interpretations not directly addressed by \"edification.\"", "n", "validated"], ["The context negates the world being run for tourists' edification but does not address whether it tries to morally subject itself to tourists in other ways.", "n", "validated"], ["The phrase \"the world is not run for...\" implies intent regarding purpose, not necessarily moral subjugation, which is a broader or different concept.", "n", "validated"], ["The context refers to the world not being organized for tourists’ benefit or improvement, not moral subjection.", "c", "validated"], ["The phrase \"morally subject to tourists\" is not equivalent to \"run for the edification of tourists,\" as edification means education or improvement, not moral subjugation.", "c", "validated"], ["The context does not mention morality or subjection, only lack of prioritization for tourists' learning or benefit.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 4, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "139836n", "premise": "The centralization dear to Richelieu and Louis XIV was becoming a reality.", "hypothesis": "Louis XIV cared a lot about centralization of his country and people.", "generated_explanations": [["The phrase \"the centralization dear to Richelieu and Louis XIV was becoming a reality\" indicates that centralization was important to Louis XIV.", "e", "validated"], ["Describing centralization as \"dear to Louis XIV\" implies he cared about it personally and prioritized it.", "e", "validated"], ["The fact that centralization was actively being realized during Louis XIV's time shows his commitment to making it happen.", "e", "validated"], ["The context mentions that centralization was \"dear to Richelieu and Louis XIV,\" which suggests they valued it, but does not explicitly state the intensity of Louis XIV’s personal feelings or how much he \"cared\" about it.", "n", "validated"], ["The phrase \"was becoming a reality\" indicates a process occurring, but does not directly attribute the process to Louis XIV's personal motivations or level of care.", "n", "validated"], ["The context groups Richelieu and Louis XIV together, making it unclear how much each individually cared about centralization.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 3}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "57454e", "premise": "what does um is Robby Robin Williams does he have a funny part in the movie or is", "hypothesis": "Is Robin Williams in the movie?", "generated_explanations": [["The context mentions \"Robby Robin Williams,\" which suggests that Robin Williams is being discussed in relation to the movie.", "e", "validated"], ["The question in the context asks if Robin Williams has a funny part in the movie, implying that Robin Williams is in the movie.", "e", "validated"], ["The context mentions \"Robby Robin Williams\" but does not confirm whether Robin Williams is actually in the movie.", "n", "validated"], ["The context discusses whether Robin Williams has a funny part but does not explicitly state his presence in the movie.", "n", "validated"], ["The speaker appears uncertain (\"um\"), indicating lack of definite knowledge about Robin Williams' involvement in the movie.", "n", "validated"], ["The context questions whether Robby Robin Williams has a funny part in the movie, not confirming his presence, so there is no direct statement that he is in the movie.", "c", "validated"], ["The context expresses uncertainty (\"does he have\") about Robin Williams' involvement, implying that his participation in the movie is not established.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "34573n", "premise": "But the door was locked?\" These exclamations burst from us disjointedly.", "hypothesis": "We chaotically exclaimed as we all jumped up in a frenzy, \"But the door wasn't unlocked?\"", "generated_explanations": [["The use of \"burst from us disjointedly\" suggests that the exclamations were made in a chaotic and frenzied manner, aligning with the idea of jumping up in a frenzy and exclaiming chaotically.", "e", "validated"], ["The quoted exclamation in the statement is a slight rephrasing of the one in the context, indicating both refer to the same expression of surprise about the door's locked state.", "e", "validated"], ["The collective nature implied in \"us\" and \"we\" matches in both the context and the statement, supporting the truth of the statement given the context.", "e", "not_validated"], ["The context says \"the door was locked,\" but the statement refers to \"the door wasn't unlocked,\" which is a double negative and could create ambiguity in intent or meaning.", "n", "validated"], ["The context describes exclamations bursting \"disjointedly,\" which does not explicitly confirm jumping up in a frenzy, leaving the group's physical reaction undetermined.", "n", "validated"], ["The exact wording of the exclamation in the statement (\"wasn't unlocked\") differs from the context (\"was locked\"), making it unclear if the exclamation was phrased as in the statement.", "n", "validated"], ["The context does not specify whether all individuals exclaimed together or how coordinated their actions were, so it is not clear if everyone jumped up or acted \"chaotically.\"", "n", "validated"], ["The statement says \"the door wasn't unlocked,\" while the context quotes \"the door was locked,\" which uses different wording and the opposite reasoning.", "c", "validated"], ["The statement says \"we all jumped up in a frenzy,\" which is not described or implied in the context.", "c", "validated"], ["The statement paraphrases the exclamation with a different structure (\"wasn't unlocked\" vs. \"was locked\"), which is not equivalent in meaning.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "52278e", "premise": "Tuppence rose.", "hypothesis": "Tuppence stood up.", "generated_explanations": [["\"Rose\" can mean to get up from a seated position, which is synonymous with \"stood up.\"", "e", "validated"], ["\"Rose\" could mean Tuppence moved upward in some way other than standing up, such as jumping or levitating.", "n", "validated"], ["The word \"rose\" might refer to an emotional or metaphorical rising, not a physical action.", "n", "validated"], ["\"Rose\" could mean increasing in rank, status, or another metaphorical sense, not physically standing up.", "c", "validated"], ["\"Rose\" could refer to getting out of bed or another seated position that does not involve standing up (e.g., rising to walk or move without stopping in a standing position).", "c", "not_validated"], ["The statement \"Tuppence stood up\" specifies a physical action of moving to a standing posture, whereas \"rose\" could be interpreted as only partially rising (e.g., getting onto knees) rather than fully standing.", "c", "not_validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 2}}
{"id": "11618c", "premise": "Enlarging the village was not desirable and most knew that Severn only desired wealth and a seat on the council of elders.", "hypothesis": "Severn was happy being poor.", "generated_explanations": [["The context mentions Severn desired wealth, but does not state how Severn felt about being poor.", "n", "validated"], ["The context does not provide information about Severn's current emotional state regarding his financial situation.", "n", "validated"], ["Severn desired wealth, which indicates he was not happy being poor.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "118460n", "premise": "and the other thing is the cost it's almost prohibitive to bring it to a dealer", "hypothesis": "The cost of fixing it makes it hard to bring it to a dealer.", "generated_explanations": [["The context states that the cost is almost prohibitive, which means it is very high.", "e", "validated"], ["The phrase \"almost prohibitive to bring it to a dealer\" directly supports that the cost is a significant barrier to using the dealer's services.", "e", "validated"], ["If the cost is almost prohibitive, then it makes bringing it to the dealer difficult or unlikely.", "e", "validated"], ["The context mentions that the cost is \"almost prohibitive,\" which suggests the cost is very high but does not confirm that it definitively makes it hard to bring it to a dealer.", "n", "validated"], ["The statement assumes that the high cost specifically \"makes it hard\" to bring it to a dealer, but the context does not explicitly state that the difficulty in bringing it to a dealer is due to the cost alone; other factors may be involved.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "54383c", "premise": "He knew how the Simulacra was supposed to develop.", "hypothesis": "He didn't know about Sims.", "generated_explanations": [["The context mentions \"Simulacra\" but does not specify whether \"Sims\" refers to the same thing as \"Simulacra,\" so it is unclear if knowing about one implies knowledge of the other.", "n", "validated"], ["The statement refers to knowledge about \"Sims,\" which could be a different entity or concept than \"Simulacra,\" and the context provides no information about his knowledge of \"Sims.\"", "n", "validated"], ["Knowing how the Simulacra was supposed to develop implies some knowledge about Sims, contradicting the statement that he didn't know about Sims.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "123751n", "premise": "i think that the people that are um have um a lower income which you automatically equate with lower education", "hypothesis": "I think because you have lower income you are less educated.", "generated_explanations": [["The context explicitly states that lower income is automatically equated with lower education, indicating the speaker believes there is a direct association between the two.", "e", "validated"], ["The wording “I think because you have lower income you are less educated” matches the speaker's implication that income level determines education level.", "e", "validated"], ["The context mentions that lower income is \"automatically equate[d] with lower education,\" which may reflect a generalization or perceived social assumption rather than the speaker’s own belief.", "n", "validated"], ["The use of \"I think\" in the statement asserts it as the speaker’s personal belief, but the context suggests the speaker may be describing a common societal association, not necessarily stating their own conviction.", "n", "validated"], ["The context’s phrasing is ambiguous and does not clearly distinguish between personal belief and commentary on others’ assumptions.", "n", "validated"], ["The context describes the act of equating lower income with lower education, not a personal belief or assertion that lower income causes lower education.", "c", "validated"], ["The speaker uses \"you automatically equate,\" which suggests they are describing a general perception or stereotype, not stating their own belief.", "c", "validated"], ["The speaker is reflecting on a thought process or assumption, rather than making a direct causal claim about income and education.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "43891n", "premise": "GAO recommends that the Secretary of Defense revise policy and guidance", "hypothesis": "GAO recommends that you eat 5 fruit/veg per day", "generated_explanations": [["The context refers to policy and guidance revisions related to the Secretary of Defense, not dietary recommendations.", "n", "validated"], ["There is no mention or implication of fruit or vegetable consumption in the context.", "n", "validated"], ["The pronoun \"you\" in the statement is ambiguous and does not correspond to any entity referenced in the context.", "n", "validated"], ["The context discusses recommendations related to defense policy, not dietary advice.", "c", "validated"], ["The statement refers to eating habits, which is unrelated to the subject matter of defense policy in the context.", "c", "validated"], ["The GAO is making recommendations to the Secretary of Defense, not to \"you,\" and not about nutritional guidelines.", "c", "validated"], ["There is no mention of fruit or vegetable consumption in the context.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 4}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 4}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "113039e", "premise": "In this respect, bringing Steve Jobs back to save Apple is like bringing Gen.", "hypothesis": "Steve Jobs came back to Apple.", "generated_explanations": [["The phrase \"bringing Steve Jobs back to save Apple\" implies that Steve Jobs returned to the company.", "e", "validated"], ["The comparison relies on the premise that Steve Jobs at some point came back to Apple.", "e", "validated"], ["The statement is a literal claim about Steve Jobs returning to Apple, while the context uses a simile (\"like bringing Gen\") to make a comparison, not an assertion of fact.", "n", "validated"], ["The context refers to the concept of bringing Steve Jobs back, but does not specify whether this actually happened.", "n", "validated"], ["It is unclear from the context whether Steve Jobs was actually brought back or if the mention is purely hypothetical or metaphorical.", "n", "validated"], ["The context uses a simile, comparing bringing Steve Jobs back to Apple with another hypothetical situation; it does not state that Steve Jobs actually came back to Apple.", "c", "validated"], ["The context is discussing a hypothetical or analogous scenario, not a factual event.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "83900e", "premise": "Ca'daan closed the door behind them and retied the not.", "hypothesis": "Ca'daan closed the door as they entered, and bound it shut with rope.", "generated_explanations": [["Ca'daan closed the door behind them, which implies they closed the door as they entered.", "e", "validated"], ["Ca'daan retied the \"not,\" which, assuming this is a typographical error for \"knot,\" implies that Ca'daan used rope to bind the door shut.", "e", "validated"], ["The context says Ca'daan \"retied the not,\" but does not specify that the knot was a rope, nor that it was used to bind the door shut.", "n", "validated"], ["The context does not state explicitly that Ca'daan closed the door as they entered; it only mentions closing the door behind them.", "n", "validated"], ["The context does not clarify that the knot was tied for the purpose of securing the door shut.", "n", "validated"], ["The context mentions retied the knot, not bound the door shut with rope.", "c", "validated"], ["The context specifies retied the not (likely \"knot\") without indicating that it was used to secure the door itself.", "c", "validated"], ["The context does not state that Ca'daan bound the door shut, only that they closed it.", "c", "validated"], ["There is no mention of rope in the context, only reference to a knot.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 4}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "10119e", "premise": "Then he is very sure.", "hypothesis": "He is very sure of himself.", "generated_explanations": [["Being \"very sure\" typically implies confidence, which aligns with being \"very sure of himself.\"", "e", "validated"], ["The use of \"very sure\" in the context refers to the individual's own certainty, indicating self-assurance.", "e", "validated"], ["The context states he is very sure but does not specify what he is sure about; being sure generally does not necessarily mean being sure of oneself.", "n", "validated"], ["It is possible for someone to be very sure about a fact, decision, or outcome rather than about themselves.", "n", "validated"], ["The context indicates certainty, but does not specify that the certainty is about himself; he could be sure about something external.", "c", "validated"], ["\"Very sure\" could refer to sureness about a fact, event, or another person, not necessarily self-confidence.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "21810n", "premise": "you can get a hard copy of it and that's about it", "hypothesis": "An email won't cut it.", "generated_explanations": [["A hard copy is required, so a digital form like an email is insufficient.", "e", "validated"], ["The context implies only a physical version is acceptable, rendering an email inadequate.", "e", "validated"], ["The context does not specify if an email is insufficient or not, only that a hard copy is available.", "n", "validated"], ["It is unclear from the context whether an email is an acceptable alternative; the statement's claim about email is not addressed.", "n", "validated"], ["The context does not mention email as an option at all; it only references obtaining a hard copy.", "c", "validated"], ["The context does not indicate any inadequacy of email; it simply does not address email.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "35700c", "premise": "The Honorable Bill Archer, Chairman The Honorable Charles B. Rangel Ranking Minority Member Committee on Ways and Means House of Representatives", "hypothesis": "Bill Archer has never held government office in his entire life.", "generated_explanations": [["The context refers to Bill Archer as \"Chairman\" of the Committee on Ways and Means, which suggests some form of official position, but it does not explicitly state whether he has held government office before or outside of this role.", "n", "not_validated"], ["The context does not provide any direct information about Bill Archer's entire life history or career outside of his committee involvement.", "n", "validated"], ["Bill Archer is referred to as \"The Honorable,\" a title commonly used for individuals who have held government office.", "c", "validated"], ["Bill Archer is identified as the Chairman of the Committee on Ways and Means, which is a government position in the House of Representatives.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 1, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "109278n", "premise": "Lawyers in their first three years of practice or who are inactive pay $90, and retired lawyers pay nothing.", "hypothesis": "Lawyers pay $90 to be included in the directory.", "generated_explanations": [["Lawyers in their first three years of practice pay $90, which may be the fee required for inclusion in the directory.", "e", "not_validated"], ["Inactive lawyers also pay $90, which may be the cost to be listed in the directory.", "e", "not_validated"], ["The context specifies fee information only for lawyers in their first three years of practice, inactive lawyers, and retired lawyers, but does not mention the fee for other categories of lawyers.", "n", "validated"], ["The context does not specify whether the $90 fee is specifically for inclusion in the directory or for something else, such as general dues.", "n", "validated"], ["The context indicates that some lawyers (retired) pay nothing, which suggests not all lawyers pay $90, but does not clarify the policy for all possible lawyer statuses.", "n", "validated"], ["Not all lawyers pay $90; retired lawyers pay nothing.", "c", "validated"], ["The $90 fee applies only to lawyers in their first three years of practice or who are inactive, not to all lawyers.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "138530e", "premise": "It vibrated under his hand.", "hypothesis": "It hummed quietly in his hand.", "generated_explanations": [["Vibrations can create a humming sound, especially if the vibrations are steady or rapid.", "e", "validated"], ["The act of something vibrating under someone's hand can feel and sound like a quiet hum.", "e", "validated"], ["The context mentions vibration but does not specify the presence of a humming sound.", "n", "validated"], ["The context does not indicate the loudness or quietness of any sound, if present.", "n", "validated"], ["The context does not confirm that the vibration occurred in his hand specifically, only under it.", "n", "not_validated"], ["The context only describes physical vibration and does not mention any sound, so there is no evidence that it hummed.", "c", "validated"], ["The statement asserts that the humming was quiet, but the context provides no information about the volume or presence of any sound at all.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "13387e", "premise": "yeah i can believe that", "hypothesis": "I agree with what you said.", "generated_explanations": [["Stating \"yeah i can believe that\" implies acceptance or endorsement of the prior statement, which aligns with expressing agreement.", "e", "validated"], ["The context indicates belief but does not explicitly state agreement, so it is unclear if the speaker fully agrees or just finds the statement plausible.", "n", "validated"], ["The context does not specify what was said, so it is undetermined whether the agreement claimed in the statement applies.", "n", "validated"], ["The context could refer to partial belief or acknowledgment rather than outright agreement with all aspects of what was said.", "n", "validated"], ["Believing that something is possible or true does not necessarily mean agreeing with it; one can believe something without agreeing with it.", "c", "validated"], ["The statement \"yeah i can believe that\" expresses acceptance of plausibility rather than explicit agreement with the opinion or viewpoint.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "58557e", "premise": "In the first instance, IRS would have no record of time before the person could get through to an agent and of discouraged callers.", "hypothesis": "There is no recording of the time for callers.", "generated_explanations": [["The IRS has no record of the time before a person connects with an agent, indicating that the duration callers spend waiting is not recorded.", "e", "validated"], ["There is no data on discouraged callers, implying that times for those who hang up before reaching an agent are also not recorded.", "e", "validated"], ["Not recording the pre-agent connection time indicates that the overall caller wait times are not documented.", "e", "validated"], ["The context specifies the IRS has no record of the time before a person could reach an agent and no record of discouraged callers, but it does not clarify whether there are recordings of time for all callers, only for certain periods, or for some subset.", "n", "validated"], ["The context implies a lack of records for some types of wait times but does not explicitly state that there are no recordings whatsoever.", "n", "validated"], ["The term \"no recording of the time\" could refer to different meanings—such as audio recordings, system logs, or detailed logs for all callers—which the context does not specify.", "n", "validated"], ["The statement claims there is \"no recording of the time for callers,\" but the context specifies that IRS would have no record only of the time before a person could get through to an agent, implying that other aspects of call time may still be recorded.", "c", "validated"], ["The statement overlooks the fact that time spent after connecting to an agent, or other interactions, might still be recorded by the IRS.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "36811c", "premise": "This having come to his stepmother's ears, she taxed him with it on the afternoon before her death, and a quarrel ensued, part of which was overheard.", "hypothesis": "A love affair sparked just moments before her death.", "generated_explanations": [["The context mentions a quarrel, not a love affair, and does not specify the nature of their interaction beyond a confrontation and argument.", "n", "validated"], ["The context does not provide information about any romantic relationship or feelings between the individuals involved.", "n", "validated"], ["The time sequence and causality of a love affair starting \"just moments before her death\" are not addressed in the context.", "n", "validated"], ["The context describes a quarrel, not a love affair, occurring before her death.", "c", "validated"], ["The interaction mentioned is a confrontation due to some information reaching the stepmother, not the start of a love affair.", "c", "validated"], ["There is no indication in the context of romantic feelings or a relationship beginning between the involved parties.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "73840n", "premise": "Hersheimmer \"WELL,\" said Tuppence, recovering herself, \"it really seems as though it were meant to be.\" Carter nodded.", "hypothesis": "See, luck is real!", "generated_explanations": [["Tuppence's remark that \"it really seems as though it were meant to be\" implies that events are guided by fate or luck, supporting the claim that luck is real.", "e", "validated"], ["Carter's nod of agreement suggests he concurs with the idea of things being determined by fortune or luck.", "e", "validated"], ["The context does not explicitly attribute the perceived serendipity or favorable outcome to luck; it merely notes that Tuppence remarks \"it really seems as though it were meant to be,\" and Carter nods, which could reflect fate, coincidence, or inevitability rather than luck.", "n", "validated"], ["The context lacks any direct reference or evidence supporting the actual existence of luck as a real phenomenon.", "n", "validated"], ["The context reflects Tuppence’s subjective feeling that events are predestined or fortuitous, but it does not provide objective evidence that luck is a real, external phenomenon.", "c", "validated"], ["Carter’s response is limited to a nod and does not substantiate the existence of luck, only acknowledging Tuppence’s sentiment.", "c", "validated"], ["The situation described in the context can be interpreted as coincidence or perception rather than proof that luck exists as a real force.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "31249e", "premise": "(And yes, he has said a few things that can, with some effort, be construed as support for supply-side economics.)", "hypothesis": "It would take some work to construe the things as support for supply-side economics.", "generated_explanations": [["The phrase \"with some effort\" in the context indicates that it is not easy or straightforward to interpret his statements as support for supply-side economics.", "e", "validated"], ["The word \"construed\" in both the context and statement shows that interpreting his statements as supportive requires more than just a surface reading, implying work or effort is needed.", "e", "validated"], ["The phrase \"with some effort\" is subjective and may not clearly quantify the degree of work involved, making it hard to determine if \"some effort\" equates to \"some work.\"", "n", "not_validated"], ["The context refers to \"a few things\" that can be construed, but does not specify the actual amount or nature of the work required to do so.", "n", "validated"], ["The relationship between \"some effort\" and \"some work\" is not definitively established in the context, leaving it ambiguous whether they are equivalent in this case.", "n", "validated"], ["The context explicitly states that it would take \"some effort\" to construe the things as support, which closely matches \"it would take some work\" in the statement, making the statement true rather than false according to the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "91913n", "premise": "This is one of the reasons we're growing too weak to fight the Satheri.  \"What's wrong with a ceremony of worship, if you must worship your eggshell?\" Dave asked.", "hypothesis": "Eggshell worship is the reason we're growing too weak to fight the Satheri, yet Dave asked about it.", "generated_explanations": [["The context implies that a ceremony of worship (implied to be eggshell worship) is named as a reason for growing weak, supporting the claim that eggshell worship is connected to weakness in fighting the Satheri.", "e", "validated"], ["Dave's question about what is wrong with worshipping the eggshell directly references the idea, indicating he is addressing the mentioned practice.", "e", "validated"], ["The context states eggshell worship is \"one of the reasons,\" not the sole reason, so the statement's implication that eggshell worship is the reason is not determinable.", "n", "validated"], ["The context does not clarify if Dave's question occurs before or after the group's recognition of weakness, making the sequence of events between eggshell worship being identified as a cause and Dave asking about it undetermined.", "n", "validated"], ["The context does not establish a direct causal link between eggshell worship and the group's weakness beyond it being a contributing factor, leaving the extent of its influence ambiguous.", "n", "validated"], ["The context states that eggshell worship is only \"one of the reasons\" for weakness, not the sole or definitive reason as implied by the statement.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "100895c", "premise": "Is there adequate information for judging generalizability?", "hypothesis": "Every output has some kind of resource.", "generated_explanations": [["The statement explicitly mentions \"every output,\" indicating universality, and by stating \"has some kind of resource,\" it encompasses all outputs without exception, implying generalizability within the context provided.", "e", "not_validated"], ["The context does not specify what constitutes a \"resource,\" leaving ambiguity about whether every output indeed meets this criterion.", "n", "validated"], ["The context does not describe what is meant by \"output,\" making it unclear if all outputs fall under the domain being discussed.", "n", "validated"], ["There is no information provided about the relationship between outputs and resources, so it cannot be determined if every output has a resource.", "n", "validated"], ["The context lacks details or examples to assess whether the statement universally applies.", "n", "validated"], ["The context only asks whether there is adequate information for judging generalizability and does not mention outputs or resources, so there is no basis to assert that every output has some kind of resource.", "c", "validated"], ["The statement introduces the concept of \"outputs\" and \"resources,\" which are not referenced or implied in the context, making the statement unsupported.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 4, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "837n", "premise": "The central features of the Results Act-strategic planning, performance measurement, and public reporting and accountability-can serve as powerful tools to help change the basic culture of government.", "hypothesis": "The Results Act has strategic planning as a central feature for public organizations.", "generated_explanations": [["The context explicitly states that strategic planning is one of the central features of the Results Act.", "e", "validated"], ["The context indicates that these central features, including strategic planning, are intended for use in government, which includes public organizations.", "e", "validated"], ["The context mentions strategic planning as a central feature of the Results Act for government, but it does not explicitly state that this applies specifically to all public organizations.", "n", "validated"], ["The context discusses the potential of the Results Act to influence “the basic culture of government” generally, but it does not specify whether public organizations beyond government entities are included.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "140005c", "premise": "3 It should be noted that the toxicity (LC50) of a sample observed in a range-finding test may be significantly different from the toxicity observed in the follow-up chronic definitive test  (1) the definitive test is longer; and (2) the test may be performed with a sample collected at a different time, and possibly differing significantly in the level of toxicity.", "hypothesis": "The toxicity of a sample in the range-finding test will be exactly the same as the toxicity in the follow-up test.", "generated_explanations": [["The duration of the definitive test is longer, which could lead to different observed toxicity outcomes.", "n", "validated"], ["The sample used in the definitive test might be collected at a different time, meaning its toxicity could differ significantly from the sample used in the range-finding test.", "n", "validated"], ["The duration of the definitive test is longer, which can affect toxicity results.", "c", "validated"], ["The sample used in the follow-up test may be collected at a different time and could have a different level of toxicity.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "38475c", "premise": "In 1984, Clinton picked up rock groupie Connie Hamzy when she was sunbathing in a bikini by a hotel pool.", "hypothesis": "Clinton kept her friends and relationships private in the 80s.", "generated_explanations": [["The context mentions a specific interaction between Clinton and Connie Hamzy but does not provide information about whether Clinton kept his friends and relationships private in general during the 80s.", "n", "validated"], ["The context does not clarify if this incident was public knowledge at the time or only revealed later, leaving ambiguity about his level of privacy concerning relationships.", "n", "validated"], ["The context refers to a single event and does not account for Clinton's overall behavior with all friends and relationships in the 80s.", "n", "validated"], ["The context describes Clinton engaging with Connie Hamzy in a public setting by a hotel pool, which is not private.", "c", "validated"], ["The incident involved a well-known rock groupie, making the interaction more likely to become public knowledge.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "141293e", "premise": "oh wow no i just started about well five years ago i think", "hypothesis": "It had started five years ago.", "generated_explanations": [["The speaker says they \"just started about well five years ago,\" indicating the starting point was five years ago.", "e", "validated"], ["The use of \"started\" in the context aligns with the statement that something began five years in the past.", "e", "validated"], ["The context says \"i just started about well five years ago i think,\" which expresses uncertainty about the exact timing.", "n", "validated"], ["The context refers to the speaker starting an activity, but \"it had started\" could ambiguously refer to something else, not necessarily what the speaker is talking about.", "n", "validated"], ["The speaker says they \"just started\" about five years ago, suggesting five years ago was the beginning, not that \"it had started\" (which refers to an earlier point in the past before another past event).", "c", "validated"], ["The phrasing \"I think\" indicates uncertainty about the exact timing, so it is not definite that it specifically started five years ago.", "c", "validated"], ["The statement uses passive voice, implying something else started the event, while the context directly attributes the starting to the speaker (\"I just started\").", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "30139n", "premise": "oh that's not really important the the other stuff is just you know window dressing because we we've never ordered anything fact the the van that we've got we bought uh from an estate it was an estate trade uh it was almost brand new the the gentlemen who owned it had died", "hypothesis": "We were very lucky to get the van given how new it was.", "generated_explanations": [["The van was almost brand new when purchased.", "e", "validated"], ["The opportunity to buy the van arose due to the previous owner's death, which is an uncommon circumstance.", "e", "validated"], ["It is generally unusual to find a nearly new van for sale from an estate trade.", "e", "validated"], ["The context mentions the van was almost brand new and obtained from an estate, but does not specify whether luck played a role in acquiring it.", "n", "validated"], ["The process or circumstances of acquiring the van (aside from buying it from an estate) are not described, so it is unclear if obtaining it was considered fortunate.", "n", "validated"], ["The context does not mention luck as a factor in obtaining the van; it only states the circumstances of the purchase (from an estate after the owner's death).", "c", "validated"], ["The context implies the van was available for purchase due to the previous owner's death, not due to luck.", "c", "validated"], ["There is no indication that acquiring a nearly new van under these circumstances was rare or unexpected, which would be needed to attribute the acquisition to luck.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "30380c", "premise": "The NYT , in its front-page coverage, says the plane was flying far lower than the rules for training missions allow.", "hypothesis": "The NYT reported that training missions did allow for planes to fly that low.", "generated_explanations": [["The context does not specify whether the NYT mentioned the training mission rules themselves, only that it reported the plane was flying lower than allowed.", "n", "validated"], ["The statement claims the NYT reported something permissive, but the context only describes a violation, not the explicit rules.", "n", "validated"], ["The NYT reported the opposite: that the plane was flying below the altitudes allowed by training mission rules.", "c", "validated"], ["The context indicates there was a violation of regulations, not permission, regarding flight altitude.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "22436n", "premise": "1 Now that each unit is fully staffed, the LSC Office of Program Performance and its state planning team contain over 260 years of experience in LSC-funded programs.", "hypothesis": "The LSC has over 260 years of experience with their lawyers.", "generated_explanations": [["The LSC Office of Program Performance and its state planning team, now fully staffed, collectively have over 260 years of experience in LSC-funded programs, and it is reasonable to infer that these personnel are lawyers or include lawyers, given the legal context.", "e", "validated"], ["The context specifies that the combined experience is within the LSC Office of Program Performance and its state planning team, but does not clarify whether all members are lawyers.", "n", "validated"], ["The context refers to experience in LSC-funded programs, not explicitly to legal practice or experience specific to lawyers.", "n", "validated"], ["It is possible that some of the experience attributed includes non-lawyer roles (e.g., administrators, program managers) within the teams.", "n", "validated"], ["The 260 years of experience refers to the combined experience of the LSC Office of Program Performance and its state planning team, not specifically to the LSC’s lawyers.", "c", "validated"], ["The context does not mention that the 260 years of experience is specifically legal or related solely to lawyers; it may include experience in other roles or functions within LSC-funded programs.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "76037n", "premise": "You did, didn't you?\"", "hypothesis": "You didn't mean to do that, did you?", "generated_explanations": [["The context suggests a follow-up to an action, and the statement directly questions the intention behind that action.", "e", "not_validated"], ["Both the context and the statement use tag questions to address uncertainty or seek confirmation regarding someone's actions and intent.", "e", "not_validated"], ["The context (\"You did, didn't you?\") assumes an action was taken, and the statement (\"You didn't mean to do that, did you?\") implies that while the action occurred, the intent behind it might have been accidental, which aligns with someone reflecting on what just happened.", "e", "not_validated"], ["The context only confirms that the person did something, but gives no information about their intent or whether it was accidental or deliberate.", "n", "validated"], ["The statement asks about intention, which is not addressed or implied by the context.", "n", "validated"], ["The question format in both context and statement leaves ambiguity regarding the speaker’s assumptions and the actual situation.", "n", "validated"], ["The context suggests the person did do the action, while the statement questions whether they intended to do it, focusing on intention rather than the act itself.", "c", "not_validated"], ["The context asserts the action was performed, but the statement implies uncertainty about intention, introducing doubt not present in the context.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3}, "label_set_round_2": ["n"], "error": ["c", "e"], "not_validated_exp": {"e": 3, "c": 2}}
{"id": "28456n", "premise": "A clean, wholesome-looking woman opened it.", "hypothesis": "The woman was trying to be desecrate.", "generated_explanations": [["The context describes the woman's appearance but provides no information about her intentions or behavior.", "n", "validated"], ["The adjective \"desecrate\" usually refers to treating something sacred with disrespect, but there is no mention of any sacred object or disrespectful action in the context.", "n", "validated"], ["\"Desecrate\" means to treat something sacred with disrespect, and there is no indication in the context that the woman's actions involved any disrespect or treatment of something sacred.", "c", "validated"], ["The description of the woman as \"clean\" and \"wholesome-looking\" suggests behavior that is respectful or pure, which contradicts the idea of being desecrating.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "46198c", "premise": "How effectively DOD manages these funds will determine whether it receives a good return on its investment.", "hypothesis": "The DOD is certain to have a bad return on these funds.", "generated_explanations": [["The context indicates that the outcome depends on how effectively the DOD manages the funds, so the statement's certainty about a bad return is not supported.", "n", "validated"], ["The effectiveness of fund management by the DOD is not specified, so the predicted outcome (bad return) cannot be determined.", "n", "validated"], ["The context states that the effectiveness of management will determine the return, so the outcome is not predetermined.", "c", "validated"], ["The context does not claim or imply certainty of a bad return; the possibility of a good return is mentioned.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "100136e", "premise": "Challenges to Restore Public Confidence in", "hypothesis": "Public confidence can be difficult to reestablish.", "generated_explanations": [["The context highlights challenges, indicating that efforts to restore public confidence face significant obstacles.", "e", "validated"], ["The existence of challenges implies that reestablishing public confidence is not straightforward or easy.", "e", "validated"], ["The need to restore confidence suggests it has been lost, and regaining lost trust is inherently difficult.", "e", "validated"], ["The context does not specify whether public confidence has actually been difficult or easy to reestablish.", "n", "validated"], ["The context only introduces the notion of \"challenges\" without quantifying their severity or the resulting difficulty.", "n", "validated"], ["There is no information in the context about previous attempts and their levels of success or failure in restoring public confidence.", "n", "validated"]], "label_count_round_1": {"e": 3, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 3, "n": 3}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "24103n", "premise": "if the United States had used full conventional power.", "hypothesis": "The United States is unable to maximize their potential.", "generated_explanations": [["The statement implies the United States did not use its full conventional power, so the context suggests it did not reach its maximum potential.", "e", "validated"], ["By referencing an unrealized scenario (if the United States had used full power), the context shows the United States restrained itself and therefore did not maximize its capabilities.", "e", "validated"], ["The context hypothesizes about a scenario where the United States did use full conventional power, but does not provide information about the actual capabilities or limitations of the United States in maximizing their potential.", "n", "validated"], ["The statement refers to a general inability to maximize potential, while the context is about a specific hypothetical military action, so the broader claim about potential is not addressed.", "n", "validated"], ["The context suggests the United States had the capability to use full conventional power, indicating they were able to maximize their potential.", "c", "validated"], ["The use of \"if\" implies it was possible for the United States to use full conventional power, contradicting the statement that they are unable to maximize their potential.", "c", "validated"], ["The context considers a hypothetical maximizing scenario, which would not be possible if the United States were truly unable to maximize their potential.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "142729c", "premise": "What Ellison is doing here, as Hemingway did, is equating the process of becoming an artist with that of becoming a man.", "hypothesis": "Ellison and Hemingway took different ways to compare becoming a man.", "generated_explanations": [["The context only states that both Ellison and Hemingway equated becoming an artist with becoming a man, but it does not specify whether they used the same or different methods in making this comparison.", "n", "validated"], ["There is no information given about the specific approaches each author used to make the comparison, so it is not possible to determine if their ways were the same or different.", "n", "validated"], ["The context states that both Ellison and Hemingway equate the process of becoming an artist with that of becoming a man, indicating they used the same way to make the comparison, not different ways.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "96516e", "premise": "As Ben Yagoda writes in the New York Times Book Review , somewhere along the way, Kidder must have decided not to write a book about Tommy O'Connor.", "hypothesis": "A book was not written about Tommy O'Connor.", "generated_explanations": [["It is stated that Kidder decided not to write a book about Tommy O'Connor, implying that such a book was never written.", "e", "validated"], ["The context says Kidder decided not to write a book about Tommy O'Connor, but it does not confirm whether anyone else wrote a book about him.", "n", "validated"], ["The context does not confirm whether Kidder’s decision was final or if he possibly changed his mind later.", "n", "validated"], ["The context does not exclude the possibility that a partial or unpublished book exists about Tommy O'Connor.", "n", "validated"], ["The statement only says that Kidder decided not to write a book about Tommy O'Connor, but it does not confirm whether a book about Tommy O'Connor was written by someone else.", "c", "validated"], ["The phrasing \"must have decided not to write\" indicates intention or decision, but does not guarantee the outcome; it is possible the book was written despite the decision.", "c", "validated"], ["The statement conflates the author's decision with the actual existence of a book, but the context does not rule out the possibility that a book exists through other means or authors.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "52761e", "premise": "My unborn children will never appear on the Today show.", "hypothesis": "No direct descendent of mine will ever be a guest of the Today show.", "generated_explanations": [["\"Unborn children\" refers to the speaker's direct descendants, so if they will never appear on the Today show, then no direct descendant will ever be a guest.", "e", "validated"], ["To be a guest of the Today show entails appearing on the show, so if the speaker's unborn children will never appear, they will never be guests.", "e", "validated"], ["The context only refers to unborn children, whereas the statement includes all direct descendants (e.g., currently living children, grandchildren), so the status of other direct descendants remains unknown.", "n", "validated"], ["The context specifies \"appear\" but does not clarify whether this includes being a \"guest,\" as mentioned in the statement, so the roles or forms of appearance may differ.", "n", "validated"], ["The statement extends beyond unborn children to all direct descendants, but the context only mentions unborn children, leaving open the possibility that other direct descendants could appear on the show.", "c", "validated"], ["Being a guest of the Today show is a broader condition than simply appearing on the show; the context only rules out appearances, not necessarily being a guest in other capacities.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "21297n", "premise": "He was crying like his mother had just walloped him.", "hypothesis": "He was crying like his mother hit him with a spoon.", "generated_explanations": [["Being \"walloped\" commonly implies being struck, which can include being hit with an object such as a spoon.", "e", "validated"], ["The comparison \"crying like his mother had just walloped him\" conveys intense crying due to being hit, which aligns with the idea of being hit with a spoon.", "e", "validated"], ["Both statements suggest a scenario where the mother is the cause of the crying through physical action.", "e", "validated"], ["The context mentions \"walloped\" but does not specify the object used, so it's unclear if a spoon was involved.", "n", "validated"], ["\"Walloped\" could refer to any form of hitting or punishment, not necessarily with a spoon.", "n", "validated"], ["The comparison is figurative and may not describe an actual event involving a spoon.", "n", "validated"], ["The context states he was crying as if his mother had \"walloped\" him, which implies a strong or forceful action, whereas being hit with a spoon may not carry the same level of severity or force.", "c", "validated"], ["The term \"walloped\" does not specify the object used, so assuming a spoon was involved is not supported by the context.", "c", "validated"], ["\"Walloped\" can refer to being struck in a variety of ways, not limited to being hit with a spoon; substituting \"hit him with a spoon\" makes a specific assumption absent from the context.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "98487c", "premise": "Julius nodded gravely.", "hypothesis": "Julius loves to ask questions.", "generated_explanations": [["The context does not mention anything about Julius's habits or preferences regarding asking questions.", "n", "validated"], ["Nodding gravely could indicate a wide range of emotions or responses, none of which necessarily relate to curiosity or a tendency to ask questions.", "n", "validated"], ["Nothing in the context indicates that Julius asks questions.", "c", "validated"], ["Nodding gravely suggests a demeanor of seriousness or agreement, not curiosity or inquisitiveness.", "c", "not_validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "17179n", "premise": "Lie back, and DON'T THINK.", "hypothesis": "Lie back, and do not use your crazy mind.", "generated_explanations": [["\"Don't think\" implies refraining from mental activity, which aligns with \"do not use your mind.\"", "e", "validated"], ["The phrase \"crazy mind\" could refer to the chaotic thoughts one tries to avoid by not thinking.", "e", "validated"], ["Both the context and statement instruct lying back and not engaging in mental processes.", "e", "validated"], ["The context advises not to think, but does not specify whether all mental activity, including imagination or creativity (\"crazy mind\"), should be avoided.", "n", "validated"], ["The term \"crazy mind\" in the statement is ambiguous and not clarified or referenced in the context, so it is unclear if \"thinking\" as mentioned in the context includes what is meant by \"crazy mind.\"", "n", "validated"], ["The context says \"DON'T THINK,\" but the statement expands this to \"do not use your crazy mind,\" introducing the notion of the mind being \"crazy,\" which is not mentioned or implied in the context.", "c", "validated"], ["\"DON'T THINK\" instructs not to think, but \"do not use your crazy mind\" suggests not using the mind at all, which is a broader and different restriction.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "132539e", "premise": "Boca da Corrida Encumeada (moderate; 5 hours): views of Curral das Freiras and the valley of Ribeiro do Poco.", "hypothesis": "Boca da Corrida Encumeada is a moderate text that takes 5 hours to complete.", "generated_explanations": [["The context refers to \"Boca da Corrida Encumeada\" as a route or trail, not a \"text,\" so it is unclear if the \"moderate text\" in the statement is referring to the same thing.", "n", "validated"], ["The duration of 5 hours in the context is associated with an activity (likely hiking), not with reading or completing a text, so it is undetermined whether the statement correctly describes the duration of completing a text.", "n", "validated"], ["Boca da Corrida Encumeada refers to a hiking route or location, not a text.", "c", "validated"], ["\"Takes 5 hours to complete\" applies to an activity or journey, not to reading or completing a text.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "23642n", "premise": "The second half of the book dealt with the use of the true name.", "hypothesis": "The first part dealt with the use of false names.", "generated_explanations": [["The context does not specify what the first part of the book dealt with, so it is unknown whether it discussed false names or something else.", "n", "validated"], ["The fact that the second half is about the true name does not imply the first part is necessarily about false names—it could have covered other topics related or unrelated to names.", "n", "validated"], ["There is no information given about the content of the first part of the book, so we cannot assume it dealt with the use of false names.", "c", "validated"], ["The context only specifies that the second half focused on true names, not that there is a contrast involving false names in the first half.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "84781e", "premise": "By coordinating policy development and awareness activities in this manner, she helps ensure that new risks and policies are communicated promptly and that employees are periodically reminded of existing policies through means such as monthly bulletins, an intranet web site, and presentations to new employees.", "hypothesis": "She can find new risks with the awareness campaign.", "generated_explanations": [["Regular communication with employees through awareness campaigns may prompt employees to report risks they encounter, thereby helping her identify new risks.", "e", "validated"], ["Engagement with employees via presentations and bulletins can reveal gaps in current policies or uncover risks that have not been previously documented.", "e", "validated"], ["Feedback mechanisms associated with awareness activities, such as responses to bulletins or intranet posts, can provide information about emerging risks.", "e", "validated"], ["The context describes her role in communicating and reminding employees about risks and policies but does not specify whether the awareness campaign itself enables her to discover or find new risks.", "n", "validated"], ["It is unclear from the context whether the process of running awareness campaigns directly results in the identification of new risks, as opposed to simply communicating identified risks.", "n", "validated"], ["The context describes her role as communicating and reminding employees about risks and policies, not discovering or identifying new risks.", "c", "validated"], ["The awareness campaign is focused on dissemination of information rather than the detection of previously unknown risks.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "15771c", "premise": "or just get out and walk uh or even jog a little although i don't do that regularly but Washington's a great place to do that", "hypothesis": "\"I regularly go for a walk or a jog at Washington's.\"", "generated_explanations": [["The context mentions walking or jogging in Washington, but clarifies that jogging is not done regularly, and does not specify if walking is done regularly, making the regularity of either activity undetermined.", "n", "validated"], ["The statement refers to \"Washington's,\" which could imply a specific location or possessive form, while the context refers to \"Washington\" as a place in general, creating ambiguity about whether they refer to the same place.", "n", "validated"], ["The speaker explicitly states that they do not jog regularly.", "c", "validated"], ["The statement implies regularity in both walking and jogging, but the context only mentions walking as an occasional option and jogging as something not done regularly.", "c", "validated"], ["There is no mention in the context of a location called \"Washington's\"; the speaker refers to \"Washington\" as a place, not as a possessive location (\"Washington's\").", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "134655c", "premise": "Catch up on the Indian avant-garde and the bohemian people of Caletta at the Academy of Fine Arts on the southeast corner of the Maidan.", "hypothesis": "The Academy of Fine Arts is located in Northern Maidan.", "generated_explanations": [["The context specifies the Academy of Fine Arts is on the southeast corner of the Maidan, but does not provide information about the location of \"Northern Maidan,\" so the spatial relationship between the southeast corner and the north of the Maidan is unclear.", "n", "validated"], ["The context does not define the boundaries or extent of the Maidan, so it is undetermined whether the southeast corner can also be considered as part of the northern region.", "n", "validated"], ["The context states that the Academy of Fine Arts is on the southeast corner of the Maidan, not in the northern part.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "33822n", "premise": "Why shouldn't he be?", "hypothesis": "He doesn't actually want to be that way.", "generated_explanations": [["He shouldn't be that way because he doesn't genuinely desire to be that way.", "e", "not_validated"], ["The context questions why he shouldn't be a certain way, but provides no information about his desires or motivations.", "n", "validated"], ["The statement introduces the idea that he doesn't want to be that way, but there is no evidence in the context to support or contradict this claim.", "n", "validated"], ["The context questions the reason for any doubt (\"Why shouldn't he be?\"), which implies there is no evidence against him wanting to be that way; the statement asserts he does not want to be that way, which contradicts the context's implication.", "c", "validated"], ["There is no information in the context about his desires or intentions, so the statement introduces a claim not supported by the context.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "125021c", "premise": "Other functional components of the Postal Service are presumed here not to exhibit significant scale economies, although this has not been demonstrated.", "hypothesis": "The Postal Service only operates very large scale economies.", "generated_explanations": [["The context states that only some components of the Postal Service may exhibit scale economies, and for other components, it is merely presumed they do not, without definitive evidence.", "n", "validated"], ["The context does not claim that the entire Postal Service, or only large-scale economies, are at play; it discusses some components and a lack of demonstrated evidence for others.", "n", "validated"], ["The context states that only some components of the Postal Service are presumed not to have significant scale economies, not that only very large scale economies exist.", "c", "validated"], ["The statement asserts exclusivity (\"only\"), which is not supported by the context.", "c", "validated"], ["The context does not confirm the existence of \"very large scale economies,\" only that it has not been demonstrated for some components.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "133005n", "premise": "In May 1967, Gallup found that the number of people who said they intensely disliked RFK--who was also probably more intensely liked than any other practicing politician--was twice as high as the number who intensely disliked Johnson, the architect of the increasingly unpopular war in Vietnam.", "hypothesis": "Due to his attitudes on cheesecake, RFK was more disliked than Johnson.", "generated_explanations": [["The context does not mention RFK's attitudes on cheesecake or connect his level of dislike to this topic, so it is unknown whether his attitudes on cheesecake had any influence on people disliking him.", "n", "validated"], ["The reason given in the context for people's dislike of RFK is not specified; the context only provides comparative dislike statistics without attributing them to specific factors such as his attitudes on cheesecake.", "n", "validated"], ["The context attributes RFK's higher dislike to factors other than his attitudes on cheesecake, specifically his political persona and actions, not his views on cheesecake.", "c", "validated"], ["There is no mention or evidence in the context regarding RFK's attitudes toward cheesecake or their impact on public opinion.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "65650e", "premise": "She didn't listen.", "hypothesis": "She did not listen to the noise.", "generated_explanations": [["The statement \"She did not listen to the noise\" is consistent with the context \"She didn't listen\" because not listening to anything, including noise, is implied by not listening in general.", "e", "validated"], ["The context does not specify what she didn't listen to, so it is unclear whether it refers to \"the noise\" or something else.", "n", "validated"], ["The statement introduces \"the noise,\" which is not mentioned or implied in the context, leading to uncertainty about whether they refer to the same thing.", "n", "validated"], ["The context does not specify what she did not listen to, so it is possible she did not listen to something other than noise.", "c", "validated"], ["The statement adds \"the noise,\" introducing a specific object that is not mentioned in the context.", "c", "not_validated"], ["She might have listened to the noise but ignored something else, so the statement could be inaccurate.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "3545n", "premise": "Several of the organizations had professional and administrative staffs that provided analytical capabilities and facilitated their members' participation in the organization's activities.", "hypothesis": "Organizations had mandatory bonding exercises for their members.", "generated_explanations": [["The context does not mention bonding exercises or any similar activities.", "n", "validated"], ["The context only discusses professional and administrative staff functions related to analysis and facilitation, not social or team-building requirements.", "n", "validated"], ["There is no information about whether participation in activities was mandatory or voluntary.", "n", "validated"], ["The context mentions analytical and facilitative roles of staff but provides no information about mandatory bonding exercises.", "c", "validated"], ["There is no indication in the context that participation in bonding exercises was required for members.", "c", "validated"], ["The focus of the context is on administrative and professional support, not on social or team-building activities.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "105196n", "premise": "Indeed, said San'doro.", "hypothesis": "They were certain.", "generated_explanations": [["San'doro's affirmative response (\"Indeed\") indicates agreement or confirmation with something previously stated, suggesting certainty.", "e", "validated"], ["The use of \"Indeed\" typically reinforces or emphasizes the truth of a prior assertion, implying a state of certainty shared by those involved.", "e", "not_validated"], ["The context does not specify who \"they\" refers to or whether anyone was certain.", "n", "validated"], ["The statement \"Indeed, said San'doro\" only indicates an agreement or affirmation from San'doro, not certainty from any group.", "n", "validated"], ["No information is provided about anyone's level of certainty.", "n", "validated"], ["The word \"Indeed\" does not necessarily indicate certainty; it can simply mean agreement or acknowledgment.", "c", "validated"], ["There is no explicit mention in the context that they were certain.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "144753e", "premise": "When he's ready for a major strike, how many innocents do you suppose are going to suffer? To quote one of your contemporaries; 'The needs of the many outweigh the needs of the few.' '", "hypothesis": "If he does a big strike, many people will suffer.", "generated_explanations": [["The context asks how many innocents will suffer if a major strike is carried out, implying that such an event will cause suffering to many people.", "e", "validated"], ["The reference to \"the needs of the many outweigh the needs of the few\" suggests that many people are at risk, reinforcing that a big strike would affect a large number of individuals.", "e", "validated"], ["The context presents a rhetorical question about how many innocents will suffer but does not confirm that a big strike will actually occur or specify the number of people who would suffer.", "n", "validated"], ["The quotation about \"the needs of the many\" provides a moral perspective but does not offer factual information about whether or how many will suffer if a strike happens.", "n", "validated"], ["The context poses a rhetorical question and does not assert as fact that a major strike will occur or that many will suffer; it's speculative.", "c", "validated"], ["The speaker is quoting another person to make a moral or philosophical point rather than stating a literal expectation of suffering.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "114458e", "premise": "Mortifyingly enough, it is all  the difficulty, the laziness, the pathetic formlessness in youth, the round peg in the square hole, the whatever do you want?", "hypothesis": "Many youth are lazy.", "generated_explanations": [["The context explicitly mentions \"the laziness...in youth,\" directly attributing laziness to youth.", "e", "validated"], ["The context mentions \"the laziness\" in youth, but it is unclear whether this applies to many youth generally or just a particular instance or subgroup.", "n", "validated"], ["The context uses a personal and subjective tone, possibly describing an individual's experience rather than making a generalization about many youth.", "n", "validated"], ["The context refers to \"the laziness\" as one of several qualities or problems in youth, but does not imply that many youth are lazy.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "49237c", "premise": "'You burned down my house.'", "hypothesis": "'Even though you tried to burn it down, my house is in perfect state.'", "generated_explanations": [["The context only states that the house was burned down, but does not mention any attempt or failure—so it is unclear whether there was merely an attempt or a successful burning.", "n", "validated"], ["There is no information in the context about the current state of the house, so it is not possible to determine if the house is in perfect state or not.", "n", "validated"], ["The context indicates that the house was actually burned down, contradicting the statement that it is in perfect state.", "c", "validated"], ["The statement claims only an attempt was made, while the context asserts the act was completed.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "70047c", "premise": "What about the hole?\" They scanned the cliff-side narrowly.", "hypothesis": "They looked from the top of the cliff for the hole.", "generated_explanations": [["Scanning the cliff-side narrowly suggests a careful visual search, which could logically occur from the top of the cliff for a better vantage point.", "e", "not_validated"], ["The mention of \"the hole\" implies the object of their search, and scanning the cliff-side would likely involve looking for it from an elevated position such as the top.", "e", "not_validated"], ["The context does not specify the location from which they scanned the cliff-side, so it is unclear whether they were at the top of the cliff.", "n", "validated"], ["The context does not indicate whether their scanning was specifically for the hole or for something else.", "n", "validated"], ["The context states they scanned the cliff-side, not that they looked from the top of the cliff.", "c", "validated"], ["There is no information indicating their location was at the top of the cliff.", "c", "validated"], ["Scanning the cliff-side could involve examining the side or another vantage point, not necessarily from the top.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "137319n", "premise": "And she came to you?", "hypothesis": "The person asked if the woman came to him.", "generated_explanations": [["The context is a question about whether a woman came to \"you,\" which matches the statement describing someone asking if the woman came to him.", "e", "validated"], ["\"She\" in the context refers to \"the woman\" in the statement.", "e", "validated"], ["The act of asking described in the statement corresponds to the conversational question in the context.", "e", "not_validated"], ["The context only states that \"she came to you,\" but it does not mention whether anyone asked if this happened.", "n", "validated"], ["The context does not specify who is speaking or receiving, so it's unclear if there was a question about the woman's actions.", "n", "validated"], ["The context makes a statement, but the target statement refers to a question being asked, and there is no information about any question in the context.", "n", "validated"], ["The context states that she came to him, indicating it is a fact, not a question.", "c", "validated"], ["The context describes an event, not a question being asked.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "63013n", "premise": "Although claims data provide the most accurate information about health care use, ensuring adequate follow-up for purposes of obtaining information from patient self-report is important because many people do not report alcohol-related events to insurance compa-nies.", "hypothesis": "The insurance companies want to reduce medical payments by following-up to ensure patient was sober at the time of incident and intoxication may lead to a claim denial on reimbursement for medical expenses.", "generated_explanations": [["Insurance companies may deny claims for medical expenses if the patient was intoxicated at the time of the incident, as intoxication could be an exclusion in the insurance policy.", "e", "not_validated"], ["Insurance companies have a financial incentive to verify sobriety during incidents to reduce their payouts by denying claims related to alcohol intoxication.", "e", "not_validated"], ["Patient self-report follow-up is important because alcohol-related incidents may not be reported to insurance companies, potentially allowing patients to avoid claim denials related to intoxication.", "e", "not_validated"], ["Ensuring adequate follow-up helps insurance companies detect cases where intoxication could affect the validity of a claim, supporting their goal of minimizing unnecessary reimbursements.", "e", "not_validated"], ["The context does not specify the motivations of insurance companies regarding follow-up or claim denials.", "n", "validated"], ["There is no information in the context about insurance companies using follow-up to ensure sobriety at the time of incidents.", "n", "validated"], ["The context does not indicate that intoxication leads to claim denial or affects reimbursement for medical expenses.", "n", "validated"], ["The context discusses the importance of patient self-report for obtaining information about alcohol-related events that are not reported to insurance companies, not about insurance companies seeking to follow up for claim denial purposes.", "c", "validated"], ["There is no mention in the context of insurance companies conducting follow-ups to determine sobriety at the time of the incident.", "c", "validated"], ["The context does not state or imply that insurance companies use intoxication as a basis for denying medical expense reimbursement.", "c", "validated"]], "label_count_round_1": {"e": 4, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 4}}
{"id": "79507e", "premise": "An organization's activities, core processes, and resources must be aligned to support its mission and help it achieve its goals.", "hypothesis": "An organization is successful if its activities, resources, and goals align.", "generated_explanations": [["Alignment of activities, resources, and goals enables the organization to efficiently work towards its mission, increasing the likelihood of success.", "e", "validated"], ["When resources are dedicated to goals and activities that support the mission, the organization's efforts are focused and effective, facilitating achievement.", "e", "validated"], ["Misalignment often leads to wasted efforts and inefficiencies, so ensuring alignment is a key factor in organizational success as per the context.", "e", "validated"], ["The context states that alignment is necessary to support the mission and achieve goals but does not guarantee success, as other factors may be involved.", "n", "validated"], ["The statement assumes alignment alone is sufficient for success, which is not established by the context.", "n", "validated"], ["The context does not define what constitutes \"success,\" so it is unclear if alignment ensures it.", "n", "validated"], ["The context suggests alignment is supportive but not exclusively determinative of outcomes.", "n", "validated"], ["Alignment of activities, resources, and goals does not guarantee success, as external factors (such as market conditions, competition, and regulation) can still lead to failure.", "c", "validated"], ["Organizational success also depends on the effectiveness and quality of execution, not just alignment.", "c", "validated"], ["Misaligned stakeholder interests or lack of support from leadership and employees can undermine success even if alignment exists on paper.", "c", "validated"], ["Unforeseen crises or risks (such as natural disasters or financial shocks) can prevent success regardless of alignment.", "c", "validated"], ["The organization's definition of success may involve metrics or outcomes that aren't achieved solely through internal alignment.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 5}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 4, "c": 5}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "121910e", "premise": "If ancient writings give only a romanticized view, they do offer a more precise picture of Indo-Aryan society.", "hypothesis": "Ancient writings don't show an accurate picture of Indo-Anryan society.", "generated_explanations": [["The context claims that ancient writings offer a more precise picture, but also mentions their romanticized nature, leaving it unclear whether \"precise\" equates to \"accurate\" or if some distortions persist.", "n", "validated"], ["The definition of \"precise\" in the context could differ from \"accurate,\" making it unclear whether the writings truly reflect the society's reality.", "n", "validated"], ["The degree to which the romanticized aspect affects the accuracy of the depiction is not explicitly stated.", "n", "validated"], ["\"Don't show an accurate picture\" directly contradicts the statement that they offer a \"more precise picture,\" but the context does not clarify whether \"more precise\" is sufficient for being considered \"accurate.\"", "n", "validated"], ["The context states that ancient writings offer a more precise picture of Indo-Aryan society, contradicting the statement that they don't show an accurate picture.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "120323n", "premise": "In the original, Reich is set up by his host and then ambushed by a hostile questioner named John, and when he tries to answer with an eloquent Mr. Smith speech (My fist is clenched.", "hypothesis": "Reich's host is out to get him.", "generated_explanations": [["Reich's host sets him up, which implies intentional harm or betrayal towards Reich.", "e", "validated"], ["The host arranges for Reich to be ambushed by a hostile questioner, indicating a deliberate plan against Reich's interests.", "e", "validated"], ["The context states that Reich is set up by his host, but it does not provide details about the host's intentions; \"set up\" could mean arranging an event rather than acting with malicious intent.", "n", "validated"], ["Being ambushed by a hostile questioner does not necessarily imply that the host is acting against Reich; the host's role in the ambush is not clearly specified.", "n", "validated"], ["The statement interprets the host's actions as intentional hostility, but the context does not establish the host's motivations.", "n", "validated"], ["The context states that Reich is set up by his host, but it does not clarify if the host's motivation is to harm Reich specifically (\"out to get him\") as opposed to simply creating a situation for dramatic or interview purposes.", "c", "validated"], ["The host's actions may be part of a standard show format or procedure and not indicative of personal malice or hostile intent towards Reich.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "50480n", "premise": "But you will find it all right.\"", "hypothesis": "You, I'm sure, will find it more than adequate.", "generated_explanations": [["The phrase \"find it all right\" indicates that the item or situation in question is at least satisfactory, which aligns with the statement suggesting it is \"more than adequate.\"", "e", "not_validated"], ["Expressing confidence with \"But you will find it all right\" shows reassurance that the person addressed will have a positive or sufficient experience, supporting the stronger assertion that it will be \"more than adequate\" for them.", "e", "validated"], ["The context claims the subject will find \"it all right,\" which suggests adequacy, but the statement goes further by claiming \"more than adequate,\" so it's unclear if \"all right\" actually implies \"more than adequate.\"", "n", "validated"], ["The context does not provide enough information about the subject's standards of adequacy, making it unclear if \"all right\" would equate to \"more than adequate.\"", "n", "validated"], ["The term \"all right\" can be interpreted as merely sufficient or acceptable, which does not necessarily mean \"more than adequate,\" thus the exact level of adequacy remains undetermined.", "n", "validated"], ["The context only assures that it will be \"all right,\" which suggests adequacy or sufficiency, but not necessarily that it will be \"more than adequate.\"", "c", "validated"], ["The statement presumes a higher level of satisfaction (\"more than adequate\") than what is conveyed in the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "123027n", "premise": "uh high humidity", "hypothesis": "Warm, sweaty temperatures.", "generated_explanations": [["High humidity often makes the air feel warmer and can cause people to sweat more.", "e", "validated"], ["High humidity is associated with uncomfortable, sticky conditions that are described as warm and sweaty.", "e", "validated"], ["High humidity does not necessarily imply warmth; high humidity can occur at various temperatures, including cool environments.", "n", "validated"], ["High humidity alone does not guarantee that conditions are sweaty, as this depends on both humidity and temperature.", "n", "validated"], ["The term “sweaty temperatures” is subjective and not directly defined by the presence of high humidity.", "n", "validated"], ["High humidity does not always imply warm temperatures; it can be humid in cool environments as well.", "c", "validated"], ["The statement assumes that high humidity leads to sweating, but people sweat due to temperature and exertion, not humidity alone.", "c", "validated"], ["Humidity refers to the amount of moisture in the air, not the actual temperature.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "85279n", "premise": "The almost midtown Massabielle quarter (faubourg de Massabielle), is sometimes described as the most picturesque in the city.", "hypothesis": "The Massabielle quarter is a very touristy place.", "generated_explanations": [["Being described as the most picturesque part of the city suggests it attracts visitors interested in scenic or charming locations, which are typically popular with tourists.", "e", "not_validated"], ["The description of the Massabielle quarter as \"picturesque\" does not necessarily indicate that it is \"very touristy,\" as a place can be picturesque without attracting many tourists.", "n", "validated"], ["The context lacks information about the number of tourists or tourism-related activities in the Massabielle quarter.", "n", "validated"], ["The term \"picturesque\" refers to appearance and charm but does not provide data on popularity among tourists.", "n", "validated"], ["The context only describes the Massabielle quarter as \"picturesque\" and does not mention anything about it being touristy.", "c", "validated"], ["A place being picturesque does not necessarily imply that it is frequented by tourists.", "c", "validated"], ["The use of \"sometimes described\" suggests that its picturesque quality is subjective and not widely recognized, which may indicate it is not widely known or visited by tourists.", "c", "validated"], ["The context lacks any information about tourism, visitor numbers, or attractions that typically draw tourists.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 4}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 4}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "121360c", "premise": "The tip was hooked towards the edge, the same way the tips are hammered for knives used for slaughter.", "hypothesis": "They were fragile and could not leave a scratch.", "generated_explanations": [["The context describes the shape and crafting method of the tip but does not provide any information about the material properties or sharpness, so fragility and ability to scratch are not determined.", "n", "validated"], ["The fact that knife tips for slaughter are mentioned may imply robustness or sharpness, but it is not explicitly stated whether these particular items share those qualities or lack them.", "n", "validated"], ["Tips hammered for knives used for slaughter are designed to be strong and capable of cutting, not fragile or ineffective.", "c", "validated"], ["Knives intended for slaughter need to be sharp and durable, which contradicts the claim that they could not leave a scratch.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "56582n", "premise": "So far, however, the number of mail pieces lost to alternative bill-paying methods is too small to have any material impact on First-Class volume.", "hypothesis": "Occasionally mail is lost but not often", "generated_explanations": [["The phrase \"mail pieces lost to alternative bill-paying methods is too small\" implies that while some mail is lost, it happens infrequently.", "e", "validated"], ["The use of \"too small to have any material impact\" indicates that the loss of mail is occasional rather than common.", "e", "validated"], ["The context refers to \"mail pieces lost to alternative bill-paying methods,\" which means mail volume lost due to people choosing other payment methods, not mail physically lost. The statement refers to mail physically being lost, creating ambiguity about whether the two are referring to the same type of loss.", "n", "validated"], ["The context only comments on the volume of mail affected by alternative bill payment, not the frequency with which mail is physically lost, so it provides no information about how often mail gets lost during delivery.", "n", "validated"], ["The context discusses mail volume decreasing due to alternative bill-paying methods, not the frequency of mail being lost during delivery.", "c", "validated"], ["There is no mention in the context about mail being lost in transit; the \"lost\" refers to business being \"lost\" to alternatives, not physical loss of mailpieces.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "46650n", "premise": "The draft treaty was Tommy's bait.", "hypothesis": "Tommy took the bait of the treaty.", "generated_explanations": [["The phrase \"The draft treaty was Tommy's bait\" implies that Tommy presented the treaty as something to lure or tempt someone else, not that Tommy himself was tempted by it; therefore, there is no valid explanation for why the statement is true given the context.", "e", "validated"], ["The context indicates that Tommy set the bait, i.e., the draft treaty, but does not specify whether Tommy himself took the bait.", "n", "validated"], ["It is unclear whether \"bait\" refers to an action Tommy took or a strategy Tommy employed, leaving Tommy's role in relation to the bait ambiguous.", "n", "validated"], ["The sentence structure allows for the possibility that Tommy crafted the bait for someone else, without providing information on whether Tommy was ensnared by the bait himself.", "n", "validated"], ["Tommy is the one offering the bait (the draft treaty), not the one taking it.", "c", "validated"], ["The draft treaty is described as being used by Tommy to entice someone else, implying Tommy is not the target of the bait.", "c", "validated"], ["The statement incorrectly implies Tommy is being deceived or lured by his own bait, which contradicts the context.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "81579e", "premise": "All were prominent nationally known organizations.", "hypothesis": "The only identified organizations were well-known.", "generated_explanations": [["All identified organizations were described as prominent.", "e", "validated"], ["The organizations were nationally known, implying widespread recognition.", "e", "validated"], ["Being prominent and nationally known suggests these organizations are well-known.", "e", "validated"], ["The context states that all organizations were prominent and nationally known, but it does not confirm that these were the only identified organizations; there may have been other organizations not mentioned.", "n", "validated"], ["The statement implies exclusivity (\"only identified\"), but the context does not specify whether there were additional, unidentified organizations that may not have been well-known.", "n", "validated"], ["\"Prominent\" and \"well-known\" may not be synonymous; an organization can be prominent in certain areas or for certain achievements without being widely recognized as \"well-known.\"", "c", "not_validated"], ["The context does not specify that these were the only identified organizations, so there could have been other organizations identified that were not well-known.", "c", "validated"], ["Being \"nationally known\" does not necessarily imply being \"well-known\" to the general public; an organization could be known at the national level within specific circles but not broadly well-known.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "23414c", "premise": "Why bother to sacrifice your lives for dirt farmers and slavers?", "hypothesis": "No one cares about the dirt farmers and slaves.", "generated_explanations": [["The question implies that the lives of dirt farmers and slaves are not valued, suggesting a lack of care for them.", "e", "not_validated"], ["Referring to the beneficiaries as \"dirt farmers and slavers\" diminishes their significance and implies they are not worth the sacrifice, indicating general indifference toward their well-being.", "e", "validated"], ["The context questions the value of sacrificing lives for dirt farmers and slavers, but does not state whether anyone cares about them.", "n", "validated"], ["The statement makes an absolute claim about caring that is not directly supported or contradicted by the context.", "n", "validated"], ["The question implies that someone is being asked to make a sacrifice, which suggests that at least some people care about the dirt farmers and slaves.", "c", "validated"], ["The context acknowledges the existence and plight of dirt farmers and slaves, indicating some level of concern or consideration.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "36715e", "premise": "Jon twisted the man's wrist.", "hypothesis": "Jon grabbed the man.", "generated_explanations": [["Twisting someone's wrist typically requires grabbing their wrist or hand first, implying physical contact.", "e", "validated"], ["Twisting someone's wrist can be done without grabbing the person as a whole; it may only require gripping the wrist itself.", "n", "validated"], ["The action of twisting a wrist does not necessarily involve grabbing the entire person, only a part of their body.", "n", "validated"], ["It is possible to twist someone's wrist using an object or a maneuver that does not involve directly grabbing the man.", "n", "validated"], ["Twisting someone's wrist does not necessarily require grabbing the person as a whole; Jon could have only grabbed the man's wrist.", "c", "not_validated"], ["It is possible to twist someone's wrist without grabbing the man himself, such as by manipulating only the hand or wrist.", "c", "validated"], ["The statement assumes physical contact with the entire man, whereas the context only mentions contact with the wrist.", "c", "not_validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 2}}
{"id": "114492n", "premise": "and the same is true of the drug hangover you know if you", "hypothesis": "It's just like a drug hangover but worse.", "generated_explanations": [["The context compares an unspecified experience to a drug hangover, indicating they share similar effects.", "e", "validated"], ["The statement builds on the context by asserting the experience is not only like a drug hangover but even more intense, which aligns with the comparison made in the context.", "e", "validated"], ["The context compares something to a drug hangover but does not specify if it is worse, equal, or milder in effect.", "n", "validated"], ["The word \"same\" in the context implies equivalence, not a comparative degree of severity.", "n", "validated"], ["There is insufficient information about what aspect is being compared—whether the duration, intensity, or type of hangover is worse is not addressed.", "n", "validated"], ["The context suggests equivalence between two experiences, not that one is worse than the other.", "c", "validated"], ["The statement claims the subject is worse than a drug hangover, while the context states they are the same.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "136097n", "premise": "and going to school is also always very prohibitive now unless your parents are wealthy", "hypothesis": "Wealthy parents are necessary for school.", "generated_explanations": [["The context states that going to school is \"very prohibitive now unless your parents are wealthy,\" implying that only children with wealthy parents can afford to attend school, making wealthy parents a necessity for schooling.", "e", "validated"], ["The context states that school is \"very prohibitive\" unless parents are wealthy, implying that lack of wealth makes attending school difficult but not strictly impossible, so it does not establish necessity.", "n", "validated"], ["The phrase \"unless your parents are wealthy\" allows for the possibility of rare exceptions (e.g., scholarships, financial aid) that would enable non-wealthy students to attend school, which means wealthy parents may not be strictly required.", "n", "validated"], ["The context states that school is \"very prohibitive\" unless your parents are wealthy, which implies it is possible (though difficult) to attend school without wealthy parents, so wealthy parents are not strictly necessary.", "c", "validated"], ["The term \"necessary\" in the statement suggests an absolute requirement, while the context only indicates a strong barrier, not an absolute one.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "101253c", "premise": "In his effort to build nationalism across Turkey in the 1920s, Ataterk instituted a campaign to suppress Kurdish identity that continues today.", "hypothesis": "In 1942, Ataterk tried to build nationalism in Turkey.", "generated_explanations": [["Atatürk instituted a campaign to build nationalism across Turkey in the 1920s, which included efforts that could have continued or remained in effect by 1942.", "e", "not_validated"], ["The context states Ataterk's efforts were in the 1920s, but the statement refers to 1942, and it is not specified whether he continued such efforts in that year.", "n", "validated"], ["The context does not confirm whether Ataterk was still active or alive in 1942.", "n", "validated"], ["The context does not provide specific information about Ataterk's actions or campaigns in 1942.", "n", "validated"], ["Ataturk died in 1938 and could not have tried to build nationalism in Turkey in 1942.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 1}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "97520e", "premise": "AC Green's pretty good", "hypothesis": "AC Green is also a solid player.", "generated_explanations": [["\"Pretty good\" implies a positive evaluation of AC Green’s basketball skills, which is consistent with describing him as a \"solid player.\"", "e", "validated"], ["Describing someone as \"pretty good\" suggests reliability and competence, characteristics captured by the term \"solid player.\"", "e", "validated"], ["The term \"pretty good\" is subjective and may not definitively equate to \"a solid player,\" as interpretations can vary.", "n", "validated"], ["The context does not specify the criteria for being \"solid\" or \"pretty good,\" leaving the comparison between the two terms ambiguous.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "97569e", "premise": "Candle grease?", "hypothesis": "Was it candle grease?", "generated_explanations": [["The statement is a clarifying question that repeats the context phrase with slight rephrasing, seeking confirmation about whether the substance in question is candle grease.", "e", "validated"], ["The use of the question form indicates that the speaker is directly referencing the substance mentioned in the context, showing alignment between the context and the statement.", "e", "validated"], ["Both the context and the statement refer to \"candle grease,\" making the relationship one of direct entailment or restatement as a question.", "e", "validated"], ["The context only mentions \"Candle grease?\" without providing any additional information about what is being referred to, so it is unclear whether the statement refers to the same thing as the context.", "n", "validated"], ["There is insufficient context to determine if the question is being asked in reference to an event, object, or substance, or if it is answering or clarifying something.", "n", "validated"], ["It is not specified what \"it\" refers to, so we cannot determine if \"it\" was candle grease.", "n", "validated"], ["The context itself is presented as a question, not as a declarative statement, so no factual information is given to confirm or deny the statement.", "n", "validated"], ["The context does not provide enough information to confirm that the substance in question is candle grease.", "c", "validated"], ["The use of a question in the statement indicates uncertainty, not a factual assertion, so it cannot be deemed true based on the context alone.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "23751c", "premise": "Part of the reason for the difference in pieces per possible delivery may be due to the fact that five percent of possible residential deliveries are businesses, and it is thought, but not known, that a lesser percentage of possible deliveries on rural routes are businesses.", "hypothesis": "We all know that the reason for a lesser percentage of possible deliveries on rural routes being businesses, is because of the fact that people prefer living in cities rather than rural areas.", "generated_explanations": [["The context only states that it is \"thought, but not known\" that a lesser percentage of possible deliveries on rural routes are businesses, so the premise is not established as fact.", "n", "validated"], ["The context does not provide any information or evidence about why there are fewer business deliveries on rural routes.", "n", "validated"], ["The context does not mention people's preferences for living in cities versus rural areas.", "n", "validated"], ["There may be other unmentioned factors affecting the percentage of businesses on rural routes, such as economic, infrastructure, or zoning differences.", "n", "validated"], ["It is not known, only thought, that a lesser percentage of possible deliveries on rural routes are businesses.", "c", "validated"], ["There is no evidence provided that the reason is people preferring to live in cities rather than rural areas.", "c", "validated"], ["The statement claims certainty (\"we all know\") while the context expresses uncertainty about the cause.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "103169n", "premise": "'Dave Hanson, to whom nothing was impossible.' Well, we have a nearly impossible task: a task of engineering and building.", "hypothesis": "This building job is almost impossible, even for an experienced engineer.", "generated_explanations": [["The context directly describes the task as \"nearly impossible,\" which matches the statement's description of the building job as \"almost impossible.\"", "e", "validated"], ["The context refers to the challenge as one of \"engineering and building,\" supporting the statement's characterization of the task as a building job.", "e", "validated"], ["The phrase \"even for an experienced engineer\" in the statement is implied by the context mentioning Dave Hanson, who is portrayed as someone for whom \"nothing was impossible,\" suggesting a high level of expertise, and yet the task is still described as nearly impossible.", "e", "validated"], ["The context does not clearly state whether Dave Hanson is the engineer assigned to the building job.", "n", "validated"], ["The context describes the task as \"nearly impossible,\" but does not specify if it would still be \"almost impossible\" for an experienced engineer.", "n", "validated"], ["It is not specified whether the task is being compared to the abilities of an experienced engineer, only that it is nearly impossible in general.", "n", "validated"], ["The context suggests that for Dave Hanson, nothing was impossible, implying that even a nearly impossible engineering task would not be considered almost impossible for him.", "c", "validated"], ["The use of \"nearly impossible\" in the context contrasts with the absolute \"nothing was impossible\" regarding Dave Hanson, suggesting that the task may not be truly almost impossible for someone like him.", "c", "validated"], ["The context does not specifically state that an experienced engineer would find the task almost impossible, only that it is \"nearly impossible\" in general, so the statement may be overly definitive.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "134217e", "premise": "uh-huh and is it true i mean is it um", "hypothesis": "It's true.", "generated_explanations": [["The person asking \"is it true\" is seeking confirmation, and the response \"It's true\" affirms that the statement or information in question is indeed correct.", "e", "validated"], ["The context does not provide any specific information or claim to verify, so it is unclear what \"It's true\" refers to.", "n", "validated"], ["The context consists of a question and filler words, with no factual content established, making the truth value of the statement undetermined.", "n", "validated"], ["The context only contains questions and does not provide any information that can be verified as true or false.", "c", "validated"], ["There is no factual claim or assertion in the context for the statement to affirm as true.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "11601n", "premise": "36 AC usage nationally for mercury control from power plants should be roughly proportional to the total MWe of coal-fired facilities that are equipped with the technology (this assumes an average capacity factor of 85 percent and other assumptions of Tables 4-4 and 4-5).", "hypothesis": "Power plants' mercury control AC usage is higher than total MWe from coal facilities.", "generated_explanations": [["The context states AC usage is proportional to total MWe, but does not provide any information indicating that AC usage could exceed total MWe.", "n", "validated"], ["Required numerical data comparing actual AC usage and total MWe is not provided.", "n", "validated"], ["AC usage for mercury control is described as being roughly proportional to the total MWe of equipped coal-fired facilities, not higher than it.", "c", "validated"], ["There is no indication that AC usage can exceed the total electricity generation capacity (MWe) of the facilities; rather, AC usage correlates to it based on a set proportion.", "c", "validated"], ["The context assumes a direct relationship dependent on facility capacity and an 85% capacity factor, making it implausible for AC usage to surpass the total MWe.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "46059c", "premise": "The results of even the most well designed epidemiological studies are characterized by this type of uncertainty, though well-designed studies typically report narrower uncertainty bounds around the best estimate than do studies of lesser quality.", "hypothesis": "All studies have the same amount of uncertainty to them.", "generated_explanations": [["The context states that well-designed studies typically report narrower uncertainty bounds than studies of lesser quality, implying that the amount of uncertainty varies between studies.", "n", "validated"], ["The context states that well-designed studies typically report narrower uncertainty bounds than studies of lesser quality, indicating that the amount of uncertainty varies between studies.", "c", "validated"]], "label_count_round_1": {"n": 1, "c": 1}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 1, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "82156e", "premise": "The great breathtaking Italian adventure remains the road.", "hypothesis": "The road remains the Italy people want to see.", "generated_explanations": [["The phrase \"the great breathtaking Italian adventure remains the road\" suggests that the quintessential or most desired Italian experience is found by traveling the road, implying that this is what people are seeking in Italy.", "e", "validated"], ["It is not specified in the context whether \"the road\" is what people in Italy want to see, only that it is part of an adventure.", "n", "validated"], ["The context does not indicate the desires or preferences of the Italian people regarding what they want to see.", "n", "validated"], ["The statement assumes a consensus among \"Italy people\" that is not addressed or implied in the context.", "n", "validated"], ["The meaning of \"the road\" in the context may refer to experience or journey, not necessarily a literal or visual attraction people want to see.", "n", "validated"], ["The context describes the road as an adventure, not necessarily as what the Italian people want to see.", "c", "validated"], ["The context does not specify what the people of Italy want to see, only characterizing the road as \"great\" and \"breathtaking.\"", "c", "validated"], ["The context's focus is on the nature of the experience (\"adventure\") rather than public preference or desire.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 4, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 4, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "30894n", "premise": "Earlier this week, the Pakistani paper Dawn ran an editorial about reports that Pakistani poppy growers are planning to recultivate opium on a bigger scale because they haven't received promised compensation for switching to other crops.", "hypothesis": "Pakistani poppy growers are mad at the government.", "generated_explanations": [["The growers have not received the compensation they were promised by the government for switching to other crops, causing dissatisfaction.", "e", "not_validated"], ["Their decision to recultivate opium on a bigger scale suggests they are reacting negatively to the government's unfulfilled promises.", "e", "not_validated"], ["The context mentions that poppy growers have not received promised compensation, but it does not state explicitly how they feel about the government.", "n", "validated"], ["The motivation for recultivating opium could be financial necessity rather than anger at the government.", "n", "validated"], ["The context states that poppy growers are planning to recultivate opium due to lack of promised compensation, but it does not explicitly mention their emotions or state that they are mad at the government.", "c", "validated"], ["The motivation described in the context is economic (lack of compensation), not emotional (anger).", "c", "validated"], ["The context does not indicate any direct expression of anger or protest by the poppy growers toward the government.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "122645n", "premise": "Then you're ready for the fray, either in the bustling great bazaars such as Delhi's Chandni Chowk or Mumbai's Bhuleshwar, or the more sedate ambience of grander shops and showrooms.", "hypothesis": "All of the great bazaars are bustling at all times.", "generated_explanations": [["The context only describes some great bazaars as bustling and does not specify that all great bazaars have this characteristic.", "n", "validated"], ["The context does not state that the bustling nature of the bazaars is constant at all times.", "n", "validated"], ["The context only describes the great bazaars as \"bustling\" generally, but does not state that they are bustling at all times.", "c", "validated"], ["The context contrasts bustling bazaars with more sedate shops, implying variability in ambience and not constant bustle.", "c", "validated"], ["The statement universalizes (\"all\" and \"at all times\") without support from the context, which uses examples rather than a rule.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "26142n", "premise": "The importer pays duties that are required by law", "hypothesis": "Imported goods have duties", "generated_explanations": [["Duties are paid specifically on imported goods, indicating that such goods are subject to duties.", "e", "validated"], ["The payment of duties by the importer implies that the goods being imported are associated with duty requirements.", "e", "validated"], ["Legal requirements for the importer to pay duties demonstrate that imported goods incur duties by law.", "e", "validated"], ["The context specifies that the importer pays duties but does not explicitly state that all imported goods necessarily have duties; it is possible some imported goods could be exempt from duties.", "n", "validated"], ["The context refers to duties \"required by law,\" implying that only goods subject to such laws have duties, but leaves open the possibility that some imported goods may not be covered by these laws.", "n", "validated"], ["Not all imported goods are subject to duties; some may be exempt due to trade agreements or special classifications.", "c", "validated"], ["The context only mentions the importer paying required duties, not that every imported good necessarily has a duty.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "66225n", "premise": "uh but you could fill a whole bunch of uh holes with these things i used to i used to advertise buying wheat pennies um i'd give a dollar a roll which two cents a piece which is basically overpriced", "hypothesis": "I made a good dollar while selling them.", "generated_explanations": [["The speaker was able to buy wheat pennies at two cents each, which they acknowledge is overpriced, suggesting they could resell them at a higher price and make a profit.", "e", "not_validated"], ["The speaker advertised buying wheat pennies, indicating active involvement in trading them, which likely resulted in financial gain.", "e", "not_validated"], ["The context only mentions advertising to buy wheat pennies and paying a high price, but does not state whether any were later sold or for how much.", "n", "validated"], ["There is no information about profit, total earnings, or any selling activity, making it unclear if any money was made or if it was a good deal.", "n", "validated"], ["The context indicates the speaker was overpaying (\"overpriced\") to buy wheat pennies, not selling them for profit.", "c", "validated"], ["The speaker mentions advertising to buy wheat pennies, not selling them.", "c", "validated"], ["The phrase \"which is basically overpriced\" suggests financial loss rather than gain.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "134103n", "premise": "He walked out into the street and I followed.", "hypothesis": "I followed him down the street.", "generated_explanations": [["Following him out into the street implies movement in the same direction along the street, which can be described as following him down the street.", "e", "validated"], ["The act of following someone into the street typically involves continuing to follow as they proceed along the street, making the statement accurate.", "e", "validated"], ["The context only states that the speaker followed the person into the street, but does not specify that they continued to follow him down the street.", "n", "validated"], ["It is unclear from the context whether walking \"out into the street\" led to walking \"down the street\" or simply onto the street itself.", "n", "validated"], ["The statement assumes a direction or continuation that is not indicated in the context; following \"into the street\" does not necessarily mean following \"down the street.\"", "n", "validated"], ["The context only indicates that you followed him into the street, not necessarily down the street.", "c", "validated"], ["There is no information in the context about movement along the street after entering it.", "c", "validated"], ["\"Down the street\" implies traveling along its length, which is not established in the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "117177n", "premise": "I guess history repeats itself, Jane.", "hypothesis": "I truly think the prior situation shows history repeats itself.", "generated_explanations": [["The speaker explicitly states \"I guess history repeats itself,\" indicating a belief that an earlier event is occurring again, which supports the claim that the prior situation demonstrates the repetition of history.", "e", "validated"], ["The context contains an expression of guessing or uncertainty, while the statement asserts a true belief, so it is unclear if the speakers actually share the same level of conviction.", "n", "validated"], ["The context does not specify what the \"prior situation\" was, so we cannot determine if the speaker in the context is referring to the same evidence as the one in the statement.", "n", "validated"], ["The context includes dialogue (possibly involving two speakers), so it is undetermined whether the statement reflects the belief of the same person who spoke in the context.", "n", "validated"], ["The phrase \"I guess\" indicates uncertainty or speculation, whereas the statement asserts a definite belief, which is not supported by the context.", "c", "validated"], ["The context does not reference a \"prior situation\" or give evidence of a repeating event, so the statement falsely assumes an example was provided.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "78105e", "premise": "Their supplies scarce, their harvest meager, and their spirit broken, they abandoned the fort in 1858.", "hypothesis": "Their supplies remained very low and hard to maintain.", "generated_explanations": [["The context states that \"their supplies [were] scarce,\" which indicates that their supplies were very low.", "e", "validated"], ["The context implies difficulty in maintaining resources, contributing to the abandonment of the fort, suggesting supplies were hard to maintain.", "e", "validated"], ["The context states supplies were \"scarce\" at the time they abandoned the fort, but does not clarify whether they remained low and hard to maintain before or after abandonment.", "n", "validated"], ["The context does not provide information about the difficulty of maintaining the supplies, only that they were scarce at the moment of abandonment.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 2}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "23280e", "premise": "Sphinxes were guardian deitiesinEgyptianmythologyandthis was monumentalprotection,standing73 m (240 ft)longand20 m (66 feet) high.", "hypothesis": "Sphinxes guarded people.", "generated_explanations": [["In Egyptian mythology, sphinxes were designated as guardian deities, indicating their role in protection.", "e", "validated"], ["The monumental Sphinx statue was constructed as a form of protection, implying its purpose was to guard individuals or sacred spaces.", "e", "validated"], ["The context states that sphinxes were guardian deities and provided monumental protection, but it does not specify whom or what they guarded.", "n", "validated"], ["The context refers to the Sphinx as a monument, focusing on symbolic or spiritual protection rather than direct physical guarding of people.", "n", "validated"], ["The term \"guardian\" in the context may refer to guarding sacred places or objects, not necessarily people.", "n", "validated"], ["The context states that sphinxes were guardian deities and provided monumental protection, but it does not specify that they guarded people specifically—the protection could be for places, objects, or concepts rather than individuals.", "c", "validated"], ["The example given (the large sphinx statue) suggests protection in a symbolic or monumental sense, not direct protection of people.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "9393n", "premise": "Next, you enter the vast and splendid Imperial Hall, with three handsome marble fountains, and a canopied throne from which the sultan would enjoy the music and dancing of his concubines.", "hypothesis": "The sultan enjoyed drinking from the marble fountains in the Imperial Hall.", "generated_explanations": [["The context mentions marble fountains but does not specify their use or whether the sultan drank from them.", "n", "validated"], ["The context only describes the sultan enjoying music and dancing, not drinking from the fountains.", "n", "validated"], ["Fountains in palatial settings are often decorative, and their use for drinking is not implied.", "n", "validated"], ["There is no information about the sultan's drinking habits or preferences regarding the fountains.", "n", "validated"], ["The context does not mention the sultan drinking from the marble fountains, only that he enjoyed music and dancing.", "c", "validated"], ["The fountains are described as decorative features, not as a source for drinking.", "c", "validated"], ["Marble fountains in such halls are typically ornamental and not intended for drinking.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "82510c", "premise": "although the uh it's uh it we almost one day we painted the house to uh we painted we painted the whole inside and it had all this dark trim we thought uh you know we did the one wall but the other trim i'm trying to think i think i think we left most of it because it gets to be uh they don't do that in the newer houses now we don't the uh mold everything is white in a new house everything is white", "hypothesis": "It took over a day to paint the house", "generated_explanations": [["The speaker says \"we almost one day we painted the house,\" implying they did not finish within one day.", "e", "validated"], ["The speaker mentions not completing all tasks, such as \"we left most of it,\" suggesting the painting wasn't finished in a single day.", "e", "not_validated"], ["The context mentions \"we almost one day we painted the house,\" which is unclear and does not specify whether the painting actually took more or less than a day.", "n", "validated"], ["The discussion focuses on painting the whole inside and specific trim, but does not provide a clear timeline or duration for the entire painting process.", "n", "validated"], ["The mention of leaving \"most of it\" (the trim) suggests that not all parts may have been painted, leaving it ambiguous how long the work actually took.", "n", "validated"], ["No explicit statement or evidence in the context confirms that painting took more than one day.", "n", "validated"], ["The context states \"we almost one day we painted the house,\" indicating that the painting took almost one day, not over a day.", "c", "validated"], ["The phrase \"we painted the whole inside\" suggests the task was completed within that timeframe, not exceeding a day.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "14459n", "premise": "After their savage battles, the warriors recuperated through meditation in the peace of a Zen monastery rock garden.", "hypothesis": "The warriors recuperated through mediation learned from monks.", "generated_explanations": [["Warriors in a Zen monastery would have access to monks who practice and teach meditation techniques.", "e", "validated"], ["Meditating in a Zen monastery rock garden implies exposure to traditional monastic practices, which are typically taught by monks.", "e", "validated"], ["The context mentions meditation but does not specify that the meditation was learned from monks.", "n", "validated"], ["The context describes the setting as a Zen monastery rock garden, suggesting the presence or influence of monks, but does not explicitly state that the warriors interacted with monks or received instruction from them.", "n", "validated"], ["The context does not mention that the meditation was learned from monks; it only states they meditated in the rock garden.", "c", "validated"], ["The context does not state the presence or involvement of monks in the recuperation process.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "70711c", "premise": "because otherwise it's too it gets if you start them when it's cooler in the spring then it gets too hot in the summer", "hypothesis": "You should start them during Spring if you want them to be cool during the summer.", "generated_explanations": [["Starting them in the spring takes advantage of cooler temperatures before the onset of summer heat.", "e", "validated"], ["If you start them later, when it is already hot, they will experience excessive heat during their growth.", "e", "validated"], ["Initiating them during spring avoids the problem of it getting too hot in the summer.", "e", "not_validated"], ["The context suggests starting them in spring to avoid heat in summer, but it does not explicitly state that starting in spring will keep them cool during summer; it only implies that starting later would result in problems due to increased heat.", "n", "validated"], ["The context does not specify whether starting in spring guarantees the plants will be cool in the summer, only that starting in spring is preferable to starting later.", "n", "validated"], ["The context does not clarify what \"them\" refers to, so it is unclear if cooling in summer is the relevant goal for the subject in question.", "n", "validated"], ["Starting them in spring causes them to experience heat in the summer, not coolness.", "c", "validated"], ["The context suggests starting them in cooler conditions to avoid summer heat, not to achieve coolness during summer.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "77893n", "premise": "As he stepped across the threshold, Tommy brought the picture down with terrific force on his head.", "hypothesis": "Tommy hurt his head bringing the picture down.", "generated_explanations": [["Tommy brought the picture down with terrific force on his head, which implies a strong impact.", "e", "validated"], ["The act of striking his head with the picture suggests physical harm or pain.", "e", "validated"], ["The context does not specify whether Tommy's head was actually injured when he brought the picture down with terrific force.", "n", "validated"], ["It is unclear if “brought the picture down” means he struck his own head intentionally or if the action resulted in accidental contact with his head.", "n", "validated"], ["The phrase “on his head” could describe the location (e.g., above his head) rather than confirming direct impact or injury.", "n", "validated"], ["The context does not specify that Tommy was injured; it only states he brought the picture down with force on his head.", "c", "validated"], ["It is possible that despite the force, Tommy did not experience pain or injury.", "c", "validated"], ["The statement assumes a consequence (hurt) that is not explicitly mentioned in the context.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "20181n", "premise": "What the judge really wants are the facts -- he wants to make a good decision, he said.", "hypothesis": "In the end the judge made a bad decision since he imprisoned someone innocent.", "generated_explanations": [["The context does not indicate the outcome of the judge's decision, only his intentions and desires.", "n", "validated"], ["There is no information provided about whether anyone was imprisoned, or on the guilt or innocence of any such person.", "n", "validated"], ["The statement introduces new information (imprisoning someone innocent and the decision being bad) that is not addressed in the context.", "n", "validated"], ["The context does not mention the outcome of the judge's decision or indicate whether anyone was imprisoned, let alone someone innocent.", "c", "validated"], ["The context describes the judge’s intention to make a good decision, not the result of the case or the judge’s actual actions.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "137715n", "premise": "We still espouse a God-given right of human beings to use the environment for their benefit, says Barrett Duke of the Southern Baptists.", "hypothesis": "Human beings are entitled to the environment.", "generated_explanations": [["The context claims a \"God-given right\" for humans to use the environment, implying entitlement.", "e", "validated"], ["Barrett Duke’s statement suggests that this belief is upheld or supported, reinforcing the idea of entitlement.", "e", "validated"], ["The phrase \"for their benefit\" indicates that humans have a justified claim to utilize the environment, which aligns with being entitled to it.", "e", "validated"], ["The context refers to the belief in a \"God-given right\" rather than a general entitlement, leaving ambiguity about secular or universal entitlement.", "n", "validated"], ["The term \"use the environment for their benefit\" may not be equivalent to being \"entitled to the environment,\" as entitlement could imply ownership or unrestricted rights, which is not explicitly stated in the context.", "n", "validated"], ["The statement does not clarify the scope or limits of \"entitlement,\" whereas the context only mentions usage for benefit, not full entitlement.", "n", "validated"], ["The context states a belief in a right to use the environment, not entitlement to ownership or possession of the environment.", "c", "validated"], ["The statement implies entitlement to the environment as a whole, while the context specifies the right is to use it for benefit, not to the environment itself.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "109679n", "premise": "The Palace of Jahangir is built around a square court with arches.", "hypothesis": "The Palace of Jahangir houses a wonderful square court, complete with arches.", "generated_explanations": [["The context specifies that the Palace of Jahangir is built around a square court, matching the statement's claim that it houses a wonderful square court.", "e", "validated"], ["The context mentions the square court having arches, which aligns with the statement's detail that the court is \"complete with arches.\"", "e", "validated"], ["The context states the structural arrangement (built around a square court with arches) but does not provide evaluative language such as \"wonderful,\" so it is undetermined whether the court is considered wonderful.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 1}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 1}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "123891c", "premise": "His proud reserve--a product of 40 years in the spotlight--is refreshing but does not bode well for his capacity to shepherd big ideas through Congress.", "hypothesis": "He is way too loud.", "generated_explanations": [["The context mentions \"proud reserve,\" which suggests a reserved or quiet demeanor, but does not specify the actual volume of his voice.", "n", "validated"], ["There is no information about his vocal loudness or quietness, only about his demeanor and personality traits.", "n", "validated"], ["The context describes him as having a \"proud reserve,\" which implies he is not loud.", "c", "validated"], ["Being reserved suggests a quiet or restrained demeanor, contrary to being loud.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "16086n", "premise": "Unless the report is restricted by law or regulation, auditors should ensure that copies be made available for public inspection.", "hypothesis": "This report is most likely restricted by law or regulation and should not be ensured.", "generated_explanations": [["The context does not specify whether the report in question is, in fact, restricted by law or regulation, leaving its status undetermined.", "n", "validated"], ["The context outlines a conditional (\"unless...\"), but does not provide information about this particular report's classification, so its restriction cannot be inferred.", "n", "validated"], ["The context only states that reports should be made available to the public unless restricted, but it does not assert that this particular report is likely to be restricted by law or regulation.", "c", "validated"], ["The statement suggests auditors should not ensure availability, but the context says they should ensure availability unless a restriction applies; it is not established that such a restriction applies here.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "91650n", "premise": "yep because it's when it's self propelled it's heavy yeah", "hypothesis": "it's heavy when it's self propelled, in case you were wondering", "generated_explanations": [["The context explicitly states that when \"it's self propelled,\" \"it's heavy,\" directly matching the claim in the statement.", "e", "validated"], ["The phrase \"in case you were wondering\" in the statement does not contradict or alter the factual assertion made in the context.", "e", "validated"], ["Both the context and the statement identify \"self propelled\" as the condition under which the object is heavy, showing logical consistency.", "e", "validated"], ["The context suggests agreement with the idea that \"it's heavy when it's self propelled,\" but it does not explicitly confirm that heaviness is exclusive to the self-propelled state.", "n", "validated"], ["There is no information in the context specifying who is \"wondering,\" so the assumption about the listener's state of curiosity is not justified.", "n", "not_validated"], ["The context does not clarify precisely what \"it\" refers to, nor if the reference is the same in both the context and statement.", "n", "validated"], ["The context implies that the heaviness is a result of being self-propelled, not merely coinciding with it, so the statement could be misleading by suggesting the heaviness is a general fact rather than a consequence.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 1}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"n": 1, "c": 1}}
{"id": "85428e", "premise": "Christ on a crutch, what does he have to do to lose your support, stab David Geffen with a kitchen knife?", "hypothesis": "Your support is unwavering.", "generated_explanations": [["The rhetorical question in the context implies that even an extreme action (stabbing David Geffen with a kitchen knife) would not be enough to make the listener withdraw their support, suggesting absolute loyalty.", "e", "validated"], ["The exasperation conveyed implies that the listener's support remains firm regardless of potential negative actions by the person in question.", "e", "validated"], ["The context describes a hypothetical extreme action that questions the limit of support but does not state whether support has actually continued or wavered, so the current state of support is unclear.", "n", "validated"], ["The rhetorical question implies doubt about unwavering support but does not confirm whether the support is, in fact, unwavering or not.", "n", "validated"], ["The context implies there are hypothetical actions (such as stabbing David Geffen) that would cause the person to lose support, indicating their support is not unwavering.", "c", "validated"], ["The rhetorical question suggests the speaker believes there are conceivable limits to their support, contradicting the notion of it being unwavering.", "c", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "118403n", "premise": "oh really it wouldn't matter if we plant them when it was starting to get warmer", "hypothesis": "It is better to plant when it is colder.", "generated_explanations": [["The phrase \"it wouldn't matter if we plant them when it was starting to get warmer\" implies that planting timing relative to temperature is not important, which does not directly support the claim that it is better to plant when it is colder. Therefore, there are no reasonable distinct explanations for the statement being true given this context.", "e", "not_validated"], ["The context only discusses whether planting when it is getting warmer matters, without making any comparison to planting when it is colder.", "n", "validated"], ["There is no information in the context about the relative benefits of planting in colder versus warmer conditions.", "n", "validated"], ["The opinion or evidence for \"better\" conditions to plant is not provided in the context.", "n", "validated"], ["The context implies that planting when it gets warmer is acceptable, contradicting the claim that colder is better.", "c", "validated"], ["There is no indication in the context that colder conditions are preferable for planting; it suggests temperature does not matter.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 1}}
{"id": "105561e", "premise": "and they just put instructors out there and you you sign up for instruction and they just give you an arm band and if you see an instructor who's not doing anything you just tap him on the shoulder and ask him questions and they'll show you things", "hypothesis": "The instructors are marked with armbands, and anytime you want to know anything, you just find one of them.", "generated_explanations": [["Instructors are identified by armbands, making them easy to find.", "e", "validated"], ["Anyone can approach an available instructor to ask questions whenever they want.", "e", "validated"], ["The context specifies that you sign up for instruction and then can approach an available instructor, but it does not state explicitly that you can ask them \"anytime\" or \"for anything you want to know\".", "n", "validated"], ["The statement generalizes the instructors' availability as \"anytime\", whereas the context only mentions approaching instructors who are \"not doing anything\".", "n", "validated"], ["The statement suggests armbands are solely for identifying instructors, but the context does not clarify if armbands are exclusive to instructors or if others might wear them too.", "n", "validated"], ["The context implies a process (\"sign up for instruction\") that may limit access, while the statement omits any access restrictions.", "n", "validated"], ["The context says you sign up for instruction, implying there is a process rather than being able to approach an instructor at any time.", "c", "not_validated"], ["The statement suggests you can find an instructor anytime you want to know anything, but the context specifies you ask if you see an instructor who's not doing anything, which means you can't always ask at any time.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "11303n", "premise": "'I see.'", "hypothesis": "It was clear", "generated_explanations": [["The phrase \"I see\" can indicate that something was understood or made clear.", "e", "validated"], ["The phrase \"I see\" can indicate understanding, but does not specify whether the information or situation was objectively clear.", "n", "validated"], ["\"I see\" could be a polite acknowledgment rather than an indication of actual clarity.", "n", "validated"], ["The phrase \"I see\" can indicate comprehension even if the situation was not actually clear.", "c", "validated"], ["\"I see\" may be used out of politeness or to acknowledge someone without true understanding, so it does not guarantee that it was clear.", "c", "validated"], ["\"I see\" could be interpreted literally as visual perception rather than as understanding, which doesn't imply clarity in explanation.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "11534n", "premise": "He found himself thinking in circles of worry and pulled himself back to his problem.", "hypothesis": "He could not afford to get distracted from his problem.", "generated_explanations": [["He was aware that his habitual worrying was causing him to lose focus, so he deliberately refocused on his problem.", "e", "validated"], ["The act of pulling himself back to his problem suggests that staying attentive to it was important to him.", "e", "validated"], ["His concern about distractions implies that remaining concentrated on the problem was necessary for him.", "e", "validated"], ["The context only indicates that he pulled himself back to his problem after worrying, but does not specify whether he could afford to be distracted or not.", "n", "validated"], ["The context provides no information about the consequences or affordability of being distracted from his problem.", "n", "validated"], ["The context shows that he did get distracted by thinking in circles of worry before refocusing, which implies he was at least temporarily distracted.", "c", "validated"], ["The context does not mention any specific consequence or inability to afford distraction, only that he pulled himself back.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "46198n", "premise": "How effectively DOD manages these funds will determine whether it receives a good return on its investment.", "hypothesis": "These funds are for the purchase of five thousand tons of potatoes.", "generated_explanations": [["The context does not specify what the funds are intended to purchase or support.", "n", "validated"], ["There is no mention of potatoes or any related procurement in the context.", "n", "validated"], ["The purpose or allocation of the funds is not detailed in the context.", "n", "validated"], ["The context does not mention potatoes or any specific commodity, so there is no evidence that the funds are designated for purchasing potatoes.", "c", "validated"], ["The context discusses the effectiveness of fund management in terms of investment return, which is unrelated to the procurement of a specific quantity of potatoes.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "125013e", "premise": "yeah okay yeah those games are fun to watch you you you watch those games", "hypothesis": "Those games are a lot of fun.", "generated_explanations": [["The context mentions that the games are fun to watch, which implies that the games themselves are enjoyable.", "e", "validated"], ["The context only mentions that the games are \"fun to watch,\" not that the games themselves are inherently \"a lot of fun,\" which could refer to playing rather than watching.", "n", "validated"], ["The statement uses the phrase \"a lot of fun,\" which is a stronger and broader claim than just \"fun to watch,\" leaving uncertainty about the degree of fun or the aspect being described.", "n", "validated"], ["The context does not specify whose opinion is being reported, so it's unclear if the statement generalizes beyond the speaker's personal experience.", "n", "validated"], ["The context only mentions that the games are fun to watch, not that the games themselves are a lot of fun independent of watching them.", "c", "validated"], ["The context refers specifically to the act of watching the games as fun, not to the games' inherent qualities or overall enjoyment.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "44747n", "premise": "Total volume grew 13.", "hypothesis": "The expected increase was 10.", "generated_explanations": [["The context does not specify what the expected increase was, so it is unclear whether 10 was the expected increase.", "n", "validated"], ["The context provides the actual volume growth but does not mention any expectation or forecast.", "n", "validated"], ["The actual increase in total volume was 13, not 10.", "c", "validated"], ["The statement refers to an expectation, not the actual outcome described in the context.", "c", "not_validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 1}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "19768c", "premise": "Wear a nicely ventilated hat and keep to the shade in the street.", "hypothesis": "The buildings are so low that there is no shade in the streets.", "generated_explanations": [["The context mentions keeping to the shade, but does not specify whether the shade comes from buildings, trees, or other sources, so the presence or absence of building-provided shade is not determined.", "n", "validated"], ["The statement asserts there is no shade because of low buildings, but the context provides no information about the height of buildings or their ability to cast shade.", "n", "validated"], ["The context advises keeping to the shade in the street, which implies that shade is available.", "c", "validated"], ["The context does not mention anything about the height of the buildings or a lack of shade caused by building height.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "53468n", "premise": "But is the Internet so miraculous an advertising vehicle that Gross will be able to siphon off $400 per person from total ad spending of $1,000 per family--or persuade advertisers to spend an additional $400 to reach each of his customers?", "hypothesis": "The internet is so great at advertising that is saved Gross money.", "generated_explanations": [["The context questions whether the Internet can generate additional advertising revenue, not whether it saves Gross money.", "n", "validated"], ["The context does not mention any reduction in expenses or cost savings for Gross.", "n", "validated"], ["The context only discusses Gross's potential ability to earn more money through advertising, not save money.", "n", "validated"], ["The context questions whether the Internet can generate sufficient advertising revenue, not that it saves Gross money.", "c", "validated"], ["The context discusses the potential for Gross to earn money through advertising, not cost savings.", "c", "validated"], ["There is no mention of Gross saving money as a result of Internet advertising; the focus is on ad spending and revenue.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "136752n", "premise": "The questions may need to be tailored to", "hypothesis": "A majority of the questions referenced will need to be tailored to.", "generated_explanations": [["\"The questions\" in the context implies multiple questions are under consideration, and \"may need to be tailored\" suggests that this adjustment could apply to many or most of them, supporting the claim that a majority would be affected.", "e", "not_validated"], ["The phrase \"may need to be tailored\" is open-ended, but does not exclude the possibility that it applies to the majority, making the statement consistent with the context.", "e", "not_validated"], ["If tailoring is necessary for the questions, and there is no indication that only a minority are exempt, it is reasonable to infer that more than half (a majority) might require tailoring.", "e", "not_validated"], ["The context states that the questions \"may\" need to be tailored, which is uncertain and does not specify what proportion of questions require tailoring.", "n", "validated"], ["The statement asserts that a \"majority\" of questions will need to be tailored, which is a specific quantification not supported or contradicted by the context.", "n", "validated"], ["The context only suggests that some questions may need to be tailored, not that a majority will need to be tailored.", "c", "validated"], ["The statement asserts that most questions require tailoring, which is not supported by the possibility indicated in the context.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 3}}
{"id": "10724n", "premise": "Traditionally, certain designs were reserved for royalty, but today elegant geometric or exuberant, stylized floral patterns are available to all.", "hypothesis": "Designs once reserved for royalty cost more to buy.", "generated_explanations": [["The context discusses the availability of designs to all, but does not mention their current price.", "n", "validated"], ["There is no information about whether these designs are more expensive than others today.", "n", "validated"], ["The context does not address whether the change in availability affected the costs of these designs.", "n", "validated"], ["The context states that designs once reserved for royalty are now available to all, but does not mention anything about their cost.", "c", "validated"], ["Availability to all suggests the designs are not limited by high cost or exclusivity.", "c", "validated"], ["The context implies democratization of design access, not increased pricing.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "17753n", "premise": "The street ends at Taksim Square (Taksim Meydane), the heart of modern Istanbul, lined with luxurious five-star hotels and the glass-fronted Ataturk Cultural Centre (Ataturk Keleter Sarayy), also called the Opera House.", "hypothesis": "The street is quite a luxurious one.", "generated_explanations": [["The street ends at Taksim Square, which is described as the heart of modern Istanbul, implying a prestigious and upscale location.", "e", "validated"], ["The street is lined with luxurious five-star hotels, indicating a high level of luxury.", "e", "validated"], ["The presence of the glass-fronted Ataturk Cultural Centre (Opera House) suggests cultural refinement and affluence in the area.", "e", "not_validated"], ["The context mentions that Taksim Square is lined with luxurious hotels and an impressive cultural centre, but does not specify whether the street itself, before ending at the square, possesses similar luxurious characteristics.", "n", "validated"], ["The context provides details about what is situated at the end of the street, not about the street’s features or ambiance along its length.", "n", "validated"], ["The presence of luxurious establishments at the street’s end does not necessarily imply that the entire street is luxurious.", "n", "validated"], ["The context only mentions that Taksim Square, where the street ends, is lined with luxurious hotels, not that the entire street itself is luxurious.", "c", "validated"], ["There is no information about the street's own features or level of luxury; the description focuses on what is at the endpoint, not along the street.", "c", "validated"], ["The presence of luxurious hotels and a cultural center at the square does not necessarily imply that the street leading to it shares those luxurious characteristics.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "130928n", "premise": "Still, I guess that can be got over.", "hypothesis": "There are some things that you need to ignore.", "generated_explanations": [["\"That can be got over\" suggests that there are issues or obstacles that one must move past, which may require ignoring certain things.", "e", "validated"], ["The phrase implies resilience or acceptance, which often involves choosing not to focus on every problem—thus, ignoring some things.", "e", "validated"], ["The context does not specify what \"that\" refers to, so it is unclear what needs to be \"got over\" or if it involves ignoring something.", "n", "validated"], ["\"Got over\" could imply dealing with or overcoming something rather than ignoring it, so the relationship is ambiguous.", "n", "validated"], ["The context does not mention or imply the existence of multiple things, as the statement suggests (\"some things\"), but rather refers to a singular issue (\"that\").", "n", "validated"], ["There is no explicit mention or suggestion of the act of ignoring in the context.", "n", "validated"], ["The context refers to overcoming something, not ignoring things.", "c", "validated"], ["The context does not mention the necessity to ignore anything.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 4, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "66858n", "premise": "Managing better requires that agencies have, and rely upon, sound financial and program information.", "hypothesis": "Agencies that rely on information based on unsound financial information will have management problems.", "generated_explanations": [["Relying on unsound financial information leads to poor decision-making due to inaccurate data.", "e", "validated"], ["Unsound financial information undermines the reliability of program assessments, causing mismanagement.", "e", "validated"], ["Sound financial information is described as necessary for better management, implying unsound data results in management issues.", "e", "validated"], ["The context says agencies require and rely on sound information for better management but does not explicitly state what happens when they rely on unsound information.", "n", "validated"], ["The context does not specify the consequences (such as management problems) of relying on unsound financial information.", "n", "validated"], ["The statement assumes a causal relationship (unsound information leads to management problems) that is not directly asserted in the context.", "n", "validated"], ["The context does not address what happens if an agency relies on only partially unsound information or on other compensating factors.", "n", "validated"], ["The context does not state that agencies relying on unsound financial information will necessarily have management problems; it only emphasizes the importance of sound information.", "c", "validated"], ["The statement assumes a causal relationship (relying on unsound information leads to problems) that is not made explicit in the context.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 4, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 4, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"c": 1}}
{"id": "28601n", "premise": "Three more days went by in dreary inaction.", "hypothesis": "The days passed by slowly.", "generated_explanations": [["The phrase \"dreary inaction\" implies a lack of activity, which can make time feel as though it is passing slowly.", "e", "validated"], ["\"Three more days went by\" suggests that a notable amount of time passed with little happening, reinforcing the perception of slow-moving days.", "e", "validated"], ["The context mentions \"dreary inaction,\" which may imply boredom or inactivity but does not specify the perceived speed of time.", "n", "validated"], ["The statement interprets the passage of time as \"slow,\" but \"three more days went by\" is a neutral description and does not indicate subjective experience.", "n", "validated"], ["\"Dreary inaction\" could lead to time feeling either slow or indifferent, but this subjective impression is not explicitly stated.", "n", "validated"], ["The context does not indicate the perception of time passing slowly; it only mentions \"dreary inaction,\" not the subjective speed of time.", "c", "validated"], ["The context states \"three more days went by,\" which could imply the days passed without note or quickly, not necessarily slowly.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "92774n", "premise": "The party's broad aims were to support capitalist policies and to continue close ties with Britain and the rest of the Commonwealth.", "hypothesis": "The party sought to establish ties with the United States.", "generated_explanations": [["The context mentions close ties with Britain and the Commonwealth but does not mention the United States, so there is insufficient information to determine if the party sought ties with the United States.", "n", "validated"], ["Supporting capitalist policies and ties with Britain do not necessarily imply seeking ties with the United States, as these are separate political relationships.", "n", "validated"], ["The absence of information about relations with countries outside the Commonwealth makes it unclear whether the party had any particular stance toward the United States.", "n", "validated"], ["The context specifies the party aimed to continue close ties with Britain and the Commonwealth, with no mention of the United States.", "c", "validated"], ["The party’s stated international focus is on Britain and the Commonwealth, not the United States, suggesting the US was not a priority for establishing ties.", "c", "validated"]], "label_count_round_1": {"n": 3, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 3, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "142604e", "premise": "As the budgets, functions, and points of service of many government programs devolve to state and local government, private entities and nonprofit organizations, and other third parties, it may become harder for GAO to obtain the records it needs to complete audits and evaluations.", "hypothesis": "Audits and evaluations are harder because it is more difficult for GAO to get the records.", "generated_explanations": [["The devolution of government program responsibilities to state, local, private, and nonprofit entities increases the number of parties holding relevant records, making it more challenging for GAO to access all necessary information.", "e", "validated"], ["Third parties outside federal control may have fewer legal obligations to provide records to GAO, leading to difficulties in obtaining required documentation for audits and evaluations.", "e", "validated"], ["The context only states that it may become harder for GAO to obtain records, not that it definitely will become harder.", "n", "validated"], ["The statement assumes audits and evaluations are already harder, while the context discusses a potential future difficulty, not a current or confirmed one.", "n", "validated"], ["The statement implies that the only reason audits and evaluations are harder is the increased difficulty in obtaining records, but the context mentions devolution of budgets, functions, and points of service, which could independently make audits and evaluations harder irrespective of record access.", "c", "validated"], ["The context says it \"may become harder\" for GAO to obtain records, suggesting a possibility, while the statement assumes it is already and definitively more difficult.", "c", "validated"], ["The context discusses audits and evaluations being potentially harder for GAO, not universally harder, while the statement generalizes that audits and evaluations themselves are harder.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 3}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "42860n", "premise": "That's why we tried to kill you.", "hypothesis": "That's one of the reasons we wanted to kill you.", "generated_explanations": [["\"That's why we tried to kill you\" indicates a specific reason for their attempt, which logically serves as at least one reason among potentially others for wanting to kill the person.", "e", "validated"], ["The context suggests a single reason (\"That's why\"), whereas the statement implies multiple reasons (\"one of the reasons\"), creating ambiguity about the number of motives involved.", "n", "validated"], ["The context uses \"tried,\" indicating an attempt, while the statement uses \"wanted,\" which refers to intention; the relationship between trying and wanting is not explicitly clarified.", "n", "validated"], ["The context provides no information about other possible reasons beyond the one mentioned, so it's unclear if there were additional reasons as implied by the statement.", "n", "validated"], ["The context presents a single reason for trying to kill \"you,\" while the statement suggests there are multiple reasons.", "c", "validated"], ["The statement uses \"wanted,\" implying intention without action, whereas the context uses \"tried,\" indicating an actual attempt was made.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "77299n", "premise": "The inquiry expanded very quickly, however, from asking what technology failed to an examination of contextual influences, such as", "hypothesis": "They moved they inquiries over from technology failing because they thought it may be something else.", "generated_explanations": [["The inquiry shifted focus from technology failure to considering contextual influences, implying investigators suspected factors beyond just technological issues.", "e", "validated"], ["The context mentions an expansion of the inquiry to include contextual influences but does not specify that technology failure was abandoned as a cause; both could be investigated in parallel.", "n", "validated"], ["The motive for expanding the inquiry is not explicitly stated; it is unclear if the shift was due to a belief that something else was to blame.", "n", "validated"], ["The statement presumes a complete transition away from technology failure, while the context only confirms an expansion, not an exclusive shift.", "n", "validated"], ["The statement suggests the shift in inquiry was due to \"thinking it may be something else,\" but the context indicates the inquiry expanded, not shifted solely because of suspicion—it included an examination of contextual influences in addition to technology failure, not instead of it.", "c", "validated"], ["The statement implies that inquiries stopped considering technology failure, whereas the context indicates they added other factors rather than abandoning the original focus.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "13765c", "premise": "it's just it's the morals of the people which i mean i guess we everybody's responsible for the society but if i had a child that that did things so bad it's not they don't care about anybody these people they're stealing from they're just the big bad rich guy", "hypothesis": "I have no issue with people stealing from others.", "generated_explanations": [["The speaker expresses concern about people stealing and describes such actions as \"bad,\" which suggests disapproval, but does not explicitly state their own stance, leaving uncertainty.", "n", "validated"], ["The speaker discusses societal morals and responsibility, implying an awareness of right and wrong, but does not clearly reveal whether they personally condone or condemn stealing.", "n", "validated"], ["The speaker references \"the big bad rich guy\" in a way that could be sarcastic or critical, making it ambiguous whether they are justifying stealing from the rich or criticizing it.", "n", "validated"], ["The speaker frames the situation hypothetically (\"if I had a child that did things so bad\"), which implies theoretical disapproval, but does not directly address their own feelings about stealing in general.", "n", "validated"], ["The context implies disapproval of people who \"don't care about anybody\" and are \"stealing from\" others, suggesting the speaker does have an issue with such behavior.", "c", "validated"], ["The speaker references morals and responsibility, indicating a concern about unethical actions like stealing.", "c", "validated"], ["The speaker discusses feeling troubled if their own child were to behave in this way, which suggests a personal issue with stealing from others.", "c", "validated"]], "label_count_round_1": {"n": 4, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 4, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "139362e", "premise": "Endorphins were flowing.", "hypothesis": "My endorphins were flowing.", "generated_explanations": [["If endorphins were flowing generally, it is possible that my endorphins were among those flowing.", "e", "not_validated"], ["The statement does not specify whose endorphins, so it could include mine.", "e", "not_validated"], ["The context refers to endorphins in general, without specifying whose endorphins were flowing.", "n", "validated"], ["The statement introduces a specific individual (“my”) not identified in the context, so it is unclear if the context includes that individual's experience.", "n", "validated"], ["The context refers to endorphins in general without specifying whose endorphins were flowing, so it does not necessarily mean that your endorphins were flowing.", "c", "validated"], ["The context could refer to endorphins flowing in one or more people present, not necessarily including you.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "116176c", "premise": "Students of human misery can savor its underlying sadness and futility.", "hypothesis": "Students of human misery will be delighted to see how sad it truly is.", "generated_explanations": [["The phrase \"savor its underlying sadness and futility\" suggests that students of human misery derive a kind of pleasure or satisfaction from recognizing and understanding the depths of sadness inherent in human misery.", "e", "not_validated"], ["The context indicates that these students appreciate the true, underlying nature of human misery, including its sadness, which aligns with being \"delighted to see how sad it truly is.\"", "e", "not_validated"], ["The context states that students of human misery can \"savor\" its sadness and futility, but it does not specify that this equates to delight or being delighted.", "n", "validated"], ["The word \"savor\" does not necessarily imply delight; it can mean to deeply contemplate or appreciate, possibly with a sense of gravity or somberness rather than joy.", "n", "validated"], ["The context does not provide information about the emotional response (\"delighted\") of the students, only that they can perceive the underlying sadness and futility.", "n", "validated"], ["The context suggests students \"savor\" the underlying sadness and futility, which implies contemplation or reflection, not delight or happiness.", "c", "validated"], ["\"Delighted\" connotes pleasure or joy, which contradicts the context of \"sadness and futility.\"", "c", "validated"], ["The term \"savor\" in the context does not imply a positive emotional response like delight but rather an appreciation or immersion, often with a somber tone.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 3}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"n": 3, "c": 3}, "label_set_round_2": ["n", "c"], "error": ["e"], "not_validated_exp": {"e": 2}}
{"id": "110234e", "premise": "really oh i thought it was great yeah", "hypothesis": "that was a nice experience", "generated_explanations": [["The speaker expresses a positive opinion (\"i thought it was great\"), which implies they had a nice experience.", "e", "validated"], ["The context expresses positive sentiment but does not specify what is being referred to, so it is unclear whether \"a nice experience\" accurately describes it.", "n", "validated"], ["The context lacks explicit mention of an \"experience,\" making it uncertain if the statement applies.", "n", "validated"], ["The phrase \"oh i thought it was great\" implies that the speaker is expressing surprise, possibly in response to someone else's negative opinion, suggesting that not everyone thought it was a nice experience.", "c", "not_validated"], ["The context does not explicitly state that the experience was nice; it only conveys one person's positive opinion, which may not represent the overall truth.", "c", "not_validated"]], "label_count_round_1": {"e": 1, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 2}, "label_set_round_2": ["n", "e"], "error": ["c"], "not_validated_exp": {"c": 2}}
{"id": "84781c", "premise": "By coordinating policy development and awareness activities in this manner, she helps ensure that new risks and policies are communicated promptly and that employees are periodically reminded of existing policies through means such as monthly bulletins, an intranet web site, and presentations to new employees.", "hypothesis": "There new employees are a risk.", "generated_explanations": [["The context states that new employees receive presentations about policies but does not provide information indicating that new employees themselves are considered a risk.", "n", "validated"], ["The statement suggests new employees are a risk, but the context only mentions mechanisms for communicating policies to them without evaluating or characterizing the risk they pose.", "n", "validated"], ["The context does not indicate that new employees themselves are considered a risk; it only mentions that presentations are given to them to inform them about policies.", "c", "validated"], ["The context refers to communication methods and does not attribute risk to any specific group, including new employees.", "c", "validated"], ["The phrase \"new employees are a risk\" is not supported or implied by any information in the context.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "41052n", "premise": "HCFA published a Notice of Proposed Rulemaking on March 28, 1997 (62 Fed.", "hypothesis": "HCFA tried to keep everyone informed about the rules they were making.", "generated_explanations": [["Publishing a Notice of Proposed Rulemaking is a method used to inform the public and stakeholders about upcoming rules and to solicit feedback.", "e", "validated"], ["The context only indicates that HCFA published a Notice of Proposed Rulemaking but does not specify whether they made efforts to inform everyone beyond this publication.", "n", "validated"], ["It is unclear from the context whether the publication of the Notice was accessible to or actually reached everyone who might be affected.", "n", "validated"], ["The context does not describe HCFA’s intentions or actions regarding communication beyond the formal publication process.", "n", "validated"], ["The statement \"HCFA tried to keep everyone informed about the rules they were making\" implies an effort to inform all relevant parties, but the context only mentions the publication of a Notice of Proposed Rulemaking, which is a standard procedural step and does not necessarily demonstrate an active effort to keep everyone informed.", "c", "validated"], ["Publishing a Notice of Proposed Rulemaking does not ensure that everyone is actually informed, as some individuals or groups may not access or be aware of federal register notices.", "c", "validated"]], "label_count_round_1": {"e": 1, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 1, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "128160n", "premise": "Suddenly she started, and her face blanched.", "hypothesis": "She moved swiftly, her face pale.", "generated_explanations": [["\"Started\" implies a sudden movement, which can be interpreted as moving swiftly.", "e", "validated"], ["\"Blanched\" means her face became pale.", "e", "validated"], ["The word \"suddenly\" indicates rapid or swift action.", "e", "not_validated"], ["The context indicates she started suddenly, but it is not specified whether her subsequent movement was swift; \"started\" could mean a small flinch rather than significant movement.", "n", "validated"], ["The context describes her face as \"blanched,\" but while this implies paleness, it doesn't clarify the ongoing state or degree of paleness at the exact moment of any subsequent movement.", "n", "validated"], ["The context only mentions that she started, which can mean she was surprised or startled, not necessarily that she moved swiftly.", "c", "validated"], ["The statement refers to her movement as \"swift,\" but the context does not specify the speed or intensity of her movement.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1}}
{"id": "123038e", "premise": "Reports on attestation engagements should state that the engagement was made in accordance with generally accepted government auditing standards.", "hypothesis": "Details regarding validation engagements ought to express that the engagement was made as per by and large acknowledged government evaluating guidelines.", "generated_explanations": [["\"Attestation engagements\" and \"validation engagements\" are being used interchangeably, both referring to engagements that require reporting on standards.", "e", "not_validated"], ["Both statements assert the necessity of stating compliance with generally accepted government auditing standards (GAGAS) in engagement reports.", "e", "validated"], ["The statements both refer to expressing, in the report, adherence to government auditing standards, implying the same reporting requirement.", "e", "validated"], ["The context refers specifically to \"attestation engagements,\" while the statement refers to \"validation engagements,\" and it is not clear if these two types of engagements are equivalent or interchangeable.", "n", "validated"], ["The relationship between \"reports on attestation engagements\" and \"details regarding validation engagements\" is not established, so it is undetermined whether the requirement in the context applies to the statement.", "n", "validated"], ["The terms \"reports\" and \"details\" may not refer to the same kind or level of documentation, making it unclear whether the context’s stipulation applies to the statement.", "n", "validated"], ["The statement refers to \"validation engagements,\" which is a different type of engagement than \"attestation engagements\" referenced in the context.", "c", "validated"], ["The statement uses \"evaluating guidelines,\" which may not clearly refer to \"auditing standards\" as stated in the context.", "c", "not_validated"]], "label_count_round_1": {"e": 3, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 1}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {"e": 1, "c": 1}}
{"id": "98621n", "premise": "In other cases, we must rely on survey approaches to estimate WTP, usually through a variant of the contingent valuation approach, which generally involves directly questioning respondents for their WTP in hypothetical market situations.", "hypothesis": "Hypothetical market situations are uniform across all respondents.", "generated_explanations": [["The context does not specify whether the hypothetical market situations presented to respondents are the same for everyone or if they vary among respondents.", "n", "validated"], ["Survey designs for contingent valuation can include different scenarios for different groups to test for robustness or framing effects, which is not addressed in the context.", "n", "validated"], ["The context does not state that hypothetical market situations are the same for all respondents; it only mentions that respondents are questioned about their WTP in such situations, implying variability is possible.", "c", "validated"], ["Survey-based methods like contingent valuation often allow for variations in scenarios to test different factors or elicit more accurate responses.", "c", "validated"], ["The term \"hypothetical market situations\" is plural, suggesting that more than one scenario may be presented, which contradicts the idea of uniformity.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "97926c", "premise": "General Motors, for instance, lost $460 million to strikes in 1997, but investors treated the costs as a kind of extraordinary charge and valued the company as if the losses had never happened.", "hypothesis": "GM lost a lot almost a million dollars in labor disputes.", "generated_explanations": [["GM lost $460 million to strikes, which is a large amount and much greater than a million dollars.", "e", "validated"], ["The strikes referenced in the context are a type of labor dispute, aligning with the statement.", "e", "validated"], ["The statement says \"almost a million dollars,\" but the context states $460 million, which is much higher; it is undetermined if the speaker is underestimating, rounding, or referring to a different incident.", "n", "validated"], ["The context attributes the losses specifically to strikes, while the statement refers more generally to \"labor disputes,\" and it's unclear if all strikes are included within \"labor disputes\" as intended in the statement.", "n", "validated"], ["The statement doesn't specify the year, so it is undetermined if it refers to the 1997 event or a different occasion.", "n", "validated"], ["GM lost $460 million, which is not \"almost a million dollars\" but is much larger.", "c", "validated"], ["The losses were specifically stated as $460 million, not \"almost a million dollars,\" making the statement numerically inaccurate.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "98561e", "premise": "was it bad", "hypothesis": "Was it not good?", "generated_explanations": [["\"Bad\" and \"not good\" are synonymous, both indicating a negative evaluation.", "e", "validated"], ["Asking \"was it bad\" is logically equivalent to asking if it was \"not good,\" both inquiring about a lack of positive quality.", "e", "validated"], ["The context does not specify what \"it\" refers to, making it unclear whether \"bad\" and \"not good\" are being applied to the same thing.", "n", "validated"], ["The context is a question rather than a factual statement, so the truth or falsity of \"bad\" is not established.", "n", "validated"], ["The relationship between \"bad\" and \"not good\" can be context-dependent; \"not good\" might not necessarily mean \"bad\" in all scenarios.", "n", "validated"]], "label_count_round_1": {"e": 2, "n": 3}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 3}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {}}
{"id": "86429n", "premise": "Agencies may perform the analyses required by sections 603 and 604 in conjunction with or as part of any other agenda or analysis required by other law if such other analysis satisfies the provisions of these sections.", "hypothesis": "There are many times when the agencies have gotten in trouble.", "generated_explanations": [["The context discusses procedural options for agencies carrying out specific analyses but does not mention agency misconduct or instances of agencies getting in trouble.", "n", "validated"], ["There is no information provided about the agencies' historical actions or consequences arising from their actions.", "n", "validated"], ["The context does not mention any instances of agencies getting in trouble.", "c", "validated"], ["The context is focused solely on compliance with legal analysis requirements, not on agency misconduct or errors.", "c", "validated"], ["There is no indication or implication in the context that agencies have faced negative consequences or disciplinary actions.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 3}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 3}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
{"id": "105911c", "premise": "and to have children and just get a day care or someone to take care of it and not really have the bonding process that takes place with babies and stuff you know", "hypothesis": "The children should not go to day car.", "generated_explanations": [["The absence of the bonding process that occurs when parents personally care for their babies is highlighted as a negative consequence of using day care.", "e", "validated"], ["Relying on day care or someone else for childcare is presented as preventing the important bonding between parents and their children.", "e", "validated"], ["The context discusses the lack of bonding when children go to daycare but does not explicitly state an opinion about whether children should or should not go to daycare.", "n", "validated"], ["The context presents a scenario about daycare and bonding but does not make a normative or prescriptive judgment about the appropriateness of daycare.", "n", "validated"], ["The speaker describes potential outcomes of daycare use (less bonding) but does not directly claim that children should be kept out of daycare.", "n", "validated"], ["The context does not explicitly state that children should not go to day care; it describes a scenario where children go to day care without bonding, but does not prescribe against day care itself.", "c", "validated"], ["The context suggests a concern about the lack of bonding but does not issue a directive or explicit opinion on whether children should or should not go to day care.", "c", "validated"]], "label_count_round_1": {"e": 2, "n": 3, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 2, "n": 3, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "126486n", "premise": "The entire setup has an anti-competitive, anti-entrepreneurial flavor that rewards political lobbying rather than good business practices.", "hypothesis": "The setup has lead to increases in political lobbying.", "generated_explanations": [["The context indicates that the setup rewards political lobbying, implying that such activity is incentivized and likely to increase.", "e", "validated"], ["Since good business practices are not rewarded but political lobbying is, individuals and companies are more likely to engage in lobbying to gain advantages.", "e", "validated"], ["Labeling the setup as \"anti-entrepreneurial\" suggests reduced emphasis on innovation and enterprise, pushing actors towards political lobbying instead.", "e", "validated"], ["The context suggests the setup rewards political lobbying but does not specify whether lobbying has actually increased as a result.", "n", "validated"], ["It is unclear if the amount of political lobbying has changed, only that it is incentivized or rewarded.", "n", "validated"], ["The context criticizes the setup as rewarding political lobbying but does not state or imply that it has caused an increase in political lobbying.", "c", "validated"], ["The context describes the character of the setup, not changes or trends in lobbying behavior.", "c", "validated"]], "label_count_round_1": {"e": 3, "n": 2, "c": 2}, "label_set_round_1": ["n", "c", "e"], "label_count_round_2": {"e": 3, "n": 2, "c": 2}, "label_set_round_2": ["n", "c", "e"], "error": [], "not_validated_exp": {}}
{"id": "127809n", "premise": "I'm confused.", "hypothesis": "Not all of it is very clear to me.", "generated_explanations": [["Saying \"I'm confused\" implies a lack of clarity or understanding.", "e", "validated"], ["If someone is confused, it follows that some things are not very clear to them.", "e", "validated"], ["The context \"I'm confused\" does not specify what \"it\" refers to, so it's undetermined if \"not all of it is very clear\" is an accurate description.", "n", "validated"], ["\"I'm confused\" could refer to a general feeling or an emotional state, which might exist even if everything is actually clear, due to other factors such as stress or anxiety.", "n", "not_validated"]], "label_count_round_1": {"e": 2, "n": 2}, "label_set_round_1": ["n", "e"], "label_count_round_2": {"e": 2, "n": 1}, "label_set_round_2": ["n", "e"], "error": [], "not_validated_exp": {"n": 1}}
{"id": "28306c", "premise": "They made little effort, despite the Jesuit presence in Asia, to convert local inhabitants to Christianity or to expand their territory into the interior.", "hypothesis": "The Jesuit presence in Asia helped to convert local residents to Christianity, allowing them to expand their territory.", "generated_explanations": [["The context states that little effort was made to convert locals despite the Jesuit presence, so it is unknown whether any conversions actually happened as a result of the Jesuit presence.", "n", "validated"], ["The context indicates no expansion into the interior occurred, but does not specify if this was caused by the Jesuits' efforts or lack thereof, leaving the relationship between conversion and territorial expansion unclear.", "n", "validated"], ["The context states that little effort was made to convert local inhabitants to Christianity, contrary to the statement's claim that the Jesuit presence was helpful in converting locals.", "c", "validated"], ["The context explicitly mentions there was little attempt to expand territory into the interior, in direct contradiction to the statement's claim that their territory expanded as a result of conversion efforts.", "c", "validated"]], "label_count_round_1": {"n": 2, "c": 2}, "label_set_round_1": ["n", "c"], "label_count_round_2": {"n": 2, "c": 2}, "label_set_round_2": ["n", "c"], "error": [], "not_validated_exp": {}}
